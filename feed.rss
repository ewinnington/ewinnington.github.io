<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
	<channel>
		<title>Eric Winnington</title>
		<link>http://ewinnington.github.io/</link>
		<description>A collection of thoughts, code and snippets.</description>
		<copyright>2022</copyright>
		<pubDate>Sun, 04 Dec 2022 21:58:27 GMT</pubDate>
		<lastBuildDate>Sun, 04 Dec 2022 21:58:27 GMT</lastBuildDate>
		<item>
			<title>7 reasons to not use caching</title>
			<link>http://ewinnington.github.io/posts/7Reasons-no-cache</link>
			<description>&lt;p&gt;Inspired by &lt;a href="https://twitter.com/mjovanovictech"&gt;Milan Jovanović&lt;/a&gt; tweet on &lt;a href="https://twitter.com/mjovanovictech/status/1599124855542411264"&gt;5 reasons to use Redis for caching&lt;/a&gt;,&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/7Reasons-no-cache</guid>
			<pubDate>Sun, 04 Dec 2022 16:30:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Inspired by &lt;a href="https://twitter.com/mjovanovictech"&gt;Milan Jovanović&lt;/a&gt; tweet on &lt;a href="https://twitter.com/mjovanovictech/status/1599124855542411264"&gt;5 reasons to use Redis for caching&lt;/a&gt;,&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/caching/5reasonsCaching.png" class="img-fluid" width="80%" alt="" /&gt;&lt;/p&gt;
&lt;p&gt;and &lt;a href="https://twitter.com/danielmarbach"&gt;Daniel Marbach's&lt;/a&gt; response &amp;quot;&lt;a href="https://twitter.com/danielmarbach/status/1599352526888849408"&gt;Now I want to see five reasons to avoid caching ✋😂&lt;/a&gt;&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/caching/5reasonsNoCaching.png" class="img-fluid" width="80%" alt="" /&gt;&lt;/p&gt;
&lt;p&gt;I found &lt;a href="https://twitter.com/ThrowATwit/status/1599356806874427392"&gt;seven reasons to not introduce caching&lt;/a&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Caching can increase complexity in your application, as you need to manage the cached data and ensure it remains consistent with the underlying data store.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Caching can increase latency, as the cache itself introduces an additional lookup step.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Caching can be expensive, both in terms of the additional hardware and storage required for the cache, and the overhead of managing the cache itself.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Caching can be unreliable, as cached data can become stale or inconsistent if it is not adequately managed or invalidated.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Caching can be a security risk, as sensitive data that is stored in the cache may be vulnerable to unauthorized access or exposure. It takes additional effort to ensure that the correct authorizations are applied to cached data, increasing application complexity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Caching can be harder to debug. To determine why a piece of data is not being retrieved from the cache or is being retrieved from the underlying data store instead is difficult. This can make it challenging to diagnose and fix performance issues related to caching.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Caching can create additional maintenance overhead, as you need to monitor the cache and ensure it is working properly. Monitoring cache hit and miss rates, ensuring that the cache is not getting too full, and periodically purging expired or stale data from the cache.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;and a bonus &lt;a href="https://mobile.twitter.com/joslat/status/1599518029649678336"&gt;8.&lt;/a&gt; from &lt;a href="https://mobile.twitter.com/joslat"&gt;Jose Luis Latorre&lt;/a&gt;
&amp;quot;8. It should be also properly tested, and stress tested... without mention the security testing as well should include a check on this layer too... which would bring us to point 3. More expensive ;)&amp;quot;&lt;/p&gt;
&lt;p&gt;Introducing Caching into any architecture is a decision that must be made with care. We have to ask if it helps us fulfill a business requirement (latency requirements), and improves quality or responsiveness for the end user. And we must ensure the solution is appropriate in terms of cost of operation and cost of monitoring and support. Additionally, the security aspects of a cache should be considered in the solution design.&lt;/p&gt;
&lt;p&gt;In software architecture, there are very few single answers, everything is a compromise. Caching is a great hammer and use it when it is appropriate, but remember not every problem is a nail.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Software Architecture illustrations</title>
			<link>http://ewinnington.github.io/posts/Software-Architecture-Illustration</link>
			<description>&lt;p&gt;In software architecture, I find myself reaching more and more for tools that I can use to generate representations from a simple textual description, be it generated from a tool or hand written. And sometimes, nothing generated looks nice, so I have to do draw it myself!&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/Software-Architecture-Illustration</guid>
			<pubDate>Wed, 16 Nov 2022 20:10:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="illustrations-in-software-architecture"&gt;Illustrations in Software architecture&lt;/h1&gt;
&lt;p&gt;In software architecture, I find myself reaching more and more for tools that I can use to generate representations from a simple textual description, be it generated from a tool or hand written. And sometimes, nothing generated looks nice, so I have to do draw it myself!&lt;/p&gt;
&lt;p&gt;Here are a few of the tools I have recently used, for different purposes:&lt;/p&gt;
&lt;h2 id="diagrams-as-code"&gt;Diagrams as code:&lt;/h2&gt;
&lt;h3 id="mermaid"&gt;Mermaid&lt;/h3&gt;
&lt;p&gt;Mermaid is a language to generate flow charts, pie charts, entity relation diagrams and several other diagrams. I’ve used it in internal documentation and blog posts. The graph description language is simple enough that you can write code to generate charts, too.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mermaid-js.github.io/mermaid/#/"&gt;https://mermaid-js.github.io/mermaid/#/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A live editor is also available online:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mermaid.live/"&gt;https://mermaid.live/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mermaid rendering has been integrated into several markdown renderers, GitHub markdown and VS Code both support it.&lt;/p&gt;
&lt;div class="mermaid"&gt;flowchart LR
    a[Airflow] ---&gt; b[AirFlowTask] --&gt; c[[RabbitMQ Queue Events]] --&gt; d[EventReceiver] --insert--&gt; e[(Postgresql)] --&gt; Monitoring
    d --failed--&gt; g[[Deadletter queue]] --&gt; h[Reconciliation] --&gt; e
&lt;/div&gt;
&lt;p&gt;&lt;img src="/posts/images/SA-Illustrations/Mermaid-flow.png" class="img-fluid" alt="" /&gt;&lt;/p&gt;
&lt;div class="mermaid"&gt;sequenceDiagram
    autonumber

    participant C as Client
    participant S as Target

    S --) C: Communicate API-Key
    C -&gt;&gt; S: Send request with API-Key
    activate S
    S --&gt;&gt; S: Validate API-Key
    S -X C: If not valid: Return 401 
    S -&gt;&gt; C: If valid: Return 200
    deactivate S
&lt;/div&gt;
&lt;p&gt;&lt;img src="/posts/images/SA-Illustrations/Mermaid-sequence.png" class="img-fluid" alt="" /&gt;&lt;/p&gt;
&lt;h3 id="python-diagrams"&gt;Python Diagrams&lt;/h3&gt;
&lt;p&gt;Python has a diagram library which has icons for most programming tools, from Airflow to ZeroMQ. You design the diagram with simple Python code and it uses the Graphviz library to render png images. Highly recommended for small architecture diagrams that just need a dozen or so elements.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://diagrams.mingrammer.com/"&gt;https://diagrams.mingrammer.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ve also done some pull requests to add symbols to the library and I recommend you do so too if you have elements that are missing in your diagrams.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;## pip install diagrams
## winget install -e --id Graphviz.Graphviz
## set PATH=C:\Program Files\Graphviz\bin;%PATH%
#
# Architecture of the docker-compose using a chart generated in py

from diagrams import Diagram, Cluster
from diagrams.onprem.inmemory import Redis
from diagrams.onprem.database import Postgresql
from diagrams.onprem.queue import Rabbitmq
from diagrams.programming.language import PHP
from diagrams.programming.language import Csharp
from diagrams.onprem.client import Users
from diagrams.onprem.network import Nginx

with Diagram(&amp;quot;Composed Docker&amp;quot;, show=False):
    users = Users(&amp;quot;users&amp;quot;)
    
    with Cluster(&amp;quot;Front-End&amp;quot;):
        web = Nginx(&amp;quot;ngweb&amp;quot;)
        php = PHP(&amp;quot;php&amp;quot;)

    with Cluster(&amp;quot;Back-Ends&amp;quot;):
        redis = Redis(&amp;quot;cache&amp;quot;)
        rabbit = Rabbitmq(&amp;quot;rabbit&amp;quot;)
        listener = Csharp(&amp;quot;listener&amp;quot;)
        db = Postgresql(&amp;quot;db&amp;quot;)
    
    users &amp;gt;&amp;gt; web &amp;gt;&amp;gt; php &amp;gt;&amp;gt; rabbit &amp;gt;&amp;gt; listener &amp;gt;&amp;gt; db
    php &amp;gt;&amp;gt; redis
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="/posts/images/SA-Illustrations/composed_docker.png" class="img-fluid" width="80%" alt="" /&gt;&lt;/p&gt;
&lt;h3 id="plantuml"&gt;PlantUML&lt;/h3&gt;
&lt;p&gt;The big one! Plant UML has a ton of diagrams, the language is maybe a bit more obscure and complicated than mermaid, but you gain a lot from PlantUML when you actually need those features.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://plantuml.com/"&gt;https://plantuml.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PlantUML also has a live editor online:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.plantuml.com/plantuml/uml/"&gt;https://www.plantuml.com/plantuml/uml/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actually, I’ve used it quite seldomly, being able to cover most requirements with Mermaid and Python Diagrams.&lt;/p&gt;
&lt;h3 id="d2"&gt;D2&lt;/h3&gt;
&lt;p&gt;D2 has recently been open-sourced and made available. I haven't yet had time to test it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://d2lang.com/tour/intro/"&gt;https://d2lang.com/tour/intro/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="diagrams-as-drawing"&gt;Diagrams as Drawing:&lt;/h2&gt;
&lt;h3 id="diagrams"&gt;Diagrams&lt;/h3&gt;
&lt;p&gt;Diagrams.net has both an online and an offline version of a vector drawing software that works exceedingly well for software architecture illustrations. With symbols for most public cloud platforms included in their delectable libraries, you’ll be able to find the right symbol you need.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.diagrams.net/"&gt;https://www.diagrams.net/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There’s even a Visual Studio Code extension for editing a diagram inside the IDE. Export can be done to PNG easily. Diagrams produced are easily embedded in Atlassian’s wiki and other wiki products.&lt;/p&gt;
&lt;p&gt;Highly recommend if you need to place your architecture elements instead of relying on the auto layout of diagrams as code. Now I just wish that the diagrams as code tools could create a diagram baseline compatible with this tool to modify the layout.&lt;/p&gt;
&lt;h3 id="archi-archimate-modelling"&gt;Archi (Archimate modelling)&lt;/h3&gt;
&lt;p&gt;If you use the &lt;a href="https://en.m.wikipedia.org/wiki/ArchiMate"&gt;Archimate modelling language&lt;/a&gt;, then this is the tool for you to build your modelling concepts. The formalism is great for making something that everyone can “read” once trained on it, but the investment can be quite high to do the correct modelling of your infrastructure with this tool.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.archimatetool.com/"&gt;https://www.archimatetool.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I used the Local application running on Windows.&lt;/p&gt;
&lt;h4 id="online-architecture-repositories"&gt;Online architecture repositories&lt;/h4&gt;
&lt;p&gt;There is also online hosted versions of architecture repository tools using Archimate &lt;a href="https://www.boc-group.com/en/adoit/"&gt;Adoit EA Suite&lt;/a&gt; and an associated community version too.&lt;/p&gt;
&lt;p&gt;Alternatively, there's also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.mega.com/hopex-platform"&gt;Hopex's MEGA&lt;/a&gt; which I only used as it was being decommissioned&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sparxsystems.com/products/ea/index.html"&gt;Sparx Systems’ Enterprise Architect&lt;/a&gt; which I used for a short amount of time before the company standardised on Adoit.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="yed"&gt;yEd&lt;/h3&gt;
&lt;p&gt;In writing this article, I discovered the tool yEd and wanted to mention it for completeness, I haven't had the opportunity to use it yet. It does mention many of the illustration types that are useful (BPML, Flowcharts, UML, ...).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.yworks.com/products/yed"&gt;https://www.yworks.com/products/yed&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="diagrams-from-programming"&gt;Diagrams from programming:&lt;/h2&gt;
&lt;p&gt;Now these are more out there and not always directly applicable, but when you need a visualisation that the above tools cannot do, it’s time to break out these applications.&lt;/p&gt;
&lt;h3 id="d3js"&gt;D3js&lt;/h3&gt;
&lt;p&gt;Not sure if I need to introduce D3js,  it is probably one of the most commonly use and important is visualisation libraries. Used in everything from maps to genomics to economic data. It can do it all.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://d3js.org/"&gt;https://d3js.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I previously used d3js to embed charts of price curves generated from market data, overlapped with the delivery period of energy instruments.&lt;/p&gt;
&lt;h3 id="processing.js"&gt;Processing.js&lt;/h3&gt;
&lt;p&gt;Animated heart pulsating on a field of scintillating gold lace? Yes. That and many more things! Processing excels in the visual demos, animations and more. You’ll have to code it, but it’s no issue to get your custom Mandelbrot animated render and many more. Has interactions with sound and many more features. Does have a high bar of entry though and it takes a while to be productive with it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://processing.org/"&gt;https://processing.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="graphviz"&gt;Graphviz&lt;/h3&gt;
&lt;p&gt;I would be remiss if I didn’t mention Graphviz. It is the library used to generate diagrams from textual descriptions using one of their many languages, Dot being one of them.&lt;/p&gt;
&lt;p&gt;Not something I use directly but more indirect usages via the Python diagrams library. You can learn it’s language and create charts.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://graphviz.org/"&gt;https://graphviz.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="online-services-collaborative"&gt;Online services (collaborative)&lt;/h2&gt;
&lt;p&gt;When you need online collaboration, which the tools above do not cover, you can turn to the following services.&lt;/p&gt;
&lt;h3 id="miro"&gt;Miro&lt;/h3&gt;
&lt;p&gt;I’ve had the most experience with Miro while running large organisation meetings as a place to collect ideas, do feedback rounds and generally plan activities.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://miro.com"&gt;https://miro.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="lucidspark-lucidchart-and-lucidscale"&gt;LucidSpark, LucidChart and LucidScale&lt;/h3&gt;
&lt;p&gt;Both collaboration and vector illustration online software. Also their ability with lucid scale to connect and document your cloud infrastructure is very impressive and helps to keep you infrastructure maps updated.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.lucidspark.com/"&gt;https://www.lucidspark.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.lucidscale.com/"&gt;https://www.lucidscale.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.lucidchart.com/"&gt;https://www.lucidchart.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sadly, it’s one that I’ve not had the opportunity to use very often, usually because it was covered by other tools and no one else in the company was using it. But you should check it out to see if it does work for you and your team.&lt;/p&gt;
&lt;h3 id="microsoft-whiteboard"&gt;Microsoft Whiteboard&lt;/h3&gt;
&lt;p&gt;When all else fails, there’s Microsoft whiteboard. It works, there’s an online version, an integration in teams, a desktop app and even an iOS / iPadOS application. More suited to drawing with a pen, then it becomes a great collaborative whiteboard. I have given internal talks using a Microsoft Whiteboard as a backdrop. I really like to start small and progressively zoom out on these massive canvases.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/microsoft-365/microsoft-whiteboard/digital-whiteboard-app"&gt;https://www.microsoft.com/en-us/microsoft-365/microsoft-whiteboard/digital-whiteboard-app&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="mind-maps"&gt;Mind maps&lt;/h2&gt;
&lt;p&gt;I don't use mind maps very often anymore. I was taught to use them as a child, but haven't kept up the practice. I'm just adding a couple of references in case you are looking for them:&lt;/p&gt;
&lt;h3 id="vscode-mindmap"&gt;vscode-mindmap&lt;/h3&gt;
&lt;p&gt;I've used vscode-mindmap when I needed to create a quick hierarchy map.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=pmcxs.vscode-mindmap"&gt;https://marketplace.visualstudio.com/items?itemName=pmcxs.vscode-mindmap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;There’s no one tool for everything in this day and age. Use what works for you and try out several to see if they stick!&lt;/p&gt;
&lt;p&gt;I highly recommend generating some charts in mermaid from your own database ER-Diagram (easy to do!) or using it to make pie charts like &lt;a href="https://youtu.be/IXRGa5m-Lbo"&gt;Microsoft Polyglot notebooks demonstrates at 15:05 onwards&lt;/a&gt; in their &lt;a href="https://github.com/dotnet/interactive/blob/main/samples/notebooks/polyglot/github%20repo%20milestone%20report.ipynb"&gt;GitHub demo notebook&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have other recommendations for me, do feel free to reach out and I’ll see if they make to cut to get added to this list. :) You can even pull request this actual blog post on GitHub.&lt;/p&gt;
&lt;p&gt;Finally, if someone has a recommendation for a WAN/LAN topology visualisation or charting tool, I’d be happy to hear about it and your experience with it!&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Data Lineage for dataflow and workflow processes</title>
			<link>http://ewinnington.github.io/posts/Data-Lineage</link>
			<description>&lt;p&gt;When working with large amounts of data, extraction, transforms and loads procedures can hide the source of the original data and make inquiries on "where did this data come from and what happened to it?" difficult to answer.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/Data-Lineage</guid>
			<pubDate>Sat, 12 Nov 2022 22:10:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="data-lineage"&gt;Data lineage&lt;/h1&gt;
&lt;p&gt;When working with large amounts of data, extraction, transforms and loads procedures can hide the source of the original data and make inquiries on &amp;quot;where did this data come from and what happened to it?&amp;quot; difficult to answer.&lt;/p&gt;
&lt;p&gt;A data lineage is &amp;quot;the process of understanding, recording, and visualizing data as it flows from data sources to consumption&lt;a id="fnref:1" href="#fn:1" class="footnote-ref"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&amp;quot; and tries to answer that question.&lt;/p&gt;
&lt;p&gt;Using dataflow and ETL orchestration tools such as &lt;a href="https://airflow.apache.org/"&gt;Airflow&lt;/a&gt;, &lt;a href="https://www.prefect.io"&gt;Prefect&lt;/a&gt;, &lt;a href="https://nifi.apache.org/"&gt;NiFi&lt;/a&gt;, we move and transform data, but also lose the reference as to how the data was transformed.&lt;/p&gt;
&lt;p&gt;In this document, we will approach one open source tool OpenLineage and one &amp;quot;hand built&amp;quot; approach to capturing and storing data lineage information.&lt;/p&gt;
&lt;h1 id="openlineage-and-marquez-open-source-tools"&gt;OpenLineage and Marquez - Open source tools&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://openlineage.io/"&gt;OpenLineage&lt;/a&gt; is an open source project and framework for data lineage collection and analysis that helps collect lineage metadata from the data  processing applications. At its core, OpenLineage exposes a standard API for metadata collection - a single API call: &lt;a href="https://openlineage.io/apidocs/openapi/"&gt;&lt;strong&gt;postRunEvent&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To simplify its implementation with AirFlow, Open Lineage has an &lt;a href="https://github.com/OpenLineage/OpenLineage/tree/main/integration/airflow/openlineage/airflow"&gt;airflow connection module&lt;/a&gt; already available.&lt;/p&gt;
&lt;p&gt;On the back-end, the storage of run meta-data has a reference implementation named Marquez. The data model is illustrated here.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://lucid.app/lucidchart/f918ce01-9eb4-4900-b266-49935da271b8/view?page=8xAE.zxyknLQ#"&gt;Marquez data model&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/data-lineage/Marquez-Data-Model.png" class="img-fluid" width="80%" alt="" /&gt;&lt;/p&gt;
&lt;p&gt;But it is also possible to implement one's own storage for metadata in case there is a need or added value, but adopting the open source solution will be an advantage for integration later.&lt;/p&gt;
&lt;h1 id="locally-grown-alternatives"&gt;Locally grown alternatives&lt;/h1&gt;
&lt;p&gt;Data correlation and lineage information can be generated via the emission of events while processing input data. Additionally, input data can be fingerprinted via a fast hash function to check for duplicate imports, so as to enable idempotent processing.&lt;/p&gt;
&lt;h3 id="input-dataset-fingerprinting-via-non-cryptographic-hash-function"&gt;Input dataset fingerprinting via non-cryptographic hash function&lt;/h3&gt;
&lt;p&gt;We can use a fast non-cryptographic hash function such as &lt;a href="https://github.com/backtrace-labs/umash"&gt;umash&lt;/a&gt; to generate a hash of the input data or xxhash &lt;code&gt;sudo apt-get install xxhash&lt;/code&gt;. xxhash is capable of taking streaming STDIN data from compressed files to generate a fast hash.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;time gunzip -c /mnt/d/smart_meter_data/ckw_opendata_smartmeter_dataset_a_202101.csv.gz | /usr/bin/xxhsum
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="correlation-ids-with-uuids"&gt;Correlation IDs with UUIDs&lt;/h3&gt;
&lt;p&gt;Generating uuid for correlations identifiers along &lt;a href="https://www.rfc-editor.org/rfc/rfc4122.html"&gt;rfc4122&lt;/a&gt; gives us multiple variant generation algorithms to give us sortable UUIDs which minimize collision possibilities even with a high UUID generation rate.&lt;/p&gt;
&lt;h3 id="hierarchical-correlation-ids-using-closure-tables"&gt;Hierarchical correlation IDs using closure tables&lt;/h3&gt;
&lt;p&gt;When inputs contain a dataset that is composed of multiple data points that identify unique sets in our final processed dataset, it becomes necessary to be able to trace their lineage back to the initial input. A recursive search through a table of entries to find the parent correlation identifier of a child time-series is quite inefficient.&lt;/p&gt;
&lt;p&gt;To have fast search over deep hierarchies of correlations IDs in relational databases, we can turn to the concept of closure tables.&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;Field&lt;/th&gt;
&lt;th style="text-align: left;"&gt;Type&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;ParentId&lt;/td&gt;
&lt;td style="text-align: left;"&gt;UUID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;ChildId&lt;/td&gt;
&lt;td style="text-align: left;"&gt;UUID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Depth&lt;/td&gt;
&lt;td style="text-align: left;"&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This table structure allows to query in one query all parent or children of an identifier in one non-recursive sql query. This is done at the cost of having to insert the entire hierarchy of the correlationIDs upon insertion.&lt;/p&gt;
&lt;p&gt;Here we are representing the two hierarchies&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aaa &amp;gt; bbb &amp;gt; ccc
aaa &amp;gt; eee 
&lt;/code&gt;&lt;/pre&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;ParentId&lt;/th&gt;
&lt;th style="text-align: left;"&gt;ChildId&lt;/th&gt;
&lt;th style="text-align: right;"&gt;Depth&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;aaa&lt;/td&gt;
&lt;td style="text-align: left;"&gt;aaa&lt;/td&gt;
&lt;td style="text-align: right;"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;bbb&lt;/td&gt;
&lt;td style="text-align: left;"&gt;bbb&lt;/td&gt;
&lt;td style="text-align: right;"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;ccc&lt;/td&gt;
&lt;td style="text-align: left;"&gt;ccc&lt;/td&gt;
&lt;td style="text-align: right;"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;eee&lt;/td&gt;
&lt;td style="text-align: left;"&gt;eee&lt;/td&gt;
&lt;td style="text-align: right;"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;aaa&lt;/td&gt;
&lt;td style="text-align: left;"&gt;bbb&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;bbb&lt;/td&gt;
&lt;td style="text-align: left;"&gt;ccc&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;aaa&lt;/td&gt;
&lt;td style="text-align: left;"&gt;ccc&lt;/td&gt;
&lt;td style="text-align: right;"&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;aaa&lt;/td&gt;
&lt;td style="text-align: left;"&gt;eee&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;note&lt;/em&gt;: &lt;em&gt;if desired the initial 0 depth nodes can be neglected from the insertion process without losing functionality, but can be useful in certain modeling processes (eg. rights, groups)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If we need to find all children of &lt;strong&gt;aaa&lt;/strong&gt;, we can do a&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT ChildId, Depth FROM Closure_Table WHERE ParentId = &amp;quot;aaa&amp;quot; ORDER BY Depth;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which returns the following&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;ChildId&lt;/th&gt;
&lt;th style="text-align: left;"&gt;Depth&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;aaa&lt;/td&gt;
&lt;td style="text-align: left;"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;bbb&lt;/td&gt;
&lt;td style="text-align: left;"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;eee&lt;/td&gt;
&lt;td style="text-align: left;"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;ccc&lt;/td&gt;
&lt;td style="text-align: left;"&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;If we need to find all parents of &lt;strong&gt;eee&lt;/strong&gt;, we can do a&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT ParentId, Depth FROM Closure_Table WHERE ChildId = &amp;quot;eee&amp;quot; ORDER BY Depth DESC;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which returns the following&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;ParentId&lt;/th&gt;
&lt;th style="text-align: left;"&gt;Depth&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;aaa&lt;/td&gt;
&lt;td style="text-align: left;"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;eee&lt;/td&gt;
&lt;td style="text-align: left;"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="table-structure-for-a-correlated-fingerprinted-hierarchical-data-lineage"&gt;Table structure for a Correlated, fingerprinted hierarchical data lineage&lt;/h3&gt;
&lt;p&gt;With correlatedEvent and CorrelatedLineage tables, it becomes possible in a single request to generate a lineage graph for parents or descendants of correlated dataset.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/data-lineage/CorrelatedLineageDataModel.png" class="img-fluid" alt="" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;erDiagram
    CorrelationEvent {
        uuid     IdEvent
        string   Process
        string   Version
        hash     Fingerprint
        int      InputSize
        datetime EventTime
        int      Forced
    }

    CorrelationDetails {
        uuid IdEvent
        string Field
        json Data 
    }

    CorrelationLineage {
        uuid IdParent
        uuid IdChild
        integer Depth
    }

    CorrelationEvent ||--o{ CorrelationDetails : &amp;quot;&amp;quot;
    CorrelationEvent ||--o{ CorrelationLineage : &amp;quot;parent&amp;quot;
    CorrelationEvent ||--o{ CorrelationLineage : &amp;quot;child&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It would even be possible to generate the diagrams using mermaid automatically to trace the flows through the system&lt;a id="fnref:2" href="#fn:2" class="footnote-ref"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/data-lineage/CorrelatedLineageFlow.png" class="img-fluid" alt="" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;flowchart LR
    id1((&amp;quot;DSO Timeseries&amp;quot;)) --&amp;gt; id2[SFTP Download] --&amp;gt; id3[Split]
    id3 --&amp;gt; TS01
    id3 --&amp;gt; TS02
    id3 --&amp;gt; TS03 
    id3 --&amp;gt; TS04
    id3 --&amp;gt; TS..
    TS01 --&amp;gt; id4[Delivery point sum]
    TS02 --&amp;gt; id4
    id4 --&amp;gt; id5[Load]

    met((Weather provider)) --&amp;gt; met2[API Download] --&amp;gt; met3[&amp;quot;Aggregate to hour&amp;quot;] --&amp;gt; met4[&amp;quot;delivery point history&amp;quot;]

    met4 --&amp;gt; for1[forecast consumption]
    id4 --&amp;gt; for1 --&amp;gt; for2[Load]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="solution-design"&gt;Solution design&lt;/h3&gt;
&lt;p&gt;A rabbitMQ message queue to receive correlation events emitted by the tasks, with several consumer tasks receiving and committing to the database is a preferred approach over an HTTP 1.1 connection due the the scaling efficiency of AMQP over pure HTTP&lt;a id="fnref:3" href="#fn:3" class="footnote-ref"&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/data-lineage/CorrelatedApplicationFlow.png" class="img-fluid" width="80%" alt="" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;flowchart LR
    a[Airflow] ---&amp;gt; b[AirFlowTask] --&amp;gt; c[[RabbitMQ Queue Events]] --&amp;gt; d[EventReceiver] -- success --&amp;gt; g[(Postgresql)] --&amp;gt; Monitoring
    d -- failed --&amp;gt; e[[RabbitMQ Queue Deadletter]] --&amp;gt; f[DLQ processing and Reconciliation] --&amp;gt; g
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A particular focus on the monitoring of the solution is necessary to truly have an operational system. The RabbitMQ should be a redundant, instrumented and reported to Graphana, with a queue length monitoring in place. The EventReceivers should employ a dead letter queue in case message are rejected by the database. These rejected messages could also also be a uuid collision - which can be treated by the daily reconciliation process and DeadLetter queue processing.&lt;/p&gt;
&lt;p&gt;A high availability Postgresql is recommended, either as a local instance or as a cloud hosted service - which would facilitate operations.&lt;/p&gt;
&lt;p&gt;The issue of Data retention should be discussed with Business. If we do not keep a time-series history in the time-series datastore, then the event correlation become actually an &lt;a href="https://microservices.io/patterns/data/event-sourcing.html"&gt;event sourcing pattern&lt;/a&gt;, enabling to re-create the history of how the time-series was updated.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Irrespective of the method chosen to capture and store the messages, the systems chosen must provide a high availability solution for data lineage - but must be sure to not block ingestion if the data lineage system is unresponsive. As long as the message queue is persistent and accessible, it can always be caught up later.&lt;/p&gt;
&lt;p&gt;The main task is emitting the events with meaningful data and unique correlation IDs. A focus on the semantics of the events while developing the workflow / dataflows is primordial. A callable event library provides the best developer experience to maximize standardization of code&lt;/p&gt;
&lt;p&gt;The design of idempotent imports into the system is important, it allows to replay events non-destructively and provides operational resilience.&lt;/p&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="https://www.imperva.com/learn/data-security/data-lineage/"&gt;https://www.imperva.com/learn/data-security/data-lineage/&lt;/a&gt;&lt;a href="#fnref:1" class="footnote-back-ref"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;&lt;a href="https://github.com/dotnet/interactive/blob/main/samples/notebooks/polyglot/github%20repo%20milestone%20report.ipynb"&gt;https://github.com/dotnet/interactive/blob/main/samples/notebooks/polyglot/github%20repo%20milestone%20report.ipynb&lt;/a&gt; - See the PieWithMermaid C# task for a visualisation of such an interaction.&lt;a href="#fnref:2" class="footnote-back-ref"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;This should be re-evaluated when HTTP/3 oneshot becomes available in the servers and languages used. The expected performance improvement are such that at that time HTTP/3 QUIC might outrace any other streaming solution. &lt;a href="https://blog.cloudflare.com/http3-the-past-present-and-future/"&gt;https://blog.cloudflare.com/http3-the-past-present-and-future/&lt;/a&gt;&lt;a href="#fnref:3" class="footnote-back-ref"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</content:encoded>
		</item>
		<item>
			<title>Tesla Megapacks put into context</title>
			<link>http://ewinnington.github.io/posts/tesla-megapack</link>
			<description>&lt;p&gt;Tesla on Twitter announced: &lt;a href="https://t.co/aw85eHECXI"&gt;"Meet Megafactory, our new Megapack factory in Lathrop, CA 🔋🔋🔋"&lt;/a&gt;&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/tesla-megapack</guid>
			<pubDate>Wed, 09 Nov 2022 21:40:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="tesla-megapacks"&gt;Tesla Megapacks&lt;/h1&gt;
&lt;p&gt;Tesla on Twitter announced: &lt;a href="https://t.co/aw85eHECXI"&gt;&amp;quot;Meet Megafactory, our new Megapack factory in Lathrop, CA 🔋🔋🔋&amp;quot;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tesla's energy division has recently completed their new Megapack factory in Lathrop California , which they claim can produce currently 10'000 Megapacks a year. How much storage is that and how does this compare to a Hydropower pump storage plant?&lt;/p&gt;
&lt;h2 id="tesla-megapacks-specs-per-pack"&gt;Tesla megapacks Specs per pack&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;4 Hour Duration&lt;/li&gt;
&lt;li&gt;Power: 970 kW&lt;/li&gt;
&lt;li&gt;Energy: 3,916 kWh per Megapack&lt;/li&gt;
&lt;li&gt;Round Trip Efficiency: 93.5%&lt;/li&gt;
&lt;li&gt;9.12 m x 1.65 m x 2.79 m&lt;/li&gt;
&lt;li&gt;38,100 kg&lt;/li&gt;
&lt;li&gt;~$2 million per pack&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="offer"&gt;Offer&lt;/h2&gt;
&lt;p&gt;An offer was generated on the Tesla Energy website to get an appropriate pricing for the largest system they offer.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1000 Megapack&lt;/li&gt;
&lt;li&gt;969.6 MW Power&lt;/li&gt;
&lt;li&gt;3916 MWh Energy Megapack&lt;/li&gt;
&lt;li&gt;Duration: 4 Hours&lt;/li&gt;
&lt;li&gt;Delivery: Q3 2024&lt;/li&gt;
&lt;li&gt;Estimated Price (California) $1,832,519,850&lt;/li&gt;
&lt;li&gt;Est. Annual Maintenance $4,821,480 - Maintenance Price escalates at 2% per year&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Based on this, we can see that 10'000 megapacks represent about 39160 MWh of storage (39 GWh), with a sales cost of approx $18 billion.&lt;/p&gt;
&lt;p&gt;So how does this compare to the two latest large Swiss Pump-Storage Hydropowerplants?&lt;/p&gt;
&lt;h2 id="hydropower-plants"&gt;Hydropower plants&lt;/h2&gt;
&lt;h3 id="nant-de-drance-pump-storage-extension"&gt;Nant-de-Drance pump-storage extension&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;1 Pump-storage power plant&lt;/li&gt;
&lt;li&gt;Power 900 MW (Turbines and Pumps)&lt;/li&gt;
&lt;li&gt;Storage 20 GWh&lt;/li&gt;
&lt;li&gt;Duration: 19 Hours&lt;/li&gt;
&lt;li&gt;Round trip efficiency: over 90%&lt;/li&gt;
&lt;li&gt;Estimated Price 2 billion CHF&lt;/li&gt;
&lt;li&gt;~14 years to build and bring into operation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="kraftwerk-linthlimmern-pump-storage-extension"&gt;Kraftwerk-Linth–Limmern pump-storage extension&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;1 Pump-storage power plant&lt;/li&gt;
&lt;li&gt;Power 1000 MW (Turbines and Pumps)&lt;/li&gt;
&lt;li&gt;Storage 33 GWh&lt;/li&gt;
&lt;li&gt;Duration: 33 Hours&lt;/li&gt;
&lt;li&gt;Round trip efficiency: over 90%&lt;/li&gt;
&lt;li&gt;Estimated Price 2.1 billion CHF&lt;/li&gt;
&lt;li&gt;~10 years to build and bring into operation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The storage cost of the batteries is currently about a factor 4-9x the price of the hydropower plant construction but have the advantage of being available within about 18 months. What remains to be seen is how much battery degradation is a factor in these grid scale battery installations. At least Tesla is offering, from my understanding, a 15 year warranty on the Megapack.&lt;/p&gt;
&lt;p&gt;The amount of storage produced by the factory represents more than 1 large hydropower plant per year.&lt;/p&gt;
&lt;p&gt;The 39 GWh storage produced by the factory in one year is a huge amount, so much that it would cover around 25% of the &lt;a href="https://www.iea.org/data-and-statistics/charts/battery-storage-capability-by-countries-2020-and-2026"&gt;expected total capacity that the IEA planned for the entire world by 2026&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="post-scriptum-new-gridscale-batteries-in-europe"&gt;Post-scriptum: new gridscale batteries in Europe&lt;/h2&gt;
&lt;p&gt;2022.11.22 - &lt;a href="https://www.bbc.com/news/uk-england-humber-63707463"&gt;Cottingham: Europe's biggest battery storage system switched on - 196MWh&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Power: ? (my estimate ~50-100 MW)&lt;/li&gt;
&lt;li&gt;Storage: 196 MWh&lt;/li&gt;
&lt;li&gt;use Tesla's AI software to match energy supply to demand&lt;/li&gt;
&lt;li&gt;Commissioning in two stages in December 2022 and March 2023.&lt;/li&gt;
&lt;li&gt;Supplier: Tesla&lt;/li&gt;
&lt;li&gt;Cost: ? (my estimate $100 million+)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As usual, BBC is terribly uninformative about specifications and cost. If we assume 50 Tesla Megapacks, cost should be around $100 million+ and 50 to 100 MW based on the 2h or 4h megapacks. Interesting to see a Tesla system in Europe. I expect many more to come online.&lt;/p&gt;
&lt;p&gt;2022.11.07 - &lt;a href="https://www.rwe.com/en/press/rwe-generation/2022-11-07-battery-storage-220-mw-neurath"&gt;RWE gives green light for 220-megawatt battery storage system in North Rhine-Westphalia&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Power: 80 + 140 MW = 220 MW&lt;/li&gt;
&lt;li&gt;Storage: delivering the required output for over an hour but full capacity not mentioned. 220 MWh to 440MWh.&lt;/li&gt;
&lt;li&gt;140 million euros&lt;/li&gt;
&lt;li&gt;commissioning in 2024&lt;/li&gt;
&lt;li&gt;Supplier: Not mentioned.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2021.07.22 - &lt;a href="https://www.rwe.com/en/press/rwe-ag/2021-07-22-rwe-builds-one-of-the-largest-battery-storage-facilities-in-germany"&gt;RWE bringing 72MW BESS in Germany online in November&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Power: 72 + 45MW = 117 MW&lt;/li&gt;
&lt;li&gt;Storage: 128MWh&lt;/li&gt;
&lt;li&gt;€50 million&lt;/li&gt;
&lt;li&gt;commissioning in end 2022&lt;/li&gt;
&lt;li&gt;Supplier: CATL batteries&lt;/li&gt;
&lt;/ul&gt;
</content:encoded>
		</item>
		<item>
			<title>Embracing SQLite and living with micro-services</title>
			<link>http://ewinnington.github.io/posts/sqlite-microstores</link>
			<description>&lt;p&gt;The idea of micro-services and their own single purpose data stores is easy to describe. But then to implement and live with it is a different story. So as a developer and architect, I’ve decided to do just that! Make micro-services and micro-data stores to cover the tiny and small stuff in my life I want to keep track of.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/sqlite-microstores</guid>
			<pubDate>Sat, 22 Oct 2022 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;The idea of micro-services and their own single purpose data stores is easy to describe. But then to implement and live with it is a different story. So as a developer and architect, I’ve decided to do just that! Make micro-services and micro-data stores to cover the tiny and small stuff in my life I want to keep track of.&lt;/p&gt;
&lt;p&gt;As an example, I read online comics, light novels and mangas. I had a continuous list of a couple hundred bookmarks that I tried to keep updated with the last position I was when I read the story. But I always forget to update the bookmark and have so many of them that I lose the last read chapter. My solution?&lt;/p&gt;
&lt;p&gt;A SQLite db and some Python code to load it. Pass a single url on some command line Python and it gets added to the Db, a Request goes out, gets the title and chapter from the html, then adds it to the DB by title. Now I have a track of where I left off and I can get have last updated / last read records. Bonus, I can do a SELECT .. ORDER BY updated LIMIT 10 to check the last stories I was reading and pipe them to my browser to open up the chapters where I left them off.&lt;/p&gt;
&lt;p&gt;To really embrace SQLite is to make everything in your life become a new micro database, even if there's only a couple of tables with a dozen or a hundred rows.&lt;/p&gt;
&lt;p&gt;Stock tracking? an SQLite Db with Transactions and a roll-up Inventory table.&lt;/p&gt;
&lt;p&gt;In fact, even when sending data around from one system to another, we should even embrace the simplicity of SQLite over CSV files. See &lt;a href="https://berthub.eu/articles/posts/big-data-storage/"&gt;https://berthub.eu/articles/posts/big-data-storage/&lt;/a&gt; for his views and performance tests.&lt;/p&gt;
&lt;p&gt;Now I have micro data-stores, I can add a service on top which contains the CRUD commands I need to interact with them and show them in a personal dashboard.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>The case for a SpaceX Starship laser ablation platform for orbital debris management</title>
			<link>http://ewinnington.github.io/posts/Starship-laser-ablation</link>
			<description>&lt;p&gt;SpaceX’s Starship program as a platform for specialised load-outs has many potential applications: Tanker variants for orbital refuelling, Crew variant for Dear Moon mission and dedicated satellite launcher for the Starlink satellite constellation deployment being the variants we already know about.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/Starship-laser-ablation</guid>
			<pubDate>Sun, 18 Sep 2022 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;SpaceX’s Starship program as a platform for specialised load-outs has many potential applications: Tanker variants for orbital refuelling, Crew variant for Dear Moon mission and dedicated satellite launcher for the Starlink satellite constellation deployment being the variants we already know about.&lt;/p&gt;
&lt;p&gt;With the latest discussion about Orbital debris fields, I suggest it is time to discuss about another variant: a dedicated laser ablation Starship variant for de-orbiting or destroying 1 to 10 cm sized debris.&lt;/p&gt;
&lt;p&gt;To deorbit or destroy debris in Earth’s orbit, laser ablation is one of the ideal techniques to use since it can directly burn up small debris or  deorbit larger ones via plasma propulsion (in effect, burning up the target object and causing it to be propelled by the plasma generated by the laser hitting the target).&lt;/p&gt;
&lt;p&gt;To be able to make orbital cleanup affordable, we need to have a cheap to fly, high power laser with a sufficient burn time and have the ability to choose the orbit of our laser platform.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cheap to fly: The launch costs of a SpaceX starship is estimated to be at least one order of magnitude less in dollar per kilo to orbit.&lt;/li&gt;
&lt;li&gt;High power laser: The high power of chemical lasers along with their high mass requirements make them a good fit for integration into a Starship. With sufficient mass for the chemicals to supply the laser, the lasers could be used long enough to clear the coplanar orbit. Once the chemicals are depleted, the starship can be landed and the laser refuelled for another mission. Other types of lasers, which have been developed recently, are also candidates: Solid state lasers, fiber lasers, diode lasers - with these the mass capability of Starship would be used for large batteries and potentially hydrogen fuel cells to provide enough power for the application.&lt;/li&gt;
&lt;li&gt;Ability to choose orbit: Laser ablation is most effective when the platform if shooting from a “same altitude and coplanar” orbit. Different launches are then the most effective way of reaching these orbits to get maximal efficiency.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the &lt;a href="https://www.fastcompany.com/90789865/orbits-act-what-to-know-about-congress-effort-to-clean-up-space-debris"&gt;US government decides to start paying for orbital clearing services&lt;/a&gt; with the Orbital Clearance with the Orbital Sustainability (ORBITS) Act, it would be a clear case to develop such a Starship variant. Without other incentives, it might still be profitable by selling “deorbiting and clearance services” to other satellite providers. This remains to be seen how much “good citizenship” is to be expected from satellite constructors, launchers and operators.&lt;/p&gt;
&lt;h2 id="references-to-laser-ablation-papers"&gt;References to laser ablation papers&lt;/h2&gt;
&lt;p&gt;Space based -
&lt;a href="https://conference.sdo.esoc.esa.int/proceedings/sdc8/paper/43/SDC8-paper43.pdf"&gt;https://conference.sdo.esoc.esa.int/proceedings/sdc8/paper/43/SDC8-paper43.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ground based -
&lt;a href="https://conference.sdo.esoc.esa.int/proceedings/sdc6/paper/29/SDC6-paper29.pdf"&gt;https://conference.sdo.esoc.esa.int/proceedings/sdc6/paper/29/SDC6-paper29.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Air based Anti ballistic missile chemical laser - a lower powered could be used in Starsjip for de-orbiting, but this shows the feasibility.
&lt;a href="https://minutemanmissile.com/abl.html"&gt;https://minutemanmissile.com/abl.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="discussion"&gt;Discussion&lt;/h2&gt;
&lt;p&gt;A &lt;a href="https://www.reddit.com/r/SpaceXLounge/comments/xj8bjh/the_case_for_a_spacex_starship_laser_ablation/"&gt;discussion thread on reddit about this post&lt;/a&gt; has provided some feedback and the post has been updated.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>We can leave viruses behind on Earth as we leave the gravity well</title>
			<link>http://ewinnington.github.io/posts/Viruses-left-behind</link>
			<description>&lt;p&gt;As humanity left for the stars, bacteria hitched a ride with us. They were on us, in us and around us - as much part of us as our own cells. Viruses, on the other hand, due to careful screening programs, quarantines and selective breeding programs of the few animals that took to the stars, were confined to the gravity well of Earth. Without hosts, they could not follow us. We had left our ancient enemy behind.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/Viruses-left-behind</guid>
			<pubDate>Fri, 14 Jan 2022 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;As humanity left for the stars, bacteria hitched a ride with us. They were on us, in us and around us - as much part of us as our own cells. Viruses, on the other hand, due to careful screening programs, quarantines and selective breeding programs of the few animals that took to the stars, were confined to the gravity well of Earth. Without hosts, they could not follow us. We had left our ancient enemy behind.&lt;/p&gt;
&lt;p&gt;Within two generations, the space born growing up on the O’Neill colony cylinders - even those who lived at 0.9 to 1g - realised that earth was going to be a forbidden planet for them. They had no defences against the viruses that continued to permeate the planet. A visit to earth required them to live in an isolation suit and sterile quarters - limiting contact with the earthers and fauna.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Checking for liveness on databases for health checks</title>
			<link>http://ewinnington.github.io/posts/db-health</link>
			<description>&lt;p&gt;When you just want to check a DB is reachable from your api or code, a health check is used. For the following DBs the simplest query is:&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/db-health</guid>
			<pubDate>Tue, 14 Jul 2020 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;When you just want to check a DB is reachable from your api or code, a health check is used. For the following DBs the simplest query is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Oracle: &lt;code&gt;SELECT 1 FROM dual&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Postgresql: &lt;code&gt;SELECT 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;SQLite: &lt;code&gt;SELECT 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Mysql / MariaDb: &lt;code&gt;SELECT 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Microsoft SQL-Server: &lt;code&gt;SELECT 1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is really an odd one on the list.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>The point of Space exploration</title>
			<link>http://ewinnington.github.io/posts/Point-of-exporing-space</link>
			<description>&lt;p&gt;In my view, the point of exploration is hope. For a small slice of humanity, hope in a better world is what drives us.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/Point-of-exporing-space</guid>
			<pubDate>Sat, 18 Apr 2020 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;In my view, the point of exploration is hope. For a small slice of humanity, hope in a better world is what drives us.&lt;/p&gt;
&lt;p&gt;By learning about the composition of the moon, setting up ultra precise reflectors on its surface to map its motion and exploring it, we are learning about our solar system and the universe, as well as the challenges we will face in the centuries to come.&lt;/p&gt;
&lt;p&gt;Humanity needs to expand beyond earth to realize how precious earth is. Every person who has been to space has come back profoundly changed and humbled by the experience. A little distance is needed to appreciate the view and realize how lucky we all are.&lt;/p&gt;
&lt;p&gt;The science benefits us all: Solar panels and microwaves to medical innovations. Theory of ecology in closed systems, advanced recycling  and so many more.&lt;/p&gt;
&lt;p&gt;Mars and the moon are but a stepping stone to the solar system. And hopefully to the milky way and beyond. We need to answer the question &amp;quot;Is there life out there?&amp;quot;, or at least I do.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Tips and tricks for C# Jupyter notebook</title>
			<link>http://ewinnington.github.io/posts/jupyter-tips-csharp</link>
			<description>&lt;p&gt;As I use the Jupyter notebook with C# integration, I'll add to this list of tricks as I discover them.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/jupyter-tips-csharp</guid>
			<pubDate>Sun, 17 Nov 2019 01:30:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;As I use the Jupyter notebook with C# integration, I'll add to this list of tricks as I discover them.&lt;/p&gt;
&lt;h2 id="adding-collapsed-details-to-jupyter-notebooks"&gt;Adding collapsed details to jupyter notebooks&lt;/h2&gt;
&lt;p&gt;I wanted to show hints and answers to questions in the jupyter notebook, but I didn't want them to be directly visible without interaction.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/collapsed_details.png" class="img-fluid" alt="collapsed" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/expanded_details.png" class="img-fluid" alt="expanded" /&gt;&lt;/p&gt;
&lt;p&gt;This was done by creating a markdown block with an HTML section inside. When interacted with, the section expands.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-HTML"&gt;&amp;lt;details&amp;gt;
&amp;lt;summary&amp;gt;Summary of the fold&amp;lt;/summary&amp;gt;
  ... Content shown after the fold ...
&amp;lt;/details&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;details&gt;
&lt;summary&gt;Summary of the fold&lt;/summary&gt;
  ... Content shown after the fold ...
&lt;/details&gt;
&lt;p&gt;And since it's just HTML, it works anywere, including here.&lt;/p&gt;
&lt;h2 id="display-function"&gt;display() function&lt;/h2&gt;
&lt;p&gt;The C# kernel embedded in Jupyter has some functions that control the output to the cells of the notebook when executed. One of these functions is  &lt;code&gt;display()&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id="tables"&gt;Tables&lt;/h3&gt;
&lt;p&gt;It shows properties of objects or lists in a table format. In my linear programming solver examples, I used this command to make a table with the name and value of each problem variable.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt; display(solver.variables().Select(a =&amp;gt; new { Name  = a.Name(), Value = a.SolutionValue() })); 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/10-6.png" class="img-fluid" alt="var_table" /&gt;&lt;/p&gt;
&lt;p&gt;This is an ideal case for &lt;a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/anonymous-types"&gt;C#'s anonymous objects&lt;/a&gt; and &lt;a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/data-transformations-with-linq"&gt;linq to select the object properties&lt;/a&gt; that you want to see in the table. Adding &lt;code&gt;using System.Linq;&lt;/code&gt; to your references will allow you to use the &lt;code&gt;.Select( x =&amp;gt; new { PropertyHeader = x.PropertyValue, ... })&lt;/code&gt; linq command.&lt;/p&gt;
&lt;h3 id="svgs"&gt;SVGs&lt;/h3&gt;
&lt;p&gt;I discovered the &lt;code&gt;display(HTML())&lt;/code&gt; function allows you to pass items such as SVGs from inside C# to be rendered below the block. Two examples are the SVG image triange and the bar chart. On top of that, the bar chart is stylable by CSS.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/svg_img.png" class="img-fluid" alt="expanded" /&gt;&lt;/p&gt;
&lt;p&gt;The SVG code is generated inside C#, then the variable containing the SVG is displayed.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/bar_chart.png" class="img-fluid" alt="expanded" /&gt;&lt;/p&gt;
&lt;p&gt;Finally, you can add create a cell containing some CSS (with &lt;code&gt;%%html&lt;/code&gt;) , which when executed will change the chart as shown.
&lt;img src="/posts/images/jupyter-notebook-tips/bar_chart_with_css.png" class="img-fluid" alt="expanded" /&gt;
&lt;img src="/posts/images/jupyter-notebook-tips/bar_chart_css.png" class="img-fluid" alt="expanded" /&gt;&lt;/p&gt;
&lt;h2 id="magic"&gt;Magic&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;%lsmagic&lt;/code&gt; command shows a list of commands available to use in code blocks.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/lsmagic.png" class="img-fluid" alt="expanded" /&gt;&lt;/p&gt;
&lt;h3 id="javascript"&gt;%%javascript&lt;/h3&gt;
&lt;p&gt;You can execute javascript with the &lt;code&gt;%%javascript&lt;/code&gt; magic.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/javascript_hello.png" class="img-fluid" alt="collapsed" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/javascript_hello_active.png" class="img-fluid" alt="collapsed" /&gt;&lt;/p&gt;
&lt;h3 id="html"&gt;%%html&lt;/h3&gt;
&lt;p&gt;As previously mentioned, the %%html command will allow you to add CSS blocks and any other HTML output directly into the Jupyter output cell.&lt;/p&gt;
&lt;h3 id="time"&gt;%%time&lt;/h3&gt;
&lt;p&gt;Gives you access to the wall time. Actual time took to execution of the cell.&lt;/p&gt;
&lt;h3 id="whos"&gt;%whos&lt;/h3&gt;
&lt;p&gt;Gives you access to the list of currently defined variable in the memory of the notebook. Also lists the type and value (as a &amp;quot;toString() representation) of the objects.&lt;/p&gt;
&lt;h3 id="fsharp"&gt;%%fsharp&lt;/h3&gt;
&lt;p&gt;You can intermingle C# and F# code inside one notebook, as long as they are in different cells. You can switch to F# by prefixing the cell with &lt;code&gt;%%fsharp&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-%%fsharp"&gt;let main argv =
    display &amp;quot;Hello World from F#!&amp;quot;
    0 
main()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/f_sharp.png" class="img-fluid" alt="collapsed" /&gt;&lt;/p&gt;
&lt;h2 id="graphing-from-c"&gt;Graphing from C#&lt;/h2&gt;
&lt;p&gt;We can chart using &lt;code&gt;Xplot.Plotly&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;//Install XPlot package
#r &amp;quot;nuget:XPlot.Plotly,2.0.0&amp;quot;
using XPlot.Plotly;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Input data:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;DateTime now = DateTime.Now; 
var imax = 8760; 
var rand = new Random(); 
double[] data = Enumerable.Range(1, imax).Select(x =&amp;gt; 20.0 + 15.0 * Math.Sin(x/60.0) + 12 * rand.NextDouble()).ToArray(); 
DateTime[] tp = Enumerable.Range(1, imax).Select(x =&amp;gt; now.AddHours(x) ).ToArray(); 

int totalNumberForBarChart = 3;
double[] actualFares = new [] {3.4, 12.3, 20.42};
double[] predictionFares = new [] {7.4, 14.3, 18.42};
int[] elements = Enumerable.Range(0, totalNumberForBarChart).ToArray();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;my samples are here &lt;a href="https://github.com/ewinnington/noteb/blob/master/Charts_CSharp.ipynb"&gt;C# charts&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="two-bar-plot"&gt;Two bar plot&lt;/h3&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/bar.png" class="img-fluid" alt="bar" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;// Define group for Actual values
var ActualValuesGroupBarGraph = new Graph.Bar()
{
   x = elements,
   y = actualFares,
   name = &amp;quot;Actual&amp;quot;
};
 
// Define group for Prediction values
var PredictionValuesGroupBarGraph = new Graph.Bar()
{
   x = elements,
   y = predictionFares,
   name = &amp;quot;Predicted&amp;quot;
};
 
var chart = Chart.Plot(new[] {ActualValuesGroupBarGraph, PredictionValuesGroupBarGraph});
var layout = new Layout.Layout(){barmode = &amp;quot;group&amp;quot;, title=&amp;quot;Actual fares vs. Predicted fares Comparison&amp;quot;};
chart.WithLayout(layout);
chart.WithXTitle(&amp;quot;Cases&amp;quot;);
chart.WithYTitle(&amp;quot;Fare&amp;quot;);
chart.WithLegend(true);
chart.Width = 700;
chart.Height = 400;
 
display(chart);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="histogram"&gt;Histogram&lt;/h3&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/histogram.png" class="img-fluid" alt="hist" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;var faresHistogram = Chart.Plot(new Graph.Histogram(){x = data, autobinx = false, nbinsx = 20});
var layout = new Layout.Layout(){title=&amp;quot;Distribution of taxi trips per cost&amp;quot;};
faresHistogram.WithLayout(layout);

display(faresHistogram);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="scatter"&gt;Scatter&lt;/h3&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/scatter.png" class="img-fluid" alt="scatter" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;var chart = Chart.Plot(
    new Graph.Scatter()
    {
        x = actualFares,
        y = predictionFares,
        mode = &amp;quot;markers&amp;quot;,
        marker = new Graph.Marker()
        {
            color = predictionFares,
            colorscale = &amp;quot;Jet&amp;quot;
        }
    }
);

var layout = new Layout.Layout(){title=&amp;quot;Plot Time vs. Distance &amp;amp; color scale on Fares&amp;quot;};
chart.WithLayout(layout);
chart.Width = 500;
chart.Height = 500;
chart.WithLegend(true);

display(chart);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="line-chart-with-scatter"&gt;Line chart with scatter&lt;/h3&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-tips/lines.png" class="img-fluid" alt="lines" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;var linedUp = new Graph.Scatter()
{
    x = tp,
    y = data,
    mode = &amp;quot;lines&amp;quot;,
};

var chart = Chart.Plot(linedUp);
chart.WithXTitle(&amp;quot;Date&amp;quot;);
chart.WithYTitle(&amp;quot;Value&amp;quot;);
chart.WithLegend(true);
chart.Width = 1200;
chart.Height = 600;
display(chart);
&lt;/code&gt;&lt;/pre&gt;
</content:encoded>
		</item>
		<item>
			<title>Applications in LP and MILP with C# and OR-Tools inside Jupyter</title>
			<link>http://ewinnington.github.io/posts/jupyter-lp-20</link>
			<description>&lt;p&gt;Thanks to the integration of C# into &lt;a href="https://jupyter.org/"&gt;Jupyter notebooks&lt;/a&gt; with the &lt;a href="https://github.com/dotnet/try"&gt;kernel from Donet try&lt;/a&gt; and support from the &lt;a href="https://mybinder.org/"&gt;MyBinder.org&lt;/a&gt; hosting, it's easy to share with you runnable workbooks to illustrate how to use the &lt;a href="https://developers.google.com/optimization"&gt;Google OR-Tools&lt;/a&gt; to solve the &lt;a href="https://en.wikipedia.org/wiki/Linear_programming"&gt;linear&lt;/a&gt; (LP) and &lt;a href="https://en.wikipedia.org/wiki/Integer_programming"&gt;mixed-integer linear problems&lt;/a&gt; (MILP) .&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/jupyter-lp-20</guid>
			<pubDate>Sat, 16 Nov 2019 23:30:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Thanks to the integration of C# into &lt;a href="https://jupyter.org/"&gt;Jupyter notebooks&lt;/a&gt; with the &lt;a href="https://github.com/dotnet/try"&gt;kernel from Donet try&lt;/a&gt; and support from the &lt;a href="https://mybinder.org/"&gt;MyBinder.org&lt;/a&gt; hosting, it's easy to share with you runnable workbooks to illustrate how to use the &lt;a href="https://developers.google.com/optimization"&gt;Google OR-Tools&lt;/a&gt; to solve the &lt;a href="https://en.wikipedia.org/wiki/Linear_programming"&gt;linear&lt;/a&gt; (LP) and &lt;a href="https://en.wikipedia.org/wiki/Integer_programming"&gt;mixed-integer linear problems&lt;/a&gt; (MILP) .&lt;/p&gt;
&lt;h1 id="applications-of-linear-programming"&gt;Applications of linear programming&lt;/h1&gt;
&lt;h2 id="lp-problem-wire-production"&gt;LP Problem : Wire production&lt;/h2&gt;
&lt;p&gt;A plant makes aluminium and copper wires. Each Kg of aluminium wire requires 10 kWh of electricity and &lt;span class="math"&gt;\(\frac{1}{2}\)&lt;/span&gt; hour of labour. Each Kg of Copper wire requires 4 kWh of electricity and $1$ hour of labour. Electricity is limited to 450 kWh/day, labour is limited to 42.5 hours/day at a cost of 11 € an hour, Electricity cost is 20 € / MWh, Aluminium cost is 1.8 €/Kg, Copper cost is 5.4 €/Kg. Total weight delivered to the plant daily is limited to 56 Kg. Aluminium wire sales price is 45 €/Kg, Copper wire sales price is 50 €/Kg.&lt;/p&gt;
&lt;p&gt;What should be produced to maximise profit and what is the maximum profit?&lt;/p&gt;
&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=Lp_WireProduction.ipynb"&gt;Launch the binder&lt;/a&gt;  &lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=Lp_WireProduction.ipynb"&gt;&lt;img src="https://mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;Solver solver = Solver.CreateSolver(&amp;quot;LinearProgramming&amp;quot;, &amp;quot;CLP_LINEAR_PROGRAMMING&amp;quot;);

//Setting up the variables and constants of the problem 
Variable Al = solver.MakeNumVar(0.0, double.PositiveInfinity, &amp;quot;Al&amp;quot;);
Variable Cu = solver.MakeNumVar(0.0, double.PositiveInfinity, &amp;quot;Cu&amp;quot;);
double El_Price = 20.0; double El_Max = 450; 
double La_Price = 11.0; double La_Max = 42.5; 
double Weight_Max = 56.0; 
double Al_Purchase = 1.8 ; double Al_Sale = 45.0;
double Cu_Purchase = 5.4; double Cu_Sale = 50.0;

// Maximize revenue 
Objective objective = solver.Objective();
objective.SetCoefficient(Al, Al_Sale-Al_Purchase-(La_Price * 1/2.0)-(El_Price * 10/1000.0));
objective.SetCoefficient(Cu, Cu_Sale-Cu_Purchase-(La_Price * 1)-(El_Price * 4/1000.0));
objective.SetMaximization();

// Electricity usage limit
Constraint c0 = solver.MakeConstraint(0, El_Max);
c0.SetCoefficient(Al, 10);
c0.SetCoefficient(Cu, 4);

// Labour usage limit
Constraint c1 = solver.MakeConstraint(0, La_Max);
c1.SetCoefficient(Al, 1/2.0);
c1.SetCoefficient(Cu, 1);

// Weight limit
Constraint c2 = solver.MakeConstraint(0, Weight_Max);
c2.SetCoefficient(Al, 1);
c2.SetCoefficient(Cu, 1);

SolveAndPrint(solver);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="milp-problem-knapsack"&gt;MILP Problem : Knapsack&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://en.wikipedia.org/wiki/Knapsack_problem"&gt;knapsack problem&lt;/a&gt; defines a bag that was a maximal weight of &lt;span class="math"&gt;\(W\)&lt;/span&gt;, we can take items from a set of items each with a weight of &lt;span class="math"&gt;\(w_i\)&lt;/span&gt; and a value of &lt;span class="math"&gt;\(v_i\)&lt;/span&gt;. Typically, the problem is defined with an &lt;span class="math"&gt;\(x_i \in \{0,1\}\)&lt;/span&gt; variable set to either 0 or 1 knapsack where each item is either taken or not.&lt;/p&gt;
&lt;p&gt;Here we are going to allow fractional parts of the items to be taken so that we can solve it as a linear problem (also known as a linear relaxation), allowing &lt;span class="math"&gt;\(x_i \in [0,1]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=Knapsack_Lp_Milp.ipynb"&gt;Launch the binder&lt;/a&gt;  &lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=Knapsack_Lp_Milp.ipynb"&gt;&lt;img src="https://mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;//Array of items, weights and totals
int nItems = 10; 
double maxWeight = 220; 
double[] weights = {31, 27, 12, 39,  2, 69, 66, 29, 45, 58};
double[] values =  {24, 27, 26, 15, 19, 33, 30, 28, 65, 42};

Solver milp_solver = Solver.CreateSolver(&amp;quot;MILP&amp;quot;, &amp;quot;CBC_MIXED_INTEGER_PROGRAMMING&amp;quot;);

Variable[] Items = milp_solver.MakeBoolVarArray(10, &amp;quot;Items&amp;quot;);

// Maximize revenue 
Objective objective = milp_solver.Objective();
for(int i = 0; i &amp;lt; nItems; i++) objective.SetCoefficient(Items[i], values[i]);
objective.SetMaximization();

// Weight limit
Constraint c0 = milp_solver.MakeConstraint(0, maxWeight);
for(int i = 0; i &amp;lt; nItems; i++) c0.SetCoefficient(Items[i], weights[i]);

SolveAndPrint(milp_solver, nItems, weights);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are many ways of solving the knapsack problem, using LP and MILP solvers as seen here or using Dynamic Programming. The Google OR-Tools have a specific solver for multi-dimensional knapsack problems, including one which uses Dynamic Programming.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Hosting your C# Jupyter notebook online by adding one file to your repo</title>
			<link>http://ewinnington.github.io/posts/my-binder-jupyter-csharp</link>
			<description>&lt;p&gt;&lt;a href="https://mybinder.org/"&gt;MyBinder.org&lt;/a&gt; in collaboration with &lt;a href="https://github.com/dotnet/try"&gt;Dotnet try&lt;/a&gt; allows you to host your .net notebooks online.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/my-binder-jupyter-csharp</guid>
			<pubDate>Thu, 14 Nov 2019 23:20:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;&lt;a href="https://mybinder.org/"&gt;MyBinder.org&lt;/a&gt; in collaboration with &lt;a href="https://github.com/dotnet/try"&gt;Dotnet try&lt;/a&gt; allows you to host your .net notebooks online.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=SqliteInteraction.ipynb"&gt;SQLite example workbook: &lt;/a&gt;
&lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=SqliteInteraction.ipynb"&gt;&lt;img src="https://mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To light up this for your own hosted repositories, you will need a public github repo. Inside the repository, you will need to create a &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; file that gives the setup required for MyBinder to setup the environment of the workbook.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/dotnet/try/blob/master/CreateBinder.md"&gt;dotnet/try&lt;/a&gt; has the set of instrunctions.&lt;/p&gt;
&lt;p&gt;For my repository, I used the following &lt;a href="https://github.com/ewinnington/noteb/blob/master/Dockerfile"&gt;Dockerfile&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A list of my changes to the standard one proposed by dotnet/try:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I used a fixed docker image &lt;code&gt;jupyter/scipy-notebook:45f07a14b422&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Since I have all my notebooks in the root of my repository I did &lt;code&gt;COPY . ${HOME}/Notebooks/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Since I am always importing the Nuget files at the top of my workbook, I did not need to have the docker deamon add a nuget config. So I commented out the COPY command &lt;code&gt;# COPY ./NuGet.config ${HOME}/nuget.config&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;I commented out the custom &lt;code&gt;--add-source &amp;quot;https://dotnet.myget.org/F/dotnet-try/api/v3/index.json&amp;quot;&lt;/code&gt; from the installation of the dotnet try tool, since I had issue with the nuget feed with the pre-release version. Installing with &lt;code&gt;RUN dotnet tool install -g dotnet-try&lt;/code&gt; will get you the latest released version.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class="language-Skip"&gt;FROM jupyter/scipy-notebook:45f07a14b422

# Install .NET CLI dependencies

ARG NB_USER=jovyan
ARG NB_UID=1000
ENV USER ${NB_USER}
ENV NB_UID ${NB_UID}
ENV HOME /home/${NB_USER}

WORKDIR ${HOME}

USER root
RUN apt-get update
RUN apt-get install -y curl

# Install .NET CLI dependencies
RUN apt-get install -y --no-install-recommends \
        libc6 \
        libgcc1 \
        libgssapi-krb5-2 \
        libicu60 \
        libssl1.1 \
        libstdc++6 \
        zlib1g 

RUN rm -rf /var/lib/apt/lists/*

# Install .NET Core SDK
ENV DOTNET_SDK_VERSION 3.0.100

RUN curl -SL --output dotnet.tar.gz https://dotnetcli.blob.core.windows.net/dotnet/Sdk/$DOTNET_SDK_VERSION/dotnet-sdk-$DOTNET_SDK_VERSION-linux-x64.tar.gz \
    &amp;amp;&amp;amp; dotnet_sha512='766da31f9a0bcfbf0f12c91ea68354eb509ac2111879d55b656f19299c6ea1c005d31460dac7c2a4ef82b3edfea30232c82ba301fb52c0ff268d3e3a1b73d8f7' \
    &amp;amp;&amp;amp; echo &amp;quot;$dotnet_sha512 dotnet.tar.gz&amp;quot; | sha512sum -c - \
    &amp;amp;&amp;amp; mkdir -p /usr/share/dotnet \
    &amp;amp;&amp;amp; tar -zxf dotnet.tar.gz -C /usr/share/dotnet \
    &amp;amp;&amp;amp; rm dotnet.tar.gz \
    &amp;amp;&amp;amp; ln -s /usr/share/dotnet/dotnet /usr/bin/dotnet

# Enable detection of running in a container
ENV DOTNET_RUNNING_IN_CONTAINER=true \
    # Enable correct mode for dotnet watch (only mode supported in a container)
    DOTNET_USE_POLLING_FILE_WATCHER=true \
    # Skip extraction of XML docs - generally not useful within an image/container - helps performance
    NUGET_XMLDOC_MODE=skip \
    # Opt out of telemetry until after we install jupyter when building the image, this prevents caching of machine id
    DOTNET_TRY_CLI_TELEMETRY_OPTOUT=true

# Trigger first run experience by running arbitrary cmd
RUN dotnet help

# Copy notebooks

COPY . ${HOME}/Notebooks/

# Copy package sources

# COPY ./NuGet.config ${HOME}/nuget.config

RUN chown -R ${NB_UID} ${HOME}
USER ${USER}

# Install Microsoft.DotNet.Interactive
RUN dotnet tool install -g dotnet-try 
#--add-source &amp;quot;https://dotnet.myget.org/F/dotnet-try/api/v3/index.json&amp;quot;

ENV PATH=&amp;quot;${PATH}:${HOME}/.dotnet/tools&amp;quot;
RUN echo &amp;quot;$PATH&amp;quot;

# Install kernel specs
RUN dotnet try jupyter install

# Enable telemetry once we install jupyter for the image
ENV DOTNET_TRY_CLI_TELEMETRY_OPTOUT=false

# Set root to Notebooks
WORKDIR ${HOME}/Notebooks/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the Dockerfile is in the repository. Head over to &lt;a href="https://mybinder.org/"&gt;MyBinder.org&lt;/a&gt; and enter the link to your repository. Optionally, you can set an initial ipynb file to start when the link is clicked.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/my-binder/Binder-1.png" class="img-fluid" alt="MyBinder" /&gt;&lt;/p&gt;
&lt;p&gt;When you click &amp;quot;launch&amp;quot;, MyBinder will download your repository and start the docker build, very soon you will be able to access your binders online. Fully shareable and totally awesome!&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/my-binder/Binder-2.png" class="img-fluid" width="60%" alt="SQLite Running" /&gt;&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Introduction to linear programming with C# and OR-Tools inside Jupyter</title>
			<link>http://ewinnington.github.io/posts/jupyter-lp-10</link>
			<description>&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=IntroToLP.ipynb"&gt;&lt;img src="https://mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder"&gt;&lt;/a&gt;&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/jupyter-lp-10</guid>
			<pubDate>Thu, 14 Nov 2019 21:30:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=IntroToLP.ipynb"&gt;&lt;img src="https://mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="linear-programming"&gt;Linear programming&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Linear_programming"&gt;Linear programming&lt;/a&gt; (LP) is a method to provide an optimal solution to a problem defined by a set of linear constraints. It is very widely applied in engineering and science.&lt;/p&gt;
&lt;p&gt;A typical linear programming problem is defined by an Objective function (the target to maximise or minimise) and a set of constraints which limit the solution space.&lt;/p&gt;
&lt;h2 id="what-does-an-lp-problem-look-like"&gt;What does an LP problem look like?&lt;/h2&gt;
&lt;p&gt;We are going to start with a very simple linear problem definition. The first line of the problem describes the objective function, in this the value to maximize. In this problem, we have two variables to optimize x and y. The constraints that limit the problem's space are defined under the subject to section.&lt;/p&gt;
&lt;div class="math"&gt;
\[
\begin{aligned}
\max (2y+x) \\
\text{subject to:} \\
\qquad x \leq 15 \\
\qquad y \leq 8 
\end{aligned}
\]&lt;/div&gt;
&lt;p&gt;This very simple maximisation problem has a maximum solution of &lt;span class="math"&gt;\(x=15\)&lt;/span&gt; and &lt;span class="math"&gt;\(y=8\)&lt;/span&gt; for an objective value of &lt;span class="math"&gt;\(31\)&lt;/span&gt; .&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/A1.png" class="img-fluid" width="100%" alt="A1" /&gt;&lt;/p&gt;
&lt;p&gt;There exist many linear programming solvers to calculate this optimum. We will be using &lt;a href="https://github.com/coin-or/Clp"&gt;Coin-OR project CLP&lt;/a&gt; with the &lt;a href="https://developers.google.com/optimization"&gt;Google OR-Tools&lt;/a&gt; as an interface for C#.&lt;/p&gt;
&lt;h2 id="meet-the-solver"&gt;Meet the solver&lt;/h2&gt;
&lt;p&gt;You can find my &lt;a href="https://github.com/ewinnington/noteb/blob/master/IntroToLP.ipynb"&gt;notebook with all the code here&lt;/a&gt;. And you can now access the &lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=IntroToLP.ipynb"&gt;Jupyter notebooks online, thanks to Binder&lt;/a&gt;!&lt;/p&gt;
&lt;h3 id="coin-or-clp-with-google-or-tools"&gt;Coin-OR&lt;a id="fnref:1" href="#fn:1" class="footnote-ref"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; CLP (with Google OR&lt;a id="fnref:2" href="#fn:1" class="footnote-ref"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;-Tools)&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://www.coin-or.org"&gt;Coin-OR project&lt;/a&gt; provides high quality solvers for many applications with an open source license. &lt;a href="https://github.com/coin-or/Clp"&gt;CLP&lt;/a&gt; is the main linear programming solver we will be using until we start adding binary variables, at which point we will start using &lt;a href="https://github.com/coin-or/Cbc"&gt;CBC&lt;/a&gt;. To call them from C#, we could write out a format that CLP / CBC knows how to read, such as &lt;a href="https://en.wikipedia.org/wiki/MPS_(format)"&gt;MPS&lt;/a&gt; or we could use a wrapping library to call them directly from C#. We will be focusing on using the Google OR-Tools.&lt;/p&gt;
&lt;h4 id="google-or-tools"&gt;Google OR-Tools&lt;/h4&gt;
&lt;p&gt;The &lt;a href="https://developers.google.com/optimization/"&gt;Google OR-Tools&lt;/a&gt; provide us with a set of primitives with which to work with so that we can define optimisation problems and allow us to call to various solvers, including CLP, which we will be using. Also the OR-Tools provide routines to write out the problems in MPS and other formats. We will focus on using the OR Tools as soon as the introduction is over.&lt;/p&gt;
&lt;p&gt;Adding the Google OR Tools through nuget to the Jupyter notebook with the &lt;code&gt;#r&lt;/code&gt; command and &lt;code&gt;using&lt;/code&gt; in the cell imports the solver.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;#r &amp;quot;nuget:Google.OrTools&amp;quot;

using Google.OrTools.LinearSolver;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/10-1.png" class="img-fluid" alt="10-1.png" /&gt;&lt;/p&gt;
&lt;p&gt;This allows us to create a solver instance as follows, note the constant &lt;code&gt;CLP_LINEAR_PROGRAMMING&lt;/code&gt; this tells us which solver we will be using.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;Solver solver = Solver.CreateSolver(&amp;quot;LinearProgramming&amp;quot;, &amp;quot;CLP_LINEAR_PROGRAMMING&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following code snippet implements the linear program formulation below&lt;a id="fnref:3" href="#fn:2" class="footnote-ref"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class="math"&gt;
\[
\begin{aligned}
\max (2y+x) \\
\text{subject to:} \\
\qquad x \leq 15 \\
\qquad y \leq 8 
\end{aligned}
\]&lt;/div&gt;
&lt;p&gt;The solver has been already defined and initalized. We are now defining the variables of the problem, the objective function and the linear constraints that apply.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;Variable x = solver.MakeNumVar(0.0, double.PositiveInfinity, &amp;quot;x&amp;quot;);
Variable y = solver.MakeNumVar(0.0, double.PositiveInfinity, &amp;quot;y&amp;quot;);

// Maximize 2*y+x.
Objective objective = solver.Objective();
objective.SetCoefficient(x, 1);
objective.SetCoefficient(y, 2);
objective.SetMaximization();

// 0 &amp;lt;= x &amp;lt;= 15 
Constraint c0 = solver.MakeConstraint(0, 15);
c0.SetCoefficient(x, 1);

// 0 &amp;lt;= y &amp;lt;= 8
Constraint c1 = solver.MakeConstraint(0, 8);
c1.SetCoefficient(y, 1);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/10-2.png" class="img-fluid" alt="10-2.png" /&gt;&lt;/p&gt;
&lt;p&gt;When you execute the next cells, the solver.Solve() function is called and the results will be written out to the cell's output. We will use this function cell several times over the course of the workbook.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;public void SolveProblem() {
    var resultStatus = solver.Solve();

    // Check that the problem has an optimal solution.
    if (resultStatus != Solver.ResultStatus.OPTIMAL)
    {
        Console.WriteLine(&amp;quot;The problem does not have an optimal solution!&amp;quot;);
        return;
    }

    Console.WriteLine(&amp;quot;Problem solved in &amp;quot; + solver.WallTime() + &amp;quot; milliseconds&amp;quot;);

    // The objective value of the solution.
    Console.WriteLine(&amp;quot;Optimal objective value = &amp;quot; + solver.Objective().Value());

    // The value of each variable in the solution.
    foreach (var v in solver.variables())
    { Console.WriteLine($&amp;quot;{v.Name()} : {v.SolutionValue()} &amp;quot;); };
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/10-3.png" class="img-fluid" alt="10-3.png" /&gt;&lt;/p&gt;
&lt;h3 id="other-solvers"&gt;Other solvers&lt;/h3&gt;
&lt;p&gt;There exists many other solvers that are available, either directly wrapped through the Google OR Tools such as GLOP or another library or as external programs fed through input files in MPS or other formats. The &lt;a href="https://neos-server.org/neos/"&gt;NEOS project&lt;/a&gt; provides a thorough set of optimisation solvers that are available online with many input formats available (MPS, AMPL, Lp, GAMS).&lt;/p&gt;
&lt;h2 id="problem-2"&gt;Problem 2&lt;/h2&gt;
&lt;p&gt;We will be adding a third constraint to the formulation of Problem 1.&lt;/p&gt;
&lt;div class="math"&gt;
\[
\begin{aligned}
\text{Obj:} \max(2y+x)
\\ \text{subject to:} \quad x \leq 15
\\ \qquad \quad \quad \quad y \leq 8
\\ \quad \quad \quad x+y \leq 18
\end{aligned}
\]&lt;/div&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/A2.png" class="img-fluid" width="100%" alt="A2" /&gt;&lt;/p&gt;
&lt;p&gt;The solver is initialized with the full problem 1 defintion already, x and y are already declared. When you click run on the solver's cell, the solver.Solve() function is called and results are written out.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;Constraint c = solver.MakeConstraint(0, 18);
c.SetCoefficient(x, 1);
c.SetCoefficient(y, 1);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you call &lt;code&gt;SolveProblem();&lt;/code&gt;, you will now have a new optimal value that is lower that the previous one. In linear programming maximization problem, adding a new constraint will always make the optimal value lower or equal to the less constrained. problem&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/10-4.png" class="img-fluid" alt="10-4.png" /&gt;&lt;/p&gt;
&lt;h2 id="problem-3"&gt;Problem 3&lt;/h2&gt;
&lt;p&gt;You should now be able to add an adding a fourth constraint to the formulation of Problem 2.&lt;/p&gt;
&lt;div class="math"&gt;
\[
\begin{aligned}
\text{Obj:} \max(2y+x)
\\ \text{subject to:} \qquad x \leq 15
\\ \qquad \quad y \leq 8
\\ \quad x+y \leq 18
\\ -\frac{1}{3}x+y \leq 2
\end{aligned}
\]&lt;/div&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/A3.png" class="img-fluid" width="100%" alt="A3" /&gt;&lt;/p&gt;
&lt;p&gt;The solver is initialized with the full problem 2 defintion already, x and y are already declared. When you click on the solver's cell, the solver.Solve() function is called and results are written out.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/10-5.png" class="img-fluid" width="100%" alt="10-5.png" /&gt;&lt;/p&gt;
&lt;p&gt;For those following along in the &lt;a href="https://github.com/ewinnington/noteb/blob/master/IntroToLP.ipynb"&gt;notebook&lt;/a&gt; there is a hint below this section with a second implementation of the &lt;code&gt;SolveProblem()&lt;/code&gt; function which should give you hints based on your objective value.&lt;/p&gt;
&lt;h2 id="the-power-of-jupyter-special-commands"&gt;The power of Jupyter special commands&lt;/h2&gt;
&lt;p&gt;I'm discovering slowly the jupyter commands. The first command &lt;code&gt;display()&lt;/code&gt; allows you to present objects in a table. A great way to select the properties you want to show is to use linq (remember to add &lt;code&gt;using System.Linq&lt;/code&gt;) to map a list of objects to an anonymous object with the properties you want to show in the table.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;display(solver.variables().Select(a =&amp;gt; new { Name  = a.Name(), Value = a.SolutionValue() }));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="/posts/images/lp/10-6.png" class="img-fluid" width="100%" alt="10-6.png" /&gt;&lt;/p&gt;
&lt;h2 id="recap"&gt;Recap&lt;/h2&gt;
&lt;p&gt;Now that we have introduced linear programming and know how to use the solver, the following chapter will cover two simple linear programming applications.&lt;/p&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;OR here refers to &lt;a href="https://en.wikipedia.org/wiki/Operations_research"&gt;Operational Research&lt;/a&gt; - the field of mathematics dedicated to the search for optimal or near optimal solutions to problems.&lt;a href="#fnref:1" class="footnote-back-ref"&gt;&amp;#8617;&lt;/a&gt;&lt;a href="#fnref:2" class="footnote-back-ref"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;For those using &lt;a href="/posts/Switching-to-wyam"&gt;Wyam to generate their blogs&lt;/a&gt;, you can add the&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-HTML"&gt;&amp;lt;script type=&amp;quot;text/javascript&amp;quot; id=&amp;quot;MathJax-script&amp;quot; async
src=&amp;quot;https://cdn.jsdelivr.net/npm/mathjax&amp;#64;3/es5/tex-mml-chtml.js&amp;quot;&amp;gt;
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to your &lt;code&gt;_Head.cshtml&lt;/code&gt; template page. I recommend checking out &lt;a href="https://www.mathjax.org/"&gt;MathJax&lt;/a&gt; for the latest &lt;a href="http://docs.mathjax.org/en/latest/web/start.html#using-mathjax-from-a-content-delivery-network-cdn"&gt;CDN&lt;/a&gt;.&lt;a href="#fnref:3" class="footnote-back-ref"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</content:encoded>
		</item>
		<item>
			<title>Docker controlled from Jupyter Notebook C# with PostgresDB</title>
			<link>http://ewinnington.github.io/posts/jupyter-docker-csharp-postgres</link>
			<description>&lt;p&gt;In the context of Docker and Jupyter Notebook, it's interesting to note that there exists a Nuget that allows C# to control docker. So, yes, it is possible to launch a Postgresql database, on docker, inside a Jupyter notebook!&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/jupyter-docker-csharp-postgres</guid>
			<pubDate>Tue, 12 Nov 2019 23:18:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;In the context of Docker and Jupyter Notebook, it's interesting to note that there exists a Nuget that allows C# to control docker. So, yes, it is possible to launch a Postgresql database, on docker, inside a Jupyter notebook!&lt;/p&gt;
&lt;p&gt;This assumes you have &lt;a href="https://hub.docker.com/?overlay=onboarding"&gt;Docker&lt;/a&gt;, &lt;a href="https://github.com/dotnet/try/blob/master/DotNetTryLocal.md"&gt;Dotnet try&lt;/a&gt;, &lt;a href="https://jupyter.org/"&gt;Jupyter notebook&lt;/a&gt; and follow the setup of the &lt;a href="/posts/jupyter-notebook-csharp-r"&gt;C# kernel for Jupyter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you don't want to wait, you can find my &lt;a href="https://github.com/ewinnington/noteb/blob/master/DockerInteraction.ipynb"&gt;complete notebook here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Microsoft has created a &lt;a href="https://github.com/microsoft/Docker.DotNet"&gt;C# Client library for talking to Docker&lt;/a&gt;, so we will be taking advantage of it. Much of the magic docker code is pulled from the Docker.DotNet repository.
I'm using the &lt;a href="https://www.npgsql.org/index.html"&gt;Npgsql drivers&lt;/a&gt; for accessing the PostgreSQL database.
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-01.png" class="img-fluid" alt="pgsql01" /&gt;&lt;/p&gt;
&lt;p&gt;The real magic moment is when you access the Docker instance, if it is on your local machine on windows, you can use the &lt;code&gt;npipe://./pipe/docker_engine&lt;/code&gt; Uri. If you are on Linux, use &lt;code&gt;unix:///var/run/docker.sock&lt;/code&gt; (at this time, I haven't tried it on linux, but if you do, please tell me).
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-02.png" class="img-fluid" alt="pgsql02" /&gt;&lt;/p&gt;
&lt;p&gt;In block 3, we select a random port to host the pgSQL database. Then list the local image names that are available (you should get postgres:latest on your machine to run this). We create and start up the container, passing the environment variables for the password, user and initial schema. Once the container is started, we detach ourselves from it, so it runs in the background. Finally, I wait until I'm pretty sure the container and database is ready (10s sleep at the end). You can reduce that sleep time. On my Surface laptop 1, I sometimes have an issue when I've got too many other containers running.
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-03.png" class="img-fluid" alt="pgsql03" /&gt;&lt;/p&gt;
&lt;p&gt;I'm connecting to the database and validating the connection name.
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-04.png" class="img-fluid" alt="pgsql04" /&gt;&lt;/p&gt;
&lt;p&gt;I'm creating a database schema and a user for this particular schema, then reconning with the new user.
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-05.png" class="img-fluid" alt="pgsql05" /&gt;&lt;/p&gt;
&lt;p&gt;Creating a table and inserting two rows using direct strings and string concatenation. In production, you should never be using string concatenation for your SQL statements. Please always use Bound variables as described below.
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-06.png" class="img-fluid" alt="pgsql06" /&gt;&lt;/p&gt;
&lt;p&gt;This is how you should interact with the PostgreSQL database if you are using direct SQL statements. You should be using Bound commands with parameters.
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-07.png" class="img-fluid" alt="pgsql07" /&gt;&lt;/p&gt;
&lt;p&gt;Finally, I check that all three insertions were successful.
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-08.png" class="img-fluid" alt="pgsql08" /&gt;&lt;/p&gt;
&lt;p&gt;You can watch the container run in the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker"&gt;docker extension&lt;/a&gt; of &lt;a href="https://code.visualstudio.com/"&gt;Visual studio Code&lt;/a&gt;. It's a great way of monitoring what is currently running, as well as deleting old containers that might be still present.
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-10.png" class="img-fluid" alt="pgsql10" /&gt;&lt;/p&gt;
&lt;p&gt;Talking of deleting old containers, this is how you shut them down and delete them at the end of the notebook. I first close the Db connection and dispose of it before asking Docker.DotNet to stop the containers.
&lt;img src="/posts/images/jupyter-notebook-csharp-r/docker-pg-09.png" class="img-fluid" alt="pgsql09" /&gt;&lt;/p&gt;
&lt;p&gt;It would be cleaner if I knew how to enfore a &lt;code&gt;Finally&lt;/code&gt; in Jupyter Notebook, but at this time, I don't know. If you do, drop me a line on &lt;a href="https://twitter.com/ThrowATwit"&gt;twitter&lt;/a&gt; or a pull request on this blog post.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Testing SQLite in C# Jupyter notebook</title>
			<link>http://ewinnington.github.io/posts/jupyter-sqlite-csharp</link>
			<description>&lt;p&gt;Now that we have &lt;a href="/posts/jupyter-notebook-csharp-r"&gt;Jupyter Notebooks with C# installed&lt;/a&gt;, using it as an environment to play with SQLite is very easy. &lt;a href="https://www.sqlite.org/index.html"&gt;SQLite&lt;/a&gt; is a relational database that is small in footprint and self-contained. It also has a great in-memory mode which is perfect for playing around in a Jupyter notebook.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/jupyter-sqlite-csharp</guid>
			<pubDate>Tue, 12 Nov 2019 20:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Now that we have &lt;a href="/posts/jupyter-notebook-csharp-r"&gt;Jupyter Notebooks with C# installed&lt;/a&gt;, using it as an environment to play with SQLite is very easy. &lt;a href="https://www.sqlite.org/index.html"&gt;SQLite&lt;/a&gt; is a relational database that is small in footprint and self-contained. It also has a great in-memory mode which is perfect for playing around in a Jupyter notebook.&lt;/p&gt;
&lt;p&gt;You can access my &lt;a href="https://github.com/ewinnington/noteb/blob/master/SqliteInteraction.ipynb"&gt;SQLite example notebook here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can now launch this online and follow along:
&lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=SqliteInteraction.ipynb"&gt;&lt;img src="https://mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can create a C# Notebook from the file menu of Jupyter.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/new-notebook.png" class="img-fluid" alt="new-notebook" /&gt;&lt;/p&gt;
&lt;p&gt;We need to pull in the nuget package &lt;code&gt;System.Data.SQLite&lt;/code&gt; to interact with the database.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;#r &amp;quot;nuget:System.Data.SQLite&amp;quot;
using System.Data.SQLite;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;#r&lt;/code&gt; is used to reference a dll or a nuget package. If you prefix the command with &amp;quot;nuget:&amp;quot; then the jupyter notebook will download the nuget and add it as a reference. Then as in usual c#, you must reference it.&lt;/p&gt;
&lt;p&gt;When you run this cell, you should see the following output:&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/sqlite01.png" class="img-fluid" alt="sqlite01" /&gt;&lt;/p&gt;
&lt;p&gt;We can then create a connection to an in-memory SQLite database.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;SQLiteConnection conn;

conn = new SQLiteConnection(&amp;quot;Data Source=:memory:;Version=3;New=True;&amp;quot;);

try
{
conn.Open();
}
catch (Exception ex)
{
Console.WriteLine(ex); 
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating two identical tables &lt;em&gt;SampleTable&lt;/em&gt; and &lt;em&gt;SampleTable1&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;using (SQLiteCommand sqlite_cmd = conn.CreateCommand()) {
    string Createsql = &amp;quot;CREATE TABLE SampleTable(Col1 VARCHAR(20), Col2 INT)&amp;quot;;
    string Createsql1 = &amp;quot;CREATE TABLE SampleTable1(Col1 VARCHAR(20), Col2 INT)&amp;quot;;
    sqlite_cmd.CommandText = Createsql;
    sqlite_cmd.ExecuteNonQuery();
    sqlite_cmd.CommandText = Createsql1;
    sqlite_cmd.ExecuteNonQuery();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Inserting a set of data into these tables.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;using (SQLiteCommand sqlite_cmd = conn.CreateCommand()) {
    sqlite_cmd.CommandText = &amp;quot;INSERT INTO SampleTable(Col1, Col2) VALUES ('Test Text ', 1);&amp;quot;;
    sqlite_cmd.ExecuteNonQuery();
    sqlite_cmd.CommandText = &amp;quot;INSERT INTO SampleTable(Col1, Col2) VALUES ('Test1 Text1 ', 2);&amp;quot;;
    sqlite_cmd.ExecuteNonQuery();
    sqlite_cmd.CommandText = &amp;quot;INSERT INTO SampleTable(Col1, Col2) VALUES ('Test2 Text2 ', 3);&amp;quot;;
    sqlite_cmd.ExecuteNonQuery();
    sqlite_cmd.CommandText = &amp;quot;INSERT INTO SampleTable1(Col1, Col2) VALUES ('Test3 Text3 ', 3);&amp;quot;;
    sqlite_cmd.ExecuteNonQuery();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reading from &lt;em&gt;SampleTable&lt;/em&gt; to verify the insertions went through correctly.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;using (SQLiteCommand sqlite_cmd = conn.CreateCommand()) {
    sqlite_cmd.CommandText = &amp;quot;SELECT * FROM SampleTable&amp;quot;;

    using(var sqlite_datareader = sqlite_cmd.ExecuteReader()){
        while (sqlite_datareader.Read())
        {
        string myreader = sqlite_datareader.GetString(0);
        Console.WriteLine(myreader);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you executed the whole workbook up to now, you should have the following output.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/sqlite05.png" class="img-fluid" alt="sqlite05" /&gt;&lt;/p&gt;
&lt;p&gt;Closing the connection to the databse.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conn.Close();
&lt;/code&gt;&lt;/pre&gt;
</content:encoded>
		</item>
		<item>
			<title>Jupyter notebook with C# and R</title>
			<link>http://ewinnington.github.io/posts/jupyter-notebook-csharp-r</link>
			<description>&lt;p&gt;Following the release of the &lt;a href="https://devblogs.microsoft.com/dotnet/net-core-with-juypter-notebooks-is-here-preview-1/"&gt;updated dotnet try tool&lt;/a&gt;, here are my instructions for getting started.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/jupyter-notebook-csharp-r</guid>
			<pubDate>Tue, 12 Nov 2019 19:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Following the release of the &lt;a href="https://devblogs.microsoft.com/dotnet/net-core-with-juypter-notebooks-is-here-preview-1/"&gt;updated dotnet try tool&lt;/a&gt;, here are my instructions for getting started.&lt;/p&gt;
&lt;h1 id="installing-jupyter-notebook-with-a-c-kernel"&gt;Installing jupyter notebook with a c# kernel&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Check if you installed python with visual studio.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Go to the start menu and start typing Python&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/python_installed.png" class="img-fluid" :height="360px" width="620px" alt="img1" /&gt;&lt;/p&gt;
&lt;p&gt;Right click on python and follow the Open File Location until you find the place where python is installed.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/python_installed_location.png" class="img-fluid" :height="360px" width="620px" alt="img2" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Or type: &lt;code&gt;where python&lt;/code&gt; in the command line.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If so, add python to the PATH of your environment. On my installation, the paths to Python were as follows. I had to add the Scripts path for the pip installation to be in the command line.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\Scripts&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;install jupyter using pip which was installed with visual studio, make sure to run in an &lt;strong&gt;administrator&lt;/strong&gt; shell
&lt;code&gt;pip install jupyter&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now get the list of installed jupyter kernels:
&lt;code&gt;jupyter kernelspec list&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;Available kernels:
  c:\program files (x86)\microsoft visual studio\shared\python37_64\share\jupyter\kernels\python3  
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Install the latest version of .net try
&lt;code&gt;dotnet tool install dotnet-try -g&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;finally install the .net kernel for jupyter with the command:
&lt;code&gt;dotnet try jupyter install&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;test the kernel is now installed with &lt;code&gt;jupyter kernelspec list&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/jupyter_kernels.png" class="img-fluid" alt="img3" /&gt;&lt;/p&gt;
&lt;h1 id="launch-jupyter-notebook"&gt;launch jupyter notebook&lt;/h1&gt;
&lt;p&gt;In the command line, type:
&lt;code&gt;jupyter notebook&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;A browser window should open and the terminal should display:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\Repos\noteb&amp;gt;jupyter notebook
[I 22:14:55.617 NotebookApp] JupyterLab extension loaded from c:\program files (x86)\microsoft visual studio\shared\python37_64\lib\site-packages\jupyterlab
[I 22:14:55.618 NotebookApp] JupyterLab application directory is c:\program files (x86)\microsoft visual studio\shared\python37_64\share\jupyter\lab
[I 22:14:55.625 NotebookApp] Serving notebooks from local directory: C:\Repos\noteb
[I 22:14:55.626 NotebookApp] The Jupyter Notebook is running at:
[I 22:14:55.627 NotebookApp] http://localhost:8888/?token=XXXXXXXXXXXXXXXXXXXc1ee1dfccc0a6624263d584b8ca4c
[I 22:14:55.628 NotebookApp]  or http://127.0.0.1:8888/?token=XXXXXXXXXXXXXXXXXXXc1ee1dfccc0a6624263d584b8ca4c
[I 22:14:55.629 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).  [C 22:14:55.737 NotebookApp]

    To access the notebook, open this file in a browser:
        file:///C:/Users/xxxxxx/AppData/Roaming/jupyter/runtime/nbserver-17608-open.html
    Or copy and paste one of these URLs:
        http://localhost:8888/?token=XXXXXXXXXXXXXXXXXXXc1ee1dfccc0a6624263d584b8ca4c
     or http://127.0.0.1:8888/?token=XXXXXXXXXXXXXXXXXXXc1ee1dfccc0a6624263d584b8ca4c
[I 22:15:16.852 NotebookApp] Kernel started: be6910a0-92f0-4ec0-a26c-d8274b44cd6d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main page of the Jupyter notebook allows you to see the notebooks available in the folder and to create new ones.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/jupyter_create_csharp.png" class="img-fluid" :height="360px" width="620px" alt="img4" /&gt;&lt;/p&gt;
&lt;h1 id="hello-world"&gt;Hello world&lt;/h1&gt;
&lt;p&gt;Create a new C# notebook. Then type&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using System; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in the first cell. I executed it and then typed:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;Console.WriteLine(&amp;quot;Hello World&amp;quot;); 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in the second cell. Executing it shows us that the C# Kernel is working.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/jupyter_hello_world_csharp.png" class="img-fluid" :height="360px" width="620px" alt="imgHello" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;#r&lt;/code&gt; is used to reference a dll or a nuget package. If you prefix the command with &amp;quot;nuget:&amp;quot; then the jupyter notebook will download the nuget and add it as a reference. Then as in usual c#, you must reference it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt; The C# notebook is now hosted on binder &lt;a href="https://mybinder.org/v2/gh/ewinnington/noteb/master?filepath=HelloWorld.ipynb"&gt;&lt;img src="https://mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder" /&gt;&lt;/a&gt;
click to launch the environment!&lt;/p&gt;
&lt;h1 id="installing-an-r-kernel-for-jupyter-notebook"&gt;Installing an R kernel for jupyter notebook&lt;/h1&gt;
&lt;p&gt;To install R Tools for Visual Studio, install the Visual Studio Extension R Tools for Visual Studio 2019, which was in preview when I looked. Once this is installed, you must install the Microsoft R client. This option will be presented if you go to the &amp;quot;R Interactive&amp;quot; window.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/install_R_vs.png" class="img-fluid" :height="360px" width="620px" alt="img5" /&gt;&lt;/p&gt;
&lt;p&gt;I have R installed with visual studio, so I launched visual studio in &lt;strong&gt;admin mode&lt;/strong&gt; to be able to have my R directory writable, went to the R Tools menu at the top and selected &amp;quot;R Interactive&amp;quot;.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/r_interactive_vs.png" class="img-fluid" alt="img6" /&gt;&lt;/p&gt;
&lt;p&gt;From the command line of R, I typed in the following commands. &lt;a href="https://irkernel.github.io/installation/"&gt;Installation guide R&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/r_interactive_kernel_install.png" class="img-fluid" alt="img6" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-R"&gt;install.packages('IRkernel')
IRkernel::installspec(user = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I got the following output after installing the IRKernel into Jupyter &lt;code&gt;[InstallKernelSpec] Installed kernelspec ir in C:\ProgramData\jupyter\kernels\ir&lt;/code&gt;. Following this, you can check on the command line that the R kernel appears in the list of Jupyter Kernels with &lt;code&gt;jupyter kernelspec list&lt;/code&gt;, this should show the ir kernel installed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Available kernels:
  ir             C:\ProgramData\jupyter\kernels\ir
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="use-r-to-show-a-some-math"&gt;Use R to show a some math&lt;/h2&gt;
&lt;p&gt;Create a new R notebook and type in the first cell:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-R"&gt;demo(plotmath)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Executing this should show you the following long list of tables with mathematical symbols.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/jupyter_R.png" class="img-fluid" :height="360px" width="620px" alt="img7" /&gt;&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Using bulk inserts on databases</title>
			<link>http://ewinnington.github.io/posts/bulk-inserts</link>
			<description>&lt;p&gt;When inserting large amounts of data into databases, you should consider using the bulk functions instead of running single row INSERT commands. Single row INSERT command will usually lead to poor performance. There exists two main techniques for mutiple row insertions in databases from code and several more if you use the loader tools that accompany the database. Here I'll detail the two main methods: BulkInserts and VectorInserts.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/bulk-inserts</guid>
			<pubDate>Mon, 11 Nov 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;When inserting large amounts of data into databases, you should consider using the bulk functions instead of running single row INSERT commands. Single row INSERT command will usually lead to poor performance. There exists two main techniques for mutiple row insertions in databases from code and several more if you use the loader tools that accompany the database. Here I'll detail the two main methods: BulkInserts and VectorInserts.&lt;/p&gt;
&lt;h1 id="bulk-inserts-for-oracle-mssql-postgresql"&gt;Bulk Inserts for Oracle, MSSQL, Postgresql&lt;/h1&gt;
&lt;p&gt;For the examples, it is assumed that there exists an object Timeseries ts with a field IEnumerable TimeseriesData that contains Datapoints. A Datapoint has a DateTime field named t and a Decimal field named value.&lt;/p&gt;
&lt;h2 id="datatable-to-database"&gt;Datatable to Database&lt;/h2&gt;
&lt;p&gt;We setup a DataTable in memory and fill it with the data we need to insert.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;DataTable dt = new DataTable();
dt.Columns.Add(&amp;quot;IDTIMESERIES&amp;quot;, typeof(int));
dt.Columns.Add(&amp;quot;TIMEPOINT&amp;quot;, typeof(DateTime));
dt.Columns.Add(&amp;quot;VALUE1&amp;quot;, typeof(decimal));

int nRowsMaxDt = 0;
//ts being a timeseries object that contains a IEnumberable TimeSeriesData of sp (single points) 
foreach (var sp in ts.TimeSeriesData)
{
	object[] oRowDt = new object[3];
	oRowDt[0] = ts.Id; oRowDt[1] = sp.t; oRowDt[2] = (decimal)sp.value; 
	dt.Rows.Add(oRowDt); nRowsMaxDt = nRowsMaxDt + 1;
}
DumpDataTableToDB(&amp;quot;DATATIMESERIES&amp;quot;, dt, nRowsMaxDt);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The DumpDataTableToDB function is then written on a per database basis. Below you will find my examples for OracleDb, MSSQL and Postgres.&lt;/p&gt;
&lt;h3 id="oracle"&gt;Oracle:&lt;/h3&gt;
&lt;p&gt;Oracle has two sets of drivers, the Unmanaged and the Managed drivers. Your usings will be different per package.&lt;/p&gt;
&lt;p&gt;With ODP.NET Unmanaged (Drivers installed seperately - you will need to add the references manually)&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using Oracle.DataAccess.Client;
using Oracle.DataAccess.Types;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With ODP.NET Managed (Nuget Installed &lt;a href="https://www.nuget.org/packages/Oracle.ManagedDataAccess/"&gt;https://www.nuget.org/packages/Oracle.ManagedDataAccess/&lt;/a&gt; )&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using Oracle.ManagedDataAccess.Client;
using Oracle.ManagedDataAccess.Types;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use the OracleBulkCopy function with Con being an open connection to the database (OracleConnection).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;public void DumpDataTableToDB(string TableName, DataTable dt, int nCount)
{
	using (OracleBulkCopy obc = new OracleBulkCopy(Con))
	{
		obc.BatchSize = nCount;
		obc.DestinationTableName = TableName;
		obc.WriteToServer(dt);
		obc.Close();
	}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This method works, but I had issues with Oracle DataGuard. So for Oracle, I do recommend using the Vectorized data insert presented below with Oracle ArrayBind.&lt;/p&gt;
&lt;h3 id="ms-sql-server"&gt;MS SQL Server&lt;/h3&gt;
&lt;p&gt;The Microsoft SQL server uses SqlBulkCopy to connect and import the data. Again here the Con represents an open connection to the database.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using System.Data;
using System.Data.Common;
using System.Data.SqlClient;

public void DumpDataTableToDB(string TableName, DataTable dt, int nCount)
{
using (SqlBulkCopy bulkCopy = new SqlBulkCopy(((SqlConnection)Con).ConnectionString, SqlBulkCopyOptions.KeepNulls))
            {
                foreach (System.Data.DataColumn col in dt.Columns)
                {
                    bulkCopy.ColumnMappings.Add(col.ColumnName, col.ColumnName);
                }
                bulkCopy.DestinationTableName = TableName;
                bulkCopy.WriteToServer(dt);
            }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="postgresql"&gt;Postgresql&lt;/h3&gt;
&lt;p&gt;In Postgresql, the important part to note is the COPY ... FROM command. This allows you to provide either a file located on the DB Server or data from STDIN, passed from the client. The Format specifier allows for binary, which we are using here or text and csv. Note, the csv format is very picky, try the text format first if you are doing imports.&lt;/p&gt;
&lt;p&gt;As usual the Con represents an open database connection.&lt;/p&gt;
&lt;p&gt;You can see the implementation of this running &lt;a href="https://github.com/ewinnington/noteb/blob/master/PgBulkInsert.ipynb"&gt;in the Jupyiter notebook with C#&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using Npgsql; // Nuget https://www.nuget.org/packages/Npgsql 

public void DumpDataTableToDB(string TableName, DataTable dt, int nCount)
{
Dictionary&amp;lt;Type, NpgsqlTypes.NpgsqlDbType&amp;gt; TypeDict = new Dictionary&amp;lt;Type, NpgsqlTypes.NpgsqlDbType&amp;gt;();

            TypeDict.Add(typeof(int), NpgsqlTypes.NpgsqlDbType.Integer);
            TypeDict.Add(typeof(double), NpgsqlTypes.NpgsqlDbType.Double);
            TypeDict.Add(typeof(decimal), NpgsqlTypes.NpgsqlDbType.Numeric);
            TypeDict.Add(typeof(string), NpgsqlTypes.NpgsqlDbType.Varchar);
            TypeDict.Add(typeof(DateTime), NpgsqlTypes.NpgsqlDbType.Timestamp);
            TypeDict.Add(typeof(char[]), NpgsqlTypes.NpgsqlDbType.Varchar);
            TypeDict.Add(typeof(Guid), NpgsqlTypes.NpgsqlDbType.Uuid);


            string sql = &amp;quot;COPY &amp;quot; + TableName + &amp;quot; ( &amp;quot;;
            foreach (System.Data.DataColumn col in dt.Columns)
            {
                sql += (col.ColumnName.ToLower() + &amp;quot;,&amp;quot;);
            }
            sql = sql.TrimEnd(',') + &amp;quot;) FROM STDIN (FORMAT BINARY)&amp;quot;;
            int nRows = dt.Rows.Count;
            using (var BulkWrite = ((Npgsql.NpgsqlConnection)Con).BeginBinaryImport(sql))
            {
                for (int idRow = 0; idRow &amp;lt; nRows; idRow++)
                {
                    BulkWrite.StartRow();
                    foreach (System.Data.DataColumn col in dt.Columns)
                    {
                        if (dt.Rows[idRow].IsNull(col))
                        {
                            BulkWrite.WriteNull();
                        }
                        else
                        {
                            if (col.DataType == typeof(string) &amp;amp;&amp;amp; string.IsNullOrEmpty(dt.Rows[idRow].Field&amp;lt;string&amp;gt;(col)))
                            {
                                BulkWrite.WriteNull();
                            }
                            else
                            {
                                BulkWrite.Write(dt.Rows[idRow][col.Ordinal], TypeDict[col.DataType]);
                            }
                        }
                    }
                    
                }
                BulkWrite.Complete();
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="alternative-method-for-oracle-array-bind-for-vector-insertion"&gt;Alternative Method for Oracle Array Bind, for Vector Insertion&lt;/h2&gt;
&lt;p&gt;This is a better method for insertions on Oracle that does not cause issues with dataguard, using arrays of data. The single INSERT command is fed with an array of data.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;int nRowsCount = ts.Count(); 
int[] IDTIMESERIES = new int[nRowsCount];
DateTime[] TIMEPOINT = new DateTime[nRowsCount];
decimal[] VALUE1 = new decimal[nRowsCount];

// loading the arrays with data 
int i = 0;
foreach (var sp in ts.TimeSeriesData)
{
	IDTIMESERIES[i] = ts.Id; TIMEPOINT[i] = sp.t; VALUE1[i] = sp.value;
	i++;
}

if (nRowsCount &amp;gt; 0)
{
	OracleCommand cmdTimeDump = new OracleCommand(&amp;quot;Insert into DATATIMESERIES (IDTIMESERIES, TIMEPOINT, VALUE1) VALUES (:1, :2, :3)&amp;quot;, OraCon);
	cmdTimeDump.ArrayBindCount = nRowsCount;
	cmdTimeDump.Parameters.Add(new OracleParameter() { OracleDbType = OracleDbType.Int32, Value = IDTIMESERIES });
	cmdTimeDump.Parameters.Add(new OracleParameter() { OracleDbType = OracleDbType.Date, Value = TIMEPOINT });
	cmdTimeDump.Parameters.Add(new OracleParameter() { OracleDbType = OracleDbType.Decimal, Value = VALUE1 });
  
	cmdTimeDump.ExecuteNonQuery();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="links"&gt;Links&lt;/h1&gt;
&lt;p&gt;An excellent overview of connections to databases in .net core was published on the &lt;a href="https://devblogs.microsoft.com/dotnet/net-core-data-access/"&gt;Microsoft devblogs&lt;/a&gt;.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Reflections on Webassembly - May/Nov 19</title>
			<link>http://ewinnington.github.io/posts/webassembly-thoughts</link>
			<description>&lt;p&gt;I rewatched this talk from 2014, &lt;a href="https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript"&gt;The Birth and Death of JavaScript&lt;/a&gt;, and am still amazed at how prescient it was and still is.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/webassembly-thoughts</guid>
			<pubDate>Sun, 03 Nov 2019 17:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="initial-post"&gt;Initial post&lt;/h1&gt;
&lt;p&gt;I rewatched this talk from 2014, &lt;a href="https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript"&gt;The Birth and Death of JavaScript&lt;/a&gt;, and am still amazed at how prescient it was and still is.&lt;/p&gt;
&lt;p&gt;The blurb for this is:
“This science fiction / comedy / absurdist / completely serious talk traces the history of JavaScript, and programming in general, from 1995 until 2035.”&lt;/p&gt;
&lt;p&gt;ASM JS is still there, but what Gary Bernhardt calls Metal in the talk is WebAssembly. And WebAssembly (Wasm) is coming, and not just for the web.&lt;/p&gt;
&lt;p&gt;In the .Net world, we see the first glimpses of the power of Wasm with the arrival of &lt;a href="https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor"&gt;Blazor&lt;/a&gt;, which allows the execution of code running on the .net framework (using the mono runtime) inside a browser.&lt;/p&gt;
&lt;p&gt;Wasm is not stopping there. With the &lt;a href="https://hacks.mozilla.org/2019/03/standardizing-wasi-a-webassembly-system-interface/"&gt;standardising of WASI&lt;/a&gt;, a system interface to run Wasm outside the web, we are truly moving towards architecture independence.&lt;/p&gt;
&lt;p&gt;It might take until 2035, like in the video, for Wasm to take over the world, but I have the feeling we will see its impact in the near future. Looking at the progress on Wasm in the two last years, I would recommend any programmer to read up on it and understanding its implications on the way they work.&lt;/p&gt;
&lt;p&gt;For further reading on Wasm, I would recommend the mozilla &lt;a href="https://hacks.mozilla.org/category/webassembly/"&gt;WebAssembly Archives&lt;/a&gt; and in particular, the &lt;a href="https://hacks.mozilla.org/2018/10/webassemblys-post-mvp-future/"&gt;WebAssembly post mvp future by Lin Clark&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="update-in-november-2019"&gt;Update in november 2019&lt;/h1&gt;
&lt;p&gt;Over the last few months, I have seen Wasm cropping up in more and more places, for example as a way to deploy code to running inside databases, such as the case of &lt;a href="https://medium.com/wasmer/announcing-the-first-postgres-extension-to-run-webassembly-561af2cfcb1"&gt;Wasm for Postgres&lt;/a&gt; which allows stored procedures to run webassembly code.&lt;/p&gt;
&lt;p&gt;Another case of that is the reflection on using &lt;a href="https://youtu.be/3yVc5t-g-VU"&gt;WebAssembly as a glue between programming languages&lt;/a&gt; by allowing type information and guarantees to flow between programming languages. This would allow future systems to take the best of breed choice of programming language for each component of the system while still allowing compile time reasoning on type safety by using a type preserving compiler.&lt;/p&gt;
&lt;?# YouTube 3yVc5t-g-VU /?&gt;
&lt;p&gt;As I noted on twitter, as I read, watch and learn about webassembly, I'm getting the feeling this is going to be a titanic shift in the way we reason about programs, languages, frameworks and software design in general.&lt;/p&gt;
&lt;p&gt;&amp;quot;The avalanche has already started, it is too late for the pebbles to vote&amp;quot; - Ambassador Kosh, Babylon 5.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>R - Reading binary files</title>
			<link>http://ewinnington.github.io/posts/R-read-binary-file</link>
			<description>&lt;p&gt;I had to get some data out of files written by Fortran. The format was a large array of doubles.&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/R-read-binary-file</guid>
			<pubDate>Sun, 03 Nov 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;I had to get some data out of files written by Fortran. The format was a large array of doubles.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;numeric() for doubles&lt;/li&gt;
&lt;li&gt;integer() for integers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;readBin takes the input file and reads the binary data. If you want to read to the end of the file, don't give a dimension as 3rd parameter.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-R"&gt;#### Reading value field from file
z &amp;lt;- file(&amp;quot;/BoundValueRemain.bin&amp;quot;, &amp;quot;rb&amp;quot;)
y &amp;lt;- readBin (z, numeric(), 51*50*50*15*13)
close(z)
dim(y) &amp;lt;- c(51, 50, 50, 15, 13)
&lt;/code&gt;&lt;/pre&gt;
</content:encoded>
		</item>
		<item>
			<title>Using Github actions to build Wyam and publish to github pages</title>
			<link>http://ewinnington.github.io/posts/wyam-github-actions</link>
			<description>&lt;p&gt;Not that I have Wyam as a static site generator, I want to use &lt;a href="https://github.com/features/actions"&gt;Github Actions&lt;/a&gt; to automatically deploy it on push. This requires a quite few steps to setup, but I did it, now so can you!&lt;/p&gt;</description>
			<guid>http://ewinnington.github.io/posts/wyam-github-actions</guid>
			<pubDate>Sun, 03 Nov 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Not that I have Wyam as a static site generator, I want to use &lt;a href="https://github.com/features/actions"&gt;Github Actions&lt;/a&gt; to automatically deploy it on push. This requires a quite few steps to setup, but I did it, now so can you!&lt;/p&gt;
&lt;p&gt;Github actions is still in beta, so you'll have to enroll to use the functionality:
&lt;img src="/posts/images/github-actions-wyam/EnrollActions.png" class="img-fluid" alt="EnrollActions" /&gt;&lt;/p&gt;
&lt;h1 id="setup-procedure"&gt;Setup procedure&lt;/h1&gt;
&lt;p&gt;This setup assumes you have a local Wyam that is working on your local machine. You can easily set one up by &lt;a href="http://ewinnington.github.io/posts/Switching-to-wyam"&gt;following these steps&lt;/a&gt;. You can always have a look at my &lt;a href="https://github.com/ewinnington/ewinnington.github.io"&gt;https://github.com/ewinnington/ewinnington.github.io&lt;/a&gt; repository to see what I have configured in my config.wyam.&lt;/p&gt;
&lt;h2 id="personal-page"&gt;Personal page&lt;/h2&gt;
&lt;p&gt;First you must have a &lt;a href="https://pages.github.com/"&gt;Personal Page&lt;/a&gt; setup in github. This is done by creating a public repository &lt;em&gt;username&lt;/em&gt;.github.io.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/CreateRepo.png" class="img-fluid" alt="RepoCreation" /&gt;&lt;/p&gt;
&lt;h3 id="create-the-correct-branches"&gt;Create the correct branches&lt;/h3&gt;
&lt;p&gt;Inside that repository, you will want to create a second branch next to the master: source. This can be done by typing a new branch name in the Switch branches/tags text box.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SourceBranch.png" class="img-fluid" alt="SourceBranch" /&gt;&lt;/p&gt;
&lt;p&gt;Next step is to make this branch the default when we push commits to the repository. This is because the &lt;em&gt;master&lt;/em&gt; branch of the username.gitub.io is what is hosted on github's personal pages. Therefore the source of the wyam site has to be stored on another branch. To set the branch as default, Go to &lt;em&gt;Settings&lt;/em&gt;, then &lt;em&gt;Branches&lt;/em&gt; and select &lt;strong&gt;source&lt;/strong&gt; in the dropdown box. Confirm with update.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SettingsBranches.png" class="img-fluid" alt="SettingsBranches" /&gt;&lt;/p&gt;
&lt;h3 id="prepare-keys-and-install-them"&gt;Prepare keys and install them&lt;/h3&gt;
&lt;p&gt;We will be doing automated pushes from the &lt;strong&gt;source&lt;/strong&gt; branch to the &lt;strong&gt;master&lt;/strong&gt; branch, this means that we need to setup deploy keys and the associated secrets so that github allows us to update in an automated manner.&lt;/p&gt;
&lt;p&gt;First, you need to generate your keys locally on your own machine with &lt;code&gt;ssh-keygen -t rsa -b 4096 -C &amp;quot;Github-user-email&amp;#64;example.com&amp;quot; -f gh-pages -N &amp;quot;&amp;quot;&lt;/code&gt;. You will need to replace &lt;em&gt;Github-user-email&amp;#64;example.com&lt;/em&gt; with your own, of course.&lt;/p&gt;
&lt;p&gt;This will generate two files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gh-pages : the private key file, this will go into the secrets tab on github. I named the key &lt;strong&gt;ACTIONS_DEPLOY_KEY&lt;/strong&gt;, this is important because we need to access it as an environment variable later in the action workflow script.&lt;/li&gt;
&lt;li&gt;gh-pages.pub : the public key file, this will go to the deploy tab on github. I named my deploy key &lt;em&gt;public ACTIONS_DEPLOY_KEY&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once installed, they should be like this in the github user interface of the repository:&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SecretsKey.png" class="img-fluid" alt="Secrets" /&gt;
&lt;img src="/posts/images/github-actions-wyam/DeployKey.png" class="img-fluid" alt="Deploy" /&gt;&lt;/p&gt;
&lt;h2 id="clone-the-repository-or-import-an-existing-git-repo"&gt;Clone the repository (or import an existing git repo)&lt;/h2&gt;
&lt;p&gt;If you have nothing yet in the repository, I suppose you can now directly clone it from github using &lt;code&gt;git clone https://github.com/username/username.github.io&lt;/code&gt; and it should come out all pre-prepared for you. Check something in and push.&lt;/p&gt;
&lt;h3 id="existing-repository"&gt;Existing repository&lt;/h3&gt;
&lt;p&gt;I had an existing repository, so I had a few things to do with it before it was ready to be uploaded. I had already a master branch named &lt;strong&gt;master&lt;/strong&gt;, so to make it conform with github, I renamed my local master branch with &lt;code&gt;git branch -m source &lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I then removed the previous origin before that was in use and I had to add the correct origin that I wanted to push to. Because I had previously had contents on the repository, I had to use the -f command on the push.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;git remote remove origin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git remote add origin https://github.com/username/username.github.io&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git push -u -f origin source&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now that I had pushed the Wyam blog, I was ready to setup the actions.&lt;/p&gt;
&lt;h4 id="side-note-good-wyam.gitignore-file"&gt;Side note - good wyam .gitignore file&lt;/h4&gt;
&lt;p&gt;To avoid checking in the output files of the wyam build, I have the following .gitignore file in the repository:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;config.wyam.dll
config.wyam.hash
config.wyam.packages.xml
wwwroot
output
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="setting-up-the-github-actions"&gt;Setting up the github actions&lt;/h2&gt;
&lt;p&gt;First you will want to check that you are allowing external workflow scripts to be launched on your repository, since I will be relying on a few steps from pre-existing scripts.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SetupActions.png" class="img-fluid" alt="SetupActions.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here the first mistake I made while configuring actions was not going through the Github user interface and instead creating the folders manually in my github repository. I created &lt;em&gt;.github/workflow&lt;/em&gt; instead of &lt;strong&gt;.github/workflows&lt;/strong&gt; which meant that my actions were never kicking off. So don't make my mistake, use the github UI to set up the action and they will create the correct folder structure in your project.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SetUpActionsWorkflow.png" class="img-fluid" alt="Actions workflow" /&gt;&lt;/p&gt;
&lt;p&gt;I setup a yaml file name &lt;a href="https://github.com/ewinnington/ewinnington.github.io/blob/source/.github/workflows/wyam.yml"&gt;wyam.yml&lt;/a&gt;. You can see what it looks like here below (I have included the code below on the page for you to copy and paste if you want. Let's go through this line by line.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/wyam-yaml.png" class="img-fluid" alt="Wyam Yaml" /&gt;&lt;/p&gt;
&lt;p&gt;Line 1: Name of the action that will appear in the action tab&lt;/p&gt;
&lt;p&gt;Line 3-6: Triggers of the action. Here we trigger the action &lt;strong&gt;on push&lt;/strong&gt; of &lt;strong&gt;branch source&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Line 8: List of jobs to run.
Line 9: First job is my build and deploy, I just called it build.&lt;/p&gt;
&lt;p&gt;Line 11: The choice of the image to run on, like in docker. I chose ubuntu-latest.&lt;/p&gt;
&lt;p&gt;Line 13: Each line prexifed with a - is a seperate action.&lt;/p&gt;
&lt;p&gt;Line 14: Checkout the repository with the branch that has just been pushed. This is a standard github action, you can find &lt;a href="https://github.com/actions/checkout"&gt;explanations here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Line 15: Installing .net core for Wyam.&lt;/p&gt;
&lt;p&gt;Line 19-20: Installing Wyam. Here I install Wyam as a local tool by giving the &lt;code&gt;--tool-path .&lt;/code&gt;, since if you install it as a global tool with &lt;em&gt;-g&lt;/em&gt;, the build system won't find it due to .net core's requirement &lt;a href="https://github.com/dotnet/cli/issues/8368"&gt;to restart the shell after being installed for the paths to be valid&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Line 21-22: Running Wyam to render the blog to a set of static pages. Here is where you can change the template (Phantom) to something else if you want.&lt;/p&gt;
&lt;p&gt;Line 23-28: We take the output of Wyam, which lives in the ./output folder and we use &lt;a href="https://github.com/peaceiris/actions-gh-pages"&gt;peaceiris's github action for Github Pages&lt;/a&gt; to publish our results to the correct branch &lt;em&gt;master&lt;/em&gt; of our repository for deployment. We pass the &lt;em&gt;secrets.ACTIONS_DEPLOY_KEY&lt;/em&gt; we defined earlier to allow the script to publish to the master branch.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: Wyam

on:
  push:
    branches:
    - source  # default branch

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout&amp;#64;v1
    - name: Setup .NET Core
      uses: actions/setup-dotnet&amp;#64;v1
      with:
        dotnet-version: 2.1.802
    - name: Install Wyam
      run: dotnet tool install --tool-path . wyam.tool
    - name: Publish blog
      run: ./wyam -r blog -t Phantom
    - name: Deploy
      uses: peaceiris/actions-gh-pages&amp;#64;v2.5.0
      env:
        ACTIONS_DEPLOY_KEY: ${{ secrets.ACTIONS_DEPLOY_KEY }}
        PUBLISH_BRANCH: master  # deploying branch
        PUBLISH_DIR: ./output

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="running-the-workflow"&gt;Running the workflow&lt;/h2&gt;
&lt;p&gt;Once you have setup this file, you can commit it and it should start off the build action. You can follow the progress of the action workflow on the github action page.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/ActionOverview.png" class="img-fluid" alt="Action Overview" /&gt;&lt;/p&gt;
&lt;p&gt;You can drill down into the details of the actions in case you had any failures. This is where I had the most trouble, but with these instructions, you should be fine.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/ActionDetail.png" class="img-fluid" alt="Action Detail" /&gt;&lt;/p&gt;
&lt;h1 id="closing"&gt;Closing&lt;/h1&gt;
&lt;p&gt;If all went well, you should now have your personal wyam generated site up and running at &lt;a href="http://username.github.io"&gt;http://username.github.io&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;Please feel free to look around both branches &lt;em&gt;source&lt;/em&gt; and &lt;em&gt;master&lt;/em&gt; on &lt;a href="https://github.com/ewinnington/ewinnington.github.io"&gt;my github repo&lt;/a&gt; to understand how my blog is setup.&lt;/p&gt;
</content:encoded>
		</item>
	</channel>
</rss>