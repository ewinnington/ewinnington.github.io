<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<id>http://ewinnington.github.io/</id>
	<title>Eric's personal page</title>
	<link rel="self" href="http://ewinnington.github.io/" />
	<rights>2019</rights>
	<updated>2019-11-03T13:18:17Z</updated>
	<subtitle>You will find here a collection of my thoughts, snippets and articles.</subtitle>
	<entry>
		<id>http://ewinnington.github.io/posts/wyam-github-actions</id>
		<title>Using Github actions to build Wyam and publish to github pages</title>
		<link href="http://ewinnington.github.io/posts/wyam-github-actions" />
		<updated>2019-11-03T00:00:00Z</updated>
		<content>&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Not that I have Wyam as a static site generator, I want to use &lt;a href="https://github.com/features/actions"&gt;Github Actions&lt;/a&gt; to automatically deploy it on push. This requires a quite few steps to setup, but I did it, now so can you!&lt;/p&gt;
&lt;p&gt;Github actions is still in beta, so you'll have to enroll to use the functionality:
&lt;img src="/posts/images/github-actions-wyam/EnrollActions.png" class="img-fluid" alt="EnrollActions" /&gt;&lt;/p&gt;
&lt;h1 id="setup-procedure"&gt;Setup procedure&lt;/h1&gt;
&lt;p&gt;This setup assumes you have a local Wyam that is working on your local machine. You can easily set one up by &lt;a href="http://ewinnington.github.io/posts/Switching-to-wyam"&gt;following these steps&lt;/a&gt;. You can always have a look at my &lt;a href="https://github.com/ewinnington/ewinnington.github.io"&gt;https://github.com/ewinnington/ewinnington.github.io&lt;/a&gt; repository to see what I have configured in my config.wyam.&lt;/p&gt;
&lt;h2 id="personal-page"&gt;Personal page&lt;/h2&gt;
&lt;p&gt;First you must have a &lt;a href="https://pages.github.com/"&gt;Personal Page&lt;/a&gt; setup in github. This is done by creating a public repository &lt;em&gt;username&lt;/em&gt;.github.io.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/CreateRepo.png" class="img-fluid" alt="RepoCreation" /&gt;&lt;/p&gt;
&lt;h3 id="create-the-correct-branches"&gt;Create the correct branches&lt;/h3&gt;
&lt;p&gt;Inside that repository, you will want to create a second branch next to the master: source. This can be done by typing a new branch name in the Switch branches/tags text box.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SourceBranch.png" class="img-fluid" alt="SourceBranch" /&gt;&lt;/p&gt;
&lt;p&gt;Next step is to make this branch the default when we push commits to the repository. This is because the &lt;em&gt;master&lt;/em&gt; branch of the username.gitub.io is what is hosted on github's personal pages. Therefore the source of the wyam site has to be stored on another branch. To set the branch as default, Go to &lt;em&gt;Settings&lt;/em&gt;, then &lt;em&gt;Branches&lt;/em&gt; and select &lt;strong&gt;source&lt;/strong&gt; in the dropdown box. Confirm with update.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SettingsBranches.png" class="img-fluid" alt="SettingsBranches" /&gt;&lt;/p&gt;
&lt;h3 id="prepare-keys-and-install-them"&gt;Prepare keys and install them&lt;/h3&gt;
&lt;p&gt;We will be doing automated pushes from the &lt;strong&gt;source&lt;/strong&gt; branch to the &lt;strong&gt;master&lt;/strong&gt; branch, this means that we need to setup deploy keys and the associated secrets so that github allows us to update in an automated manner.&lt;/p&gt;
&lt;p&gt;First, you need to generate your keys locally on your own machine with &lt;code&gt;ssh-keygen -t rsa -b 4096 -C &amp;quot;Github-user-email&amp;#64;example.com&amp;quot; -f gh-pages -N &amp;quot;&amp;quot;&lt;/code&gt;. You will need to replace &lt;em&gt;Github-user-email&amp;#64;example.com&lt;/em&gt; with your own, of course.&lt;/p&gt;
&lt;p&gt;This will generate two files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gh-pages : the private key file, this will go into the secrets tab on github. I named the key &lt;strong&gt;ACTIONS_DEPLOY_KEY&lt;/strong&gt;, this is important because we need to access it as an environment variable later in the action workflow script.&lt;/li&gt;
&lt;li&gt;gh-pages.pub : the public key file, this will go to the deploy tab on github. I named my deploy key &lt;em&gt;public ACTIONS_DEPLOY_KEY&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once installed, they should be like this in the github user interface of the repository:&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SecretsKey.png" class="img-fluid" alt="Secrets" /&gt;
&lt;img src="/posts/images/github-actions-wyam/DeployKey.png" class="img-fluid" alt="Deploy" /&gt;&lt;/p&gt;
&lt;h2 id="clone-the-repository-or-import-an-existing-git-repo"&gt;Clone the repository (or import an existing git repo)&lt;/h2&gt;
&lt;p&gt;If you have nothing yet in the repository, I suppose you can now directly clone it from github using &lt;code&gt;git clone https://github.com/username/username.github.io&lt;/code&gt; and it should come out all pre-prepared for you. Check something in and push.&lt;/p&gt;
&lt;h3 id="existing-repository"&gt;Existing repository&lt;/h3&gt;
&lt;p&gt;I had an existing repository, so I had a few things to do with it before it was ready to be uploaded. I had already a master branch named &lt;strong&gt;master&lt;/strong&gt;, so to make it conform with github, I renamed my local master branch with &lt;code&gt;git branch -m source &lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I then removed the previous origin before that was in use and I had to add the correct origin that I wanted to push to. Because I had previously had contents on the repository, I had to use the -f command on the push.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;git remote remove origin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git remote add origin https://github.com/username/username.github.io&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git push -u -f origin source&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now that I had pushed the Wyam blog, I was ready to setup the actions.&lt;/p&gt;
&lt;h4 id="side-note-good-wyam.gitignore-file"&gt;Side note - good wyam .gitignore file&lt;/h4&gt;
&lt;p&gt;To avoid checking in the output files of the wyam build, I have the following .gitignore file in the repository:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;config.wyam.dll
config.wyam.hash
config.wyam.packages.xml
wwwroot
output
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="setting-up-the-github-actions"&gt;Setting up the github actions&lt;/h2&gt;
&lt;p&gt;First you will want to check that you are allowing external workflow scripts to be launched on your repository, since I will be relying on a few steps from pre-existing scripts.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SetupActions.png" class="img-fluid" alt="SetupActions.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here the first mistake I made while configuring actions was not going through the Github user interface and instead creating the folders manually in my github repository. I created &lt;em&gt;.github/workflow&lt;/em&gt; instead of &lt;strong&gt;.github/workflows&lt;/strong&gt; which meant that my actions were never kicking off. So don't make my mistake, use the github UI to set up the action and they will create the correct folder structure in your project.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SetUpActionsWorkflow.png" class="img-fluid" alt="Actions workflow" /&gt;&lt;/p&gt;
&lt;p&gt;I setup a yaml file name &lt;a href="https://github.com/ewinnington/ewinnington.github.io/blob/source/.github/workflows/wyam.yml"&gt;wyam.yml&lt;/a&gt;. You can see what it looks like here below (I have included the code below on the page for you to copy and paste if you want. Let's go through this line by line.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/wyam-yaml.png" class="img-fluid" alt="Wyam Yaml" /&gt;&lt;/p&gt;
&lt;p&gt;Line 1: Name of the action that will appear in the action tab&lt;/p&gt;
&lt;p&gt;Line 3-6: Triggers of the action. Here we trigger the action &lt;strong&gt;on push&lt;/strong&gt; of &lt;strong&gt;branch source&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Line 8: List of jobs to run.
Line 9: First job is my build and deploy, I just called it build.&lt;/p&gt;
&lt;p&gt;Line 11: The choice of the image to run on, like in docker. I chose ubuntu-latest.&lt;/p&gt;
&lt;p&gt;Line 13: Each line prexifed with a - is a seperate action.&lt;/p&gt;
&lt;p&gt;Line 14: Checkout the repository with the branch that has just been pushed. This is a standard github action, you can find &lt;a href="https://github.com/actions/checkout"&gt;explanations here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Line 15: Installing .net core for Wyam.&lt;/p&gt;
&lt;p&gt;Line 19-20: Installing Wyam. Here I install Wyam as a local tool by giving the &lt;code&gt;--tool-path .&lt;/code&gt;, since if you install it as a global tool with &lt;em&gt;-g&lt;/em&gt;, the build system won't find it due to .net core's requirement &lt;a href="https://github.com/dotnet/cli/issues/8368"&gt;to restart the shell after being installed for the paths to be valid&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Line 21-22: Running Wyam to render the blog to a set of static pages. Here is where you can change the template (Phantom) to something else if you want.&lt;/p&gt;
&lt;p&gt;Line 23-28: We take the output of Wyam, which lives in the ./output folder and we use &lt;a href="https://github.com/peaceiris/actions-gh-pages"&gt;peaceiris's github action for Github Pages&lt;/a&gt; to publish our results to the correct branch &lt;em&gt;master&lt;/em&gt; of our repository for deployment. We pass the &lt;em&gt;secrets.ACTIONS_DEPLOY_KEY&lt;/em&gt; we defined earlier to allow the script to publish to the master branch.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: Wyam

on:
  push:
    branches:
    - source  # default branch

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout&amp;#64;v1
    - name: Setup .NET Core
      uses: actions/setup-dotnet&amp;#64;v1
      with:
        dotnet-version: 2.1.802
    - name: Install Wyam
      run: dotnet tool install --tool-path . wyam.tool
    - name: Publish blog
      run: ./wyam -r blog -t Phantom
    - name: Deploy
      uses: peaceiris/actions-gh-pages&amp;#64;v2.5.0
      env:
        ACTIONS_DEPLOY_KEY: ${{ secrets.ACTIONS_DEPLOY_KEY }}
        PUBLISH_BRANCH: master  # deploying branch
        PUBLISH_DIR: ./output

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="running-the-workflow"&gt;Running the workflow&lt;/h2&gt;
&lt;p&gt;Once you have setup this file, you can commit it and it should start off the build action. You can follow the progress of the action workflow on the github action page.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/ActionOverview.png" class="img-fluid" alt="Action Overview" /&gt;&lt;/p&gt;
&lt;p&gt;You can drill down into the details of the actions in case you had any failures. This is where I had the most trouble, but with these instructions, you should be fine.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/ActionDetail.png" class="img-fluid" alt="Action Detail" /&gt;&lt;/p&gt;
&lt;h1 id="closing"&gt;Closing&lt;/h1&gt;
&lt;p&gt;If all went well, you should now have your personal wyam generated site up and running at &lt;a href="http://username.github.io"&gt;http://username.github.io&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;Please feel free to look around both branches &lt;em&gt;source&lt;/em&gt; and &lt;em&gt;master&lt;/em&gt; on &lt;a href="https://github.com/ewinnington/ewinnington.github.io"&gt;my github repo&lt;/a&gt; to understand how my blog is setup.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Not that I have Wyam as a static site generator, I want to use &lt;a href="https://github.com/features/actions"&gt;Github Actions&lt;/a&gt; to automatically deploy it on push. This requires a quite few steps to setup, but I did it, now so can you!&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/R-read-binary-file</id>
		<title>R - Reading binary files</title>
		<link href="http://ewinnington.github.io/posts/R-read-binary-file" />
		<updated>2019-11-03T00:00:00Z</updated>
		<content>&lt;p&gt;I had to get some data out of files written by Fortran. The format was a large array of doubles.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;numeric() for doubles&lt;/li&gt;
&lt;li&gt;integer() for integers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;readBin takes the input file and reads the binary data. If you want to read to the end of the file, don't give a dimension as 3rd parameter.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-R"&gt;#### Reading value field from file
z &amp;lt;- file(&amp;quot;/BoundValueRemain.bin&amp;quot;, &amp;quot;rb&amp;quot;)
y &amp;lt;- readBin (z, numeric(), 51*50*50*15*13)
close(z)
dim(y) &amp;lt;- c(51, 50, 50, 15, 13)
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;I had to get some data out of files written by Fortran. The format was a large array of doubles.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/R-Redis-Json</id>
		<title>R - Reading JSON from redis</title>
		<link href="http://ewinnington.github.io/posts/R-Redis-Json" />
		<updated>2019-11-03T00:00:00Z</updated>
		<content>&lt;p&gt;I needed to access Redis from R. Here's the code I used to connect, set a value, then deserialize a key that was in json format and publish a message. &lt;a href="https://cran.r-project.org/web/packages/rredis/vignettes/rredis.pdf"&gt;Rredis documentation located here&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(&amp;quot;rredis&amp;quot;)
library(&amp;quot;jsonlite&amp;quot;, lib.loc=&amp;quot;~/R/win-library/3.2&amp;quot;)

redisConnect()
redisSet(&amp;quot;x&amp;quot;,rnorm(5))
redisGet(&amp;quot;x&amp;quot;)

x = fromJSON(redisGet(&amp;quot;ts_1&amp;quot;))
x$t &amp;lt;-  strptime(x$t, &amp;quot;%Y-%m-%dT%H:%M:%S&amp;quot;)

//https://cran.r-project.org/web/packages/rredis/vignettes/rredis.pdf
redisPublish(&amp;quot;General:Active&amp;quot;, charToRaw('Message'))

redisClose()
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;I needed to access Redis from R. Here's the code I used to connect, set a value, then deserialize a key that was in json format and publish a message. &lt;a href="https://cran.r-project.org/web/packages/rredis/vignettes/rredis.pdf"&gt;Rredis documentation located here&lt;/a&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/Switching-to-wyam</id>
		<title>Switching to Wyam</title>
		<link href="http://ewinnington.github.io/posts/Switching-to-wyam" />
		<updated>2019-10-23T00:00:00Z</updated>
		<content>&lt;p&gt;After many years with a half abandoned Wordpress blog, I'm switching to &lt;a href="https://wyam.io/"&gt;Wyam&lt;/a&gt; for a static site generator.&lt;/p&gt;
&lt;p&gt;This blog was generated as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dotnet tool install -g wyam.tool
wyam new -r blog
wyam -r blog -t Phantom -p -w
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last command makes wyam host the blog using the recipe blog, the theme Phantom (-t), in preview mode (-p) so that you can access it locally and in Watch mode (-w), so that you can see changes without having to re-run the build line.&lt;/p&gt;
&lt;p&gt;I also exported the previous posts from Wordpress and will be adding those that are not too outdated back here.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;After many years with a half abandoned Wordpress blog, I'm switching to &lt;a href="https://wyam.io/"&gt;Wyam&lt;/a&gt; for a static site generator.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/append-files-together-using-windows-command-line</id>
		<title>Append files together using windows command line</title>
		<link href="http://ewinnington.github.io/posts/append-files-together-using-windows-command-line" />
		<updated>2015-06-26T00:00:00Z</updated>
		<content>&lt;p&gt;In the command prompt, an easy way to append files together is to use the &amp;quot;type&amp;quot; command and pipe it to an output file.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;type Results\_\* &amp;gt; Results\_combined.txt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To call this from a piece of C# code, I have been using the command line with the /c parameter, which makes it execute the attached command.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cmd /c type Results\_\* &amp;gt; Results\_combined.txt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;C# Example usage:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using (Process RunProc = new Process()) {
    string s = &amp;quot;cmd.exe&amp;quot;;  
    string p = &amp;quot;/c type Results\_\* &amp;gt; Results\_combined.txt&amp;quot;;
    RunProc.StartInfo = new ProcessStartInfo(s, p);
    RunProc.Start();    
    RunProc.WaitForExit();
}
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;In the command prompt, an easy way to append files together is to use the "type" command and pipe it to an output file.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/tail-command-with-powershell</id>
		<title>Tail command with powershell</title>
		<link href="http://ewinnington.github.io/posts/tail-command-with-powershell" />
		<updated>2015-02-19T00:00:00Z</updated>
		<content>&lt;p&gt;Powershell has now got a command to see the last lines of a file. The syntax is for the last 10 lines:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;Get-Content _filename _\-Tail 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It also has a -wait command that blocks and shows new entries as they arrive.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Powershell has now got a command to see the last lines of a file. The syntax is for the last 10 lines:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/oracle-getting-a-list-of-all-columns-data-types-lengths-of-column-for-every-table-in-your-schema</id>
		<title>Oracle Getting a list of all columns, data types, lengths of column for every table in your schema</title>
		<link href="http://ewinnington.github.io/posts/oracle-getting-a-list-of-all-columns-data-types-lengths-of-column-for-every-table-in-your-schema" />
		<updated>2014-09-16T00:00:00Z</updated>
		<content>&lt;p&gt;To get all the columns in the schema of an oracle DB, with the appropriate datatype and column length you can use:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;select column_name, data_type, data_length, table_name 
from all_tab_columns where table_name in 
(select TABLE_NAME from user_tables);
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;To get all the columns in the schema of an oracle DB, with the appropriate datatype and column length you can use:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/getting-autoincremented-version-numbers-in-visual-studio</id>
		<title>Getting autoincremented version numbers in Visual Studio</title>
		<link href="http://ewinnington.github.io/posts/getting-autoincremented-version-numbers-in-visual-studio" />
		<updated>2014-08-25T00:00:00Z</updated>
		<content>&lt;p&gt;On C# projects, in the &amp;quot;AssemblyInfo.cs&amp;quot; file, you can set the Assembly Version to contain *, which sets the version automatically to the build date and time.&lt;/p&gt;
&lt;p&gt;If you comment out the AssemblyFileVersion, then you can see it in the Windows explorer. If you don't then Windows Explorer will always report the AssemblyFileVersion which does not support the * notation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\[assembly: AssemblyVersion(&amp;quot;1.0.\*&amp;quot;)\]
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;On C# projects, in the "AssemblyInfo.cs" file, you can set the Assembly Version to contain *, which sets the version automatically to the build date and time.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/using-svg-images-on-azure-websites</id>
		<title>Using SVG images on Azure Websites</title>
		<link href="http://ewinnington.github.io/posts/using-svg-images-on-azure-websites" />
		<updated>2014-08-23T00:00:00Z</updated>
		<content>&lt;p&gt;I've been using &lt;a href="https://useiconic.com/"&gt;Iconic's icon set&lt;/a&gt; for the development of a dashboard for one of my projects. While publishing it to &lt;a href="http://azure.microsoft.com/en-us/"&gt;Azure&lt;/a&gt; to test it out, none of the SVGs images or icons were being served.&lt;/p&gt;
&lt;p&gt;It required a little bit of configuration to get it all running:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Make sure the svg files are included in the visual studio project and are set to &amp;quot;Copy Always&amp;quot; or &amp;quot;Copy If Newer&amp;quot;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Configure the web.config of your project to contain the following code to make azure serve the SVGs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt; &amp;lt;system.webServer&amp;gt;
   &amp;lt;staticContent&amp;gt;
     &amp;lt;remove fileExtension=&amp;quot;.svg&amp;quot;/&amp;gt;
     &amp;lt;mimeMap fileExtension=&amp;quot;.svg&amp;quot; mimeType=&amp;quot;image/svg+xml&amp;quot; /&amp;gt;
   &amp;lt;/staticContent&amp;gt;
 &amp;lt;/system.webServer&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This give the correct mimeType to Azure. For some strange reason, it doesn't have it by default in its configuration, and you'll get errors when trying to serve the content (404). With these steps done, Azure should be able to serve you static SVG images when you use the correct path (I use /img/ ).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&amp;quot;~/img/database.svg&amp;quot; alt=&amp;quot;database&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should get you a black and white database icon.&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;p&gt; To use Iconic's features like CSS styling of the icons, you need to include in your script bundle the iconic.js (or iconic.min.js).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the data-src attribute in the &lt;img&gt; tag to indicate the Iconic that it must inject the SVG into the document.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img data-src=&amp;quot;~/img/database.svg&amp;quot; class=&amp;quot;iconic iconic-md ok&amp;quot; alt=&amp;quot;database&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="5"&gt;
&lt;li&gt;Create custom CSS markings like the &amp;quot;ok&amp;quot; class to style the icon. I added these in a site-iconic.css file that I include in the bundles.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;.ok {
fill: green;
}
.nok {
fill: red;
}&lt;/p&gt;
&lt;p&gt;This &amp;quot;ok&amp;quot; class changes the icon fill to green, I have similarly an &amp;quot;nok&amp;quot; class changing the icon to red.&lt;/p&gt;
&lt;ol start="6"&gt;
&lt;li&gt;If you are using the Razor engine to generate your pages, you can directly assign class names based on the object's properties. Here I have an object DbServer which has a boolean property isAvailable to show its status.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;&amp;#64;{
string status = (DbServer.isAvailable ? &amp;quot;ok&amp;quot; : &amp;quot;nok&amp;quot;);
&amp;lt;img data-src=&amp;quot;~/img/database.svg&amp;quot; class=&amp;quot;iconic iconic-md &amp;#64;status&amp;quot; alt=&amp;quot;database&amp;quot;&amp;gt;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, every time the page is refreshed, the status of the DB is indicated by the colour of the Database icon.&lt;/p&gt;
&lt;p&gt;&lt;a href="old/images/Dashboard-e1408819237573.png"&gt;&lt;img src="old/images/Dashboard-e1408819237573.png" class="img-fluid" alt="Dashboard" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now you can really use Iconic's icon set potential.&lt;/p&gt;
&lt;p&gt;Of course, if you are using &lt;a href="http://signalr.net/"&gt;SignalR&lt;/a&gt;, you can also wire up the whole setup to dynamically adjust the icons with javascript, but that's for another post.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;I've been using &lt;a href="https://useiconic.com/"&gt;Iconic's icon&amp;nbsp;set&lt;/a&gt; for the development of a dashboard for one of my projects. While publishing&amp;nbsp;it to &lt;a href="http://azure.microsoft.com/en-us/"&gt;Azure&lt;/a&gt; to test it out, none of the SVGs images or icons were being served.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/diff-compare-two-files-in-visual-studio</id>
		<title>Diff / Compare two files in Visual Studio</title>
		<link href="http://ewinnington.github.io/posts/diff-compare-two-files-in-visual-studio" />
		<updated>2014-03-23T00:00:00Z</updated>
		<content>&lt;p&gt;In visual studio, you can use the integrated command line to diff two files by using the command &lt;em&gt;Tools.DiffFiles file1 file2&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Thanks to my work colleagues for that trick!&lt;/p&gt;
</content>
		<summary>&lt;p&gt;In visual studio, you can use the integrated command line to diff two files by using the command &lt;em&gt;Tools.DiffFiles file1 file2&lt;/em&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/listing-the-channels-of-the-wifi-networks-around-you-in-windows</id>
		<title>Listing the channels of the WIFI networks around you in Windows</title>
		<link href="http://ewinnington.github.io/posts/listing-the-channels-of-the-wifi-networks-around-you-in-windows" />
		<updated>2014-03-11T00:00:00Z</updated>
		<content>&lt;p&gt;To list the network channels in use by the various wi-fi networks, you can always use this command in an Administrator command prompt.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;netsh wlan show all
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;To list the network channels in use by the various wi-fi networks, you can always use this command in an Administrator command prompt.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/oracle-reclaiming-lob-space-after-deletion-clob-blob</id>
		<title>Oracle - Reclaiming LOB space after deletion (CLOB, BLOB)</title>
		<link href="http://ewinnington.github.io/posts/oracle-reclaiming-lob-space-after-deletion-clob-blob" />
		<updated>2014-02-03T00:00:00Z</updated>
		<content>&lt;p&gt;To reclaim space after a deleting LOBs, use the following commands. XXXXX is my tablename, data is my column name for the lob, in pink the size of the table.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Check size of the table XXXXX&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;SELECT table_name, column_name, segment_name, a.bytes
FROM dba_segments a JOIN dba_lobs b
USING (owner, segment_name)
WHERE b.table_name = 'XXXXX';
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; XXXXX DATA SYS_LOB0000025315C00007$$ 1073741824
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Delete, in my case, I just clean up all files in my table.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;DELETE FROM XXXXX;
COMMIT;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; 183 rows deleted.
&amp;gt;&amp;gt; committed.
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Ask Oracle to shrink the tablespace used by the LOB column ‘data’. Have a coffee break.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;ALTER TABLE XXXXX MODIFY LOB (data) (SHRINK SPACE);
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; table XXXXX altered.
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="4"&gt;
&lt;li&gt;Check size again:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;SELECT table_name, column_name, segment_name, a.bytes
FROM dba_segments a JOIN dba_lobs b
USING (owner, segment_name)
WHERE b.table_name = 'XXXXX';
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; XXXXX DATA SYS\_LOB0000025315C00007$$ 65536
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;To reclaim space after a deleting LOBs, use the following commands. XXXXX is my tablename, data is my column name for the lob, in pink the size of the table.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/oracle-sql-developer-set-nls-to-give-you-full-date-and-time</id>
		<title>Oracle SQL Developer - Set NLS to give you full date and time</title>
		<link href="http://ewinnington.github.io/posts/oracle-sql-developer-set-nls-to-give-you-full-date-and-time" />
		<updated>2014-01-31T00:00:00Z</updated>
		<content>&lt;p&gt;In the SQL sheet for the database, use the following SQL:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;alter session set NLS_DATE_FORMAT = &amp;quot;dd.mm.yyyy hh24:mi:ss&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;In the SQL sheet for the database, use the following SQL:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/sqlfiddle-a-way-to-share-sql-snippets-so-that-they-can-be-tested-in-the-browser</id>
		<title>SqlFiddle - A way to share SQL snippets so that they can be tested in the browser</title>
		<link href="http://ewinnington.github.io/posts/sqlfiddle-a-way-to-share-sql-snippets-so-that-they-can-be-tested-in-the-browser" />
		<updated>2013-11-05T00:00:00Z</updated>
		<content>&lt;p&gt;A couple of days ago, I stumbled upon &lt;a href="http://www.sqlfiddle.com/"&gt;SQLFiddle&lt;/a&gt;, a little magical website that allows you to upload a DBSchema and run queries on it, live in the browser. It also allows to share them with other users.&lt;/p&gt;
&lt;p&gt;In the course of my work, I've often come across a table that has an identifier, a timestamp and a value, and these rows must be mapped to one new row containing multiple identifiers. Two typical examples of that are two identifiers defining a minimum and a maximum value timeseries that must be put into a single row entry and an entry that is built from three identified timeseries representing value, volatility and mean reversion parameters of a stochastic process.&lt;/p&gt;
&lt;p&gt;In my earlier blog post, &lt;a href="Oracle10g-Pivoting-data.html"&gt;Oracle 10g - Pivoting data&lt;/a&gt;, I provided two different sql scripts to solve the first case min/max time series. You can find the SQLFiddles here:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.sqlfiddle.com/#!4/dce2d/1"&gt;Decode with subquery and max &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.sqlfiddle.com/#!4/dce2d/2"&gt;Decode in one query and max &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can even view your query's execution plan, which is a really nice touch. I'll take the time to share some more oracle sql statements next time in an SQLFiddle.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;A couple of days ago, I stumbled upon &lt;a href="http://www.sqlfiddle.com/"&gt;SQLFiddle&lt;/a&gt;, a little magical website that allows you to upload a DBSchema and run queries on it, live in the browser. It also allows to share them with other users.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/raspberry-pi-update-arkos</id>
		<title>Raspberry Pi update Arkos</title>
		<link href="http://ewinnington.github.io/posts/raspberry-pi-update-arkos" />
		<updated>2013-10-31T00:00:00Z</updated>
		<content>&lt;p&gt;Since I haven't talked much about what I've been doing with my Pi, here's the latest:&lt;/p&gt;
&lt;p&gt;I've installed a distribution called &lt;a href="https://arkos.io/"&gt;ArkOS&lt;/a&gt;, which exposes a web interface allowing the easy configuration of many network accessible services, including a blog and an &lt;a href="http://owncloud.org/"&gt;owncloud&lt;/a&gt; instance.&lt;/p&gt;
&lt;p&gt;I use owncloud as my private, unlimited, Dropbox. The first time I set it up, on a nginx server, it took a lot of configuration to get just right. ArkOS does it all out of the box.&lt;/p&gt;
&lt;p&gt;For dynamic DNS, instead of my previous self-hosted &amp;quot;poor man's&amp;quot; link, I am now using &lt;a href="http://duckdns.org/"&gt;DuckDNS&lt;/a&gt; which promises free dynamic DNS and is really easy to use.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Since I haven't talked much about what I've been doing with my Pi, here's the latest:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/debugging-tips</id>
		<title>Debugging tips</title>
		<link href="http://ewinnington.github.io/posts/debugging-tips" />
		<updated>2013-10-31T00:00:00Z</updated>
		<content>&lt;p&gt;If you get a bug in a loop, remember that the bug could be caused by the previous execution of the loop and thus be below the code point that fails.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;If you get a bug in a loop, remember that the bug could be caused by the previous execution of the loop and thus be below the code point that fails.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/commenting-and-uncommenting-in-vi</id>
		<title>Commenting and Uncommenting in vi</title>
		<link href="http://ewinnington.github.io/posts/commenting-and-uncommenting-in-vi" />
		<updated>2013-07-23T00:00:00Z</updated>
		<content>&lt;p&gt;Sometimes I have to edit large config files in vi. Typically I have to comment out a block or even the whole file. Here's the command to insert a # before every line in the file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:%s/^/# /
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To comment the next 4 lines (. is current line , . + 3 lines more)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:.,.+3s/^/# /
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to uncomment the first character from every line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:%s/^#  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or uncomment a section:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:.,.+3s/^#
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;Sometimes I have to edit large config files in vi. Typically I have to comment out a block or even the whole file. Here's the command to insert a # before every line in the file:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/updating-my-raspberry-pis-ip-address-on-a-distant-server-via-sftp</id>
		<title>Updating my Raspberry Pi's IP address on a distant server via SFTP</title>
		<link href="http://ewinnington.github.io/posts/updating-my-raspberry-pis-ip-address-on-a-distant-server-via-sftp" />
		<updated>2013-07-05T00:00:00Z</updated>
		<content>&lt;p&gt;Now I have my external IP address, I want to collect it on a regular basis and push it to a server that accepts SFTP. Now sadly, that server doesn't allow me to use passkey files, so I have to workaround using sshpass (a great little module allowing to pass passwords to the SSH commands - install as usual with &lt;code&gt;apt-get install sshpass&lt;/code&gt; ).&lt;/p&gt;
&lt;p&gt;The EOF at the end of the sftp command is to ensure that I am passing the rest of the commands to the sftp command. I could also use a -b flag and a file, but it would mean one more file to deal with.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;#!/bin/bash
wget -q -O- http://ip4.me |
grep -o '\[0-9\]\\{1,3\\}\\.\[0-9\]\\{1,3\\}\\.\[0-9\]\\{1,3\\}\\.\[0-9\]\\{1,3\\}' &amp;gt; ip.txt
sshpass -p XXXXX sftp -oPort=22 username&amp;#64;xxx.cloudplush.com &amp;lt;&amp;lt;-EOF
cd /location
put ip.txt
bye
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then it was a simple matter of putting that in a crontab job, running it every five minutes is enough. Calling crontab crons.txt launched the job. crontab -l lists the jobs.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cron"&gt;\*/5 \* \* \* \* ~/go.sh &amp;gt;/dev/null
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;Now I have my external IP address, I want to collect it on a regular basis and push it to a server that accepts SFTP. Now sadly, that server doesn't allow me to use passkey files, so I have to workaround using sshpass (a great little module allowing to pass passwords to the SSH commands - install as usual with &lt;code&gt;apt-get install sshpass&lt;/code&gt; ).&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/raspberry-pi</id>
		<title>Raspberry pi</title>
		<link href="http://ewinnington.github.io/posts/raspberry-pi" />
		<updated>2013-01-23T00:00:00Z</updated>
		<content>&lt;p&gt;Since I've finally had time to do something with my &lt;a href="http://www.raspberrypi.org/"&gt;Raspberry Pi&lt;/a&gt;, I've set it up as a file server for macs and iTunes server for the house. I'm using a 7 port USB hub, powered, that uses 2 4-port hubs inside. As a drive, I used a Toshiba 500 gig USB powered HDD that supports USB3. The Raspberry is powered directly from the USB hub, so there is only one power supply for the setup with 3 USB cables (1 hub to pi for power supply, 1 pi to hub data, 1 hub to hdd data cable) and 1 ethernet cat5 cable.&lt;/p&gt;
&lt;p&gt;The distribution is a standard Raspbian that I keep up to date using &lt;em&gt;sudo apt-get update&lt;/em&gt; and &lt;em&gt;sudo apt-get upgrade&lt;/em&gt;. (&lt;em&gt;Linux raspberrypi 3.2.27+ #250 PREEMPT Thu Oct 18 19:03:02 BST 2012 armv6l&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;To mount the Toshiba HDD, I first used &lt;strong&gt;dmesg&lt;/strong&gt; to watch for where the USB drive appeared when connected to the USB hub. For me it was sda : sda1. So I mounted it using &lt;strong&gt;mount&lt;/strong&gt; and after verifying it worked, edited the_ /etc/fstab_ to make the drive auto mount on boot. I added the line: &lt;em&gt;/dev/sda1 /srv/toshiba auto defaults 0 0&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To act as a file server for mac, I used the software &lt;a href="http://netatalk.sourceforge.net/"&gt;&lt;strong&gt;netatalk&lt;/strong&gt;&lt;/a&gt;. It's quick to install and requires practically no configuration and it worked out of the box. My raspberry appeared on the mac within seconds with the home drive shared, then it was a simple share of the extra folders.&lt;/p&gt;
&lt;p&gt;To Install: &lt;em&gt;apt-get install netatalk&lt;/em&gt; To configure which folders are shared: &lt;em&gt;vi /etc/netatalk/AppleVolumes.default&lt;/em&gt; (remember to check the rights on these folders if you have a problem) To start/stop/restart the service: &lt;em&gt;sudo /etc/init.d/netatalk start&lt;/em&gt; (or &lt;em&gt;stop&lt;/em&gt; or &lt;em&gt;restart&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;To act as an &lt;a href="http://elinux.org/RPiForked-Daapd"&gt;iTunes server&lt;/a&gt;, I used &lt;strong&gt;&lt;a href="https://github.com/jasonmc/forked-daapd"&gt;forked-daapd&lt;/a&gt;&lt;/strong&gt;. Again, worked out of the box with just a touch of configuration. The config file is very easy. I didn't used the remote function of daapd yet, using the box only as a server, not as a playback device.&lt;/p&gt;
&lt;p&gt;To install: &lt;em&gt;apt-get install forked-daapd&lt;/em&gt; To configure where the music is at: &lt;em&gt;sudo vi /etc/forked-daapd.conf&lt;/em&gt; To start/stop the service: &lt;em&gt;sudo /etc/init.d/forked-daapd start&lt;/em&gt; (or &lt;em&gt;stop&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;With that installed, I had &amp;quot;Music on Raspberry pi&amp;quot; showing up in my iTunes side panel. It just worked.&lt;/p&gt;
&lt;p&gt;The only problem I was getting was that the playback of certain songs was getting interrupted in midstream and when I changed songs in iTunes, there was a very long &amp;quot;Opening URL&amp;quot; message box coming up. The Toshiba hard drive where the music is located was running really slow and any access loaded the CPU to 100% for far too long. &lt;a href="http://www.raspberrypi.org/phpBB3/viewtopic.php?f=28&amp;amp;t=10355"&gt;Similar problems had been reported on the raspberry pi forum&lt;/a&gt;. To diagnose what was the issue, I used &lt;strong&gt;hdparm&lt;/strong&gt; to check the performance of the HDD and **lsusb **to find out the tree structure of the USB hub.&lt;/p&gt;
&lt;p&gt;Run a performance test of drive sda: &lt;em&gt;hdparm -tT /dev/sda&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;My first test gave me a speed of ~280 KB/s. Abysmal performance. After checking the logs with &lt;strong&gt;dmesg&lt;/strong&gt;, I saw many USB reset messages with respect to the USB drive. With &lt;strong&gt;lsusb&lt;/strong&gt;, I confirmed the HDD was connected to the second internal usb hub of my powered hub, so I changed port until I found one that is connected to the first hub. The performance difference was instantaneous: 26 MB/s. Connecting it directly to the raspberry pi proved to be too much of a power drain for the pi's usb port.&lt;/p&gt;
&lt;p&gt;List the tree of USB hubs and devices connected: &lt;em&gt;sudo lsusb -t&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A couple more things remained before I could leave my pi headless in the closet next to the router: I changed the default password (&lt;em&gt;raspberry&lt;/em&gt;) to another one using the command &lt;strong&gt;passwd&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Then I installed &lt;a href="http://www.tightvnc.com/"&gt;&lt;strong&gt;tightvncserver&lt;/strong&gt;&lt;/a&gt; on the pi to &lt;a href="http://elinux.org/RPi_VNC_Server"&gt;serve the desktop over the network&lt;/a&gt; to a mac or a windows computer. I don't launch it automatically on logging in, I only launch a graphical environment occasionally, so it can live on the command line for the time being.&lt;/p&gt;
&lt;p&gt;To install: &lt;em&gt;sudo apt-get install tightvncserver&lt;/em&gt; To launch: &lt;em&gt;tightvncserver&lt;/em&gt; To create a display on port 0 with a 1024x768 resolution and 24 bit colour depth: &lt;em&gt;vncserver :0 -geometry 1024x768 -depth 24&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Over the network I could now SSH into the pi (On windows I use &lt;a href="http://www.chiark.greenend.org.uk/%7Esgtatham/putty/"&gt;&lt;strong&gt;Putty&lt;/strong&gt;&lt;/a&gt;, on mac I just use SSH from the command shell) and launch the GUI on another computer.&lt;/p&gt;
&lt;p&gt;Finally, I connected to my home network and forwarded the SSH (port 22) service to my raspberry pi.&lt;/p&gt;
&lt;p&gt;Next time, I want to set-up a dynamic dns for the Pi, so that I can always gain access to it, even if my home router reboots and changes ip. I would like it to use a subdomain of my cloudplush address, but I don't know if my hosting provider iPower supports that. Another option would be to email or tweet the ip address of my home router every time it changes.&lt;/p&gt;
&lt;p&gt;I also saw an interesting &lt;a href="http://jordanburgess.com/post/38986434391/raspberry-pi-airplay"&gt;AirPi project&lt;/a&gt; online, where the pi works as an airplay receiver, this would be an interesting addition to my pi. For this, I need to get a wireless adapter.&lt;/p&gt;
&lt;p&gt;I want to investigate using the pi with a LAMP stack on it and &lt;a href="https://owncloud.com/"&gt;&lt;strong&gt;OwnCloud&lt;/strong&gt;&lt;/a&gt; to serve as a private owned dropbox.&lt;/p&gt;
&lt;p&gt;Finally, I really should stop relying on passwords with my SSH connection and start using an SSH keyfile, Especially if it will be more and more internet facing.&lt;/p&gt;
&lt;p&gt;The command &lt;strong&gt;history&lt;/strong&gt; to helped me remember all the things I did.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Since I've finally had time to do something with my &lt;a href="http://www.raspberrypi.org/"&gt;Raspberry Pi&lt;/a&gt;, I've set it up&amp;nbsp;as a file server for macs and iTunes server for the house. I'm using a 7 port USB hub, powered, that uses 2 4-port hubs inside. As a drive, I used a Toshiba 500 gig USB powered HDD that supports USB3. The Raspberry is powered directly from the USB hub, so there is only one power supply for the setup with 3 USB cables (1 hub to pi for power supply, 1 pi to hub data, 1 hub to hdd data cable) and 1 ethernet cat5 cable.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/making-fortran-dlls-to-interface-with-vba-in-excel</id>
		<title>Making Fortran DLLs to interface with VBA in Excel</title>
		<link href="http://ewinnington.github.io/posts/making-fortran-dlls-to-interface-with-vba-in-excel" />
		<updated>2012-05-24T00:00:00Z</updated>
		<content>&lt;p&gt;Note to self, Remember:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When working with Intel visual fortran, always perform a static link (/MT) in the command line options so that you don't dependent on a DLL being present on the target machine.&lt;/li&gt;
&lt;li&gt;DLLs need Kernel32.lib to be added to the dependencies&lt;/li&gt;
&lt;li&gt;ByVal in VBA doesn't always mean ByVal, when calling a DLL it means &amp;quot;Copy then give a Ref&amp;quot;, so on the Fortran side, get the address by reference.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On the VB side, the string gets declared as &amp;quot;ByVal stringname as string&amp;quot;. You also need to add the string length to the end of the argument list as &amp;quot;ByVal stringlen as Integer&amp;quot;. I also changed the numeric args to ByRef, especially as one of them is written. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-VBA"&gt;Module Module1
    Declare Sub TestSSdll _
        Lib &amp;quot;C:\Documents and Settings\ . . . \TestSSdll.dll&amp;quot; _
        (ByRef Phi0 As Double, ByRef RLambda0 As Double, _
        ByRef NWinTimStps As Long, ByVal gridfile As String, _
        ByVal len_gridfile As Integer)
End Module
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will need to pass the length of the string explicitly using this arrangement.&lt;/p&gt;
&lt;p&gt;On the Fortran side, the routine needs to have the STDCALL and REFERENCE attributes, the string argument should not have the REFERENCE attribute, assuming you want the length passed. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-Fortran"&gt;subroutine TestSSdll (phi0, rlambda0, lgridfile, nWinTimStps, &amp;amp;
    gridfile)
implicit none

!DEC$ ATTRIBUTES DLLEXPORT, STDCALL, REFERENCE :: TestSSdll
!DEC$ ATTRIBUTES ALIAS: &amp;quot;TestSSdll&amp;quot; :: TestSSdll

    real(8), intent(in) :: phi0, rlambda0
    integer(8) :: nWinTimStps
    character(*), intent(in) :: gridfile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the string length is not explicitly specified in the Fortran, as the compiler will look for it, passed by value.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Note to self, Remember:&lt;/p&gt;</summary>
	</entry>
</feed>