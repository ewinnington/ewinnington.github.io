<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<id>http://ewinnington.github.io/</id>
	<title>Eric Winnington</title>
	<link rel="self" href="http://ewinnington.github.io/" />
	<rights>2019</rights>
	<updated>2019-11-12T20:46:04Z</updated>
	<subtitle>A collection of thoughts, code and snippets.</subtitle>
	<entry>
		<id>http://ewinnington.github.io/posts/jupyter-sqlite-csharp</id>
		<title>Testing SQLite in C# Jupyter notebook</title>
		<link href="http://ewinnington.github.io/posts/jupyter-sqlite-csharp" />
		<updated>2019-11-12T20:00:00Z</updated>
		<content>&lt;p&gt;Now that we have &lt;a href="/posts/jupyter-notebook-csharp-r"&gt;Jupyter Notebooks with C# installed&lt;/a&gt;, using it as an environment to play with SQLite is very easy. &lt;a href="https://www.sqlite.org/index.html"&gt;SQLite&lt;/a&gt; is a relational database that is small in footprint and self-contained. It also has a great in-memory mode which is perfect for playing around in a Jupyter notebook.&lt;/p&gt;
&lt;p&gt;You can access my &lt;a href="https://github.com/ewinnington/noteb/blob/master/SqliteInteraction.ipynb"&gt;SQLite example notebook here&lt;/a&gt;. (&lt;em&gt;Note, if you can tell me how to host them online to make them executable, drop me a line on &lt;a href="https://twitter.com/ThrowATwit"&gt;twitter&lt;/a&gt;&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;You can create a C# Notebook from the file menu of Jupyter.&lt;/p&gt;
&lt;p&gt;&lt;img src="posts/images/jupyter-notebook-csharp-r/new-notebook.png" class="img-fluid" alt="new-notebook" /&gt;&lt;/p&gt;
&lt;p&gt;We need to pull in the nuget package &lt;code&gt;System.Data.SQLite&lt;/code&gt; to interact with the database.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;#r &amp;quot;nuget:System.Data.SQLite&amp;quot;
using System.Data.SQLite;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;#r&lt;/code&gt; is used to reference a dll or a nuget package. If you prefix the command with &amp;quot;nuget:&amp;quot; then the jupyter notebook will download the nuget and add it as a reference. Then as in usual c#, you must reference it.&lt;/p&gt;
&lt;p&gt;When you run this cell, you should see the following output:&lt;/p&gt;
&lt;p&gt;&lt;img src="posts/images/jupyter-notebook-csharp-r/sqlite01.png" class="img-fluid" alt="sqlite01" /&gt;&lt;/p&gt;
&lt;p&gt;We can then create a connection to an in-memory SQLite database.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;SQLiteConnection conn;

conn = new SQLiteConnection(&amp;quot;Data Source=:memory:;Version=3;New=True;&amp;quot;);

try
{
conn.Open();
}
catch (Exception ex)
{
Console.WriteLine(ex); 
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating two identical tables &lt;em&gt;SampleTable&lt;/em&gt; and &lt;em&gt;SampleTable1&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;using (SQLiteCommand sqlite_cmd = conn.CreateCommand()) {
    string Createsql = &amp;quot;CREATE TABLE SampleTable(Col1 VARCHAR(20), Col2 INT)&amp;quot;;
    string Createsql1 = &amp;quot;CREATE TABLE SampleTable1(Col1 VARCHAR(20), Col2 INT)&amp;quot;;
    sqlite_cmd.CommandText = Createsql;
    sqlite_cmd.ExecuteNonQuery();
    sqlite_cmd.CommandText = Createsql1;
    sqlite_cmd.ExecuteNonQuery();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Inserting a set of data into these tables.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;using (SQLiteCommand sqlite_cmd = conn.CreateCommand()) {
    sqlite_cmd.CommandText = &amp;quot;INSERT INTO SampleTable(Col1, Col2) VALUES ('Test Text ', 1);&amp;quot;;
    sqlite_cmd.ExecuteNonQuery();
    sqlite_cmd.CommandText = &amp;quot;INSERT INTO SampleTable(Col1, Col2) VALUES ('Test1 Text1 ', 2);&amp;quot;;
    sqlite_cmd.ExecuteNonQuery();
    sqlite_cmd.CommandText = &amp;quot;INSERT INTO SampleTable(Col1, Col2) VALUES ('Test2 Text2 ', 3);&amp;quot;;
    sqlite_cmd.ExecuteNonQuery();
    sqlite_cmd.CommandText = &amp;quot;INSERT INTO SampleTable1(Col1, Col2) VALUES ('Test3 Text3 ', 3);&amp;quot;;
    sqlite_cmd.ExecuteNonQuery();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reading from &lt;em&gt;SampleTable&lt;/em&gt; to verify the insertions went through correctly.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;using (SQLiteCommand sqlite_cmd = conn.CreateCommand()) {
    sqlite_cmd.CommandText = &amp;quot;SELECT * FROM SampleTable&amp;quot;;

    using(var sqlite_datareader = sqlite_cmd.ExecuteReader()){
        while (sqlite_datareader.Read())
        {
        string myreader = sqlite_datareader.GetString(0);
        Console.WriteLine(myreader);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you executed the whole workbook up to now, you should have the following output.&lt;/p&gt;
&lt;p&gt;&lt;img src="posts/images/jupyter-notebook-csharp-r/sqlite05.png" class="img-fluid" alt="sqlite05" /&gt;&lt;/p&gt;
&lt;p&gt;Closing the connection to the databse.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conn.Close();
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;Now that we have &lt;a href="/posts/jupyter-notebook-csharp-r"&gt;Jupyter Notebooks with C# installed&lt;/a&gt;, using it as an environment to play with SQLite is very easy. &lt;a href="https://www.sqlite.org/index.html"&gt;SQLite&lt;/a&gt; is a relational database that is small in footprint and self-contained. It also has a great in-memory mode which is perfect for playing around in a Jupyter notebook.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/jupyter-notebook-csharp-r</id>
		<title>Jupyter notebook with C# and R</title>
		<link href="http://ewinnington.github.io/posts/jupyter-notebook-csharp-r" />
		<updated>2019-11-12T19:00:00Z</updated>
		<content>&lt;p&gt;Following the release of the &lt;a href="https://devblogs.microsoft.com/dotnet/net-core-with-juypter-notebooks-is-here-preview-1/"&gt;updated dotnet try tool&lt;/a&gt;, here are my instructions for getting started.&lt;/p&gt;
&lt;h1 id="installing-jupyter-notebook-with-a-c-kernel"&gt;Installing jupyter notebook with a c# kernel&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Check if you installed python with visual studio.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Go to the start menu and start typing Python&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/python_installed.png" class="img-fluid" :height="360px" width="620px" alt="img1" /&gt;&lt;/p&gt;
&lt;p&gt;Right click on python and follow the Open File Location until you find the place where python is installed.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/python_installed_location.png" class="img-fluid" :height="360px" width="620px" alt="img2" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Or type: &lt;code&gt;where python&lt;/code&gt; in the command line.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If so, add python to the PATH of your environment. On my installation, the paths to Python were as follows. I had to add the Scripts path for the pip installation to be in the command line.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\Scripts&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;install jupyter using pip which was installed with visual studio, make sure to run in an &lt;strong&gt;administrator&lt;/strong&gt; shell
&lt;code&gt;pip install jupyter&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now get the list of installed jupyter kernels:
&lt;code&gt;jupyter kernelspec list&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;Available kernels:
  c:\program files (x86)\microsoft visual studio\shared\python37_64\share\jupyter\kernels\python3  
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Install the latest version of .net try
&lt;code&gt;dotnet tool install dotnet-try -g&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;finally install the .net kernel for jupyter with the command:
&lt;code&gt;dotnet try jupyter install&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;test the kernel is now installed with &lt;code&gt;jupyter kernelspec list&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/jupyter_kernels.png" class="img-fluid" alt="img3" /&gt;&lt;/p&gt;
&lt;h1 id="launch-jupyter-notebook"&gt;launch jupyter notebook&lt;/h1&gt;
&lt;p&gt;In the command line, type:
&lt;code&gt;jupyter notebook&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;A browser window should open and the terminal should display:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\Repos\noteb&amp;gt;jupyter notebook
[I 22:14:55.617 NotebookApp] JupyterLab extension loaded from c:\program files (x86)\microsoft visual studio\shared\python37_64\lib\site-packages\jupyterlab
[I 22:14:55.618 NotebookApp] JupyterLab application directory is c:\program files (x86)\microsoft visual studio\shared\python37_64\share\jupyter\lab
[I 22:14:55.625 NotebookApp] Serving notebooks from local directory: C:\Repos\noteb
[I 22:14:55.626 NotebookApp] The Jupyter Notebook is running at:
[I 22:14:55.627 NotebookApp] http://localhost:8888/?token=XXXXXXXXXXXXXXXXXXXc1ee1dfccc0a6624263d584b8ca4c
[I 22:14:55.628 NotebookApp]  or http://127.0.0.1:8888/?token=XXXXXXXXXXXXXXXXXXXc1ee1dfccc0a6624263d584b8ca4c
[I 22:14:55.629 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).  [C 22:14:55.737 NotebookApp]

    To access the notebook, open this file in a browser:
        file:///C:/Users/xxxxxx/AppData/Roaming/jupyter/runtime/nbserver-17608-open.html
    Or copy and paste one of these URLs:
        http://localhost:8888/?token=XXXXXXXXXXXXXXXXXXXc1ee1dfccc0a6624263d584b8ca4c
     or http://127.0.0.1:8888/?token=XXXXXXXXXXXXXXXXXXXc1ee1dfccc0a6624263d584b8ca4c
[I 22:15:16.852 NotebookApp] Kernel started: be6910a0-92f0-4ec0-a26c-d8274b44cd6d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main page of the Jupyter notebook allows you to see the notebooks available in the folder and to create new ones.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/jupyter_create_csharp.png" class="img-fluid" :height="360px" width="620px" alt="img4" /&gt;&lt;/p&gt;
&lt;h1 id="hello-world"&gt;Hello world&lt;/h1&gt;
&lt;p&gt;Create a new C# notebook. Then type&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using System; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in the first cell. I executed it and then typed:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;Console.WriteLine(&amp;quot;Hello World&amp;quot;); 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in the second cell. Executing it shows us that the C# Kernel is working.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/jupyter_hello_world_csharp.png" class="img-fluid" :height="360px" width="620px" alt="imgHello" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;#r&lt;/code&gt; is used to reference a dll or a nuget package. If you prefix the command with &amp;quot;nuget:&amp;quot; then the jupyter notebook will download the nuget and add it as a reference. Then as in usual c#, you must reference it.&lt;/p&gt;
&lt;h1 id="installing-an-r-kernel-for-jupyter-notebook"&gt;Installing an R kernel for jupyter notebook&lt;/h1&gt;
&lt;p&gt;To install R Tools for Visual Studio, install the Visual Studio Extension R Tools for Visual Studio 2019, which was in preview when I looked. Once this is installed, you must install the Microsoft R client. This option will be presented if you go to the &amp;quot;R Interactive&amp;quot; window.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/install_R_vs.png" class="img-fluid" :height="360px" width="620px" alt="img5" /&gt;&lt;/p&gt;
&lt;p&gt;I have R installed with visual studio, so I launched visual studio in &lt;strong&gt;admin mode&lt;/strong&gt; to be able to have my R directory writable, went to the R Tools menu at the top and selected &amp;quot;R Interactive&amp;quot;.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/r_interactive_vs.png" class="img-fluid" alt="img6" /&gt;&lt;/p&gt;
&lt;p&gt;From the command line of R, I typed in the following commands. &lt;a href="https://irkernel.github.io/installation/"&gt;Installation guide R&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/r_interactive_kernel_install.png" class="img-fluid" alt="img6" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-R"&gt;install.packages('IRkernel')
IRkernel::installspec(user = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I got the following output after installing the IRKernel into Jupyter &lt;code&gt;[InstallKernelSpec] Installed kernelspec ir in C:\ProgramData\jupyter\kernels\ir&lt;/code&gt;. Following this, you can check on the command line that the R kernel appears in the list of Jupyter Kernels with &lt;code&gt;jupyter kernelspec list&lt;/code&gt;, this should show the ir kernel installed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Available kernels:
  ir             C:\ProgramData\jupyter\kernels\ir
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="use-r-to-show-a-some-math"&gt;Use R to show a some math&lt;/h2&gt;
&lt;p&gt;Create a new R notebook and type in the first cell:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-R"&gt;demo(plotmath)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Executing this should show you the following long list of tables with mathematical symbols.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/jupyter-notebook-csharp-r/jupyter_R.png" class="img-fluid" :height="360px" width="620px" alt="img7" /&gt;&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Following the release of the &lt;a href="https://devblogs.microsoft.com/dotnet/net-core-with-juypter-notebooks-is-here-preview-1/"&gt;updated dotnet try tool&lt;/a&gt;, here are my instructions for getting started.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/bulk-inserts</id>
		<title>Using bulk inserts on databases</title>
		<link href="http://ewinnington.github.io/posts/bulk-inserts" />
		<updated>2019-11-11T00:00:00Z</updated>
		<content>&lt;p&gt;When inserting large amounts of data into databases, you should consider using the bulk functions instead of running single row INSERT commands. Single row INSERT command will usually lead to poor performance. There exists two main techniques for mutiple row insertions in databases from code and several more if you use the loader tools that accompany the database. Here I'll detail the two main methods: BulkInserts and VectorInserts.&lt;/p&gt;
&lt;h1 id="bulk-inserts-for-oracle-mssql-postgresql"&gt;Bulk Inserts for Oracle, MSSQL, Postgresql&lt;/h1&gt;
&lt;p&gt;For the examples, it is assumed that there exists an object Timeseries ts with a field IEnumerable TimeseriesData that contains Datapoints. A Datapoint has a DateTime field named t and a Decimal field named value.&lt;/p&gt;
&lt;h2 id="datatable-to-database"&gt;Datatable to Database&lt;/h2&gt;
&lt;p&gt;We setup a DataTable in memory and fill it with the data we need to insert.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;DataTable dt = new DataTable();
dt.Columns.Add(&amp;quot;IDTIMESERIES&amp;quot;, typeof(int));
dt.Columns.Add(&amp;quot;TIMEPOINT&amp;quot;, typeof(DateTime));
dt.Columns.Add(&amp;quot;VALUE1&amp;quot;, typeof(decimal));

int nRowsMaxDt = 0;
//ts being a timeseries object that contains a IEnumberable TimeSeriesData of sp (single points) 
foreach (var sp in ts.TimeSeriesData)
{
	object[] oRowDt = new object[3];
	oRowDt[0] = ts.Id; oRowDt[1] = sp.t; oRowDt[2] = (decimal)sp.value; 
	dt.Rows.Add(oRowDt); nRowsMaxDt = nRowsMaxDt + 1;
}
DumpDataTableToDB(&amp;quot;DATATIMESERIES&amp;quot;, dt, nRowsMaxDt);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The DumpDataTableToDB function is then written on a per database basis. Below you will find my examples for OracleDb, MSSQL and Postgres.&lt;/p&gt;
&lt;h3 id="oracle"&gt;Oracle:&lt;/h3&gt;
&lt;p&gt;Oracle has two sets of drivers, the Unmanaged and the Managed drivers. Your usings will be different per package.&lt;/p&gt;
&lt;p&gt;With ODP.NET Unmanaged (Drivers installed seperately - you will need to add the references manually)&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using Oracle.DataAccess.Client;
using Oracle.DataAccess.Types;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With ODP.NET Managed (Nuget Installed &lt;a href="https://www.nuget.org/packages/Oracle.ManagedDataAccess/"&gt;https://www.nuget.org/packages/Oracle.ManagedDataAccess/&lt;/a&gt; )&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using Oracle.ManagedDataAccess.Client;
using Oracle.ManagedDataAccess.Types;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use the OracleBulkCopy function with Con being an open connection to the database (OracleConnection).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;public void DumpDataTableToDB(string TableName, DataTable dt, int nCount)
{
	using (OracleBulkCopy obc = new OracleBulkCopy(Con))
	{
		obc.BatchSize = nCount;
		obc.DestinationTableName = TableName;
		obc.WriteToServer(dt);
		obc.Close();
	}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This method works, but I had issues with Oracle DataGuard. So for Oracle, I do recommend using the Vectorized data insert presented below with Oracle ArrayBind.&lt;/p&gt;
&lt;h3 id="ms-sql-server"&gt;MS SQL Server&lt;/h3&gt;
&lt;p&gt;The Microsoft SQL server uses SqlBulkCopy to connect and import the data. Again here the Con represents an open connection to the database.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using System.Data;
using System.Data.Common;
using System.Data.SqlClient;

public void DumpDataTableToDB(string TableName, DataTable dt, int nCount)
{
using (SqlBulkCopy bulkCopy = new SqlBulkCopy(((SqlConnection)Con).ConnectionString, SqlBulkCopyOptions.KeepNulls))
            {
                foreach (System.Data.DataColumn col in dt.Columns)
                {
                    bulkCopy.ColumnMappings.Add(col.ColumnName, col.ColumnName);
                }
                bulkCopy.DestinationTableName = TableName;
                bulkCopy.WriteToServer(dt);
            }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="postgresql"&gt;Postgresql&lt;/h3&gt;
&lt;p&gt;In Postgresql, the important part to note is the COPY ... FROM command. This allows you to provide either a file located on the DB Server or data from STDIN, passed from the client. The Format specifier allows for binary, which we are using here or text and csv. Note, the csv format is very picky, try the text format first if you are doing imports.&lt;/p&gt;
&lt;p&gt;As usualm the Con represents an open database connection.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using Npgsql; // Nuget https://www.nuget.org/packages/Npgsql 

public void DumpDataTableToDB(string TableName, DataTable dt, int nCount)
{
Dictionary&amp;lt;Type, NpgsqlTypes.NpgsqlDbType&amp;gt; TypeDict = new Dictionary&amp;lt;Type, NpgsqlTypes.NpgsqlDbType&amp;gt;();

            TypeDict.Add(typeof(int), NpgsqlTypes.NpgsqlDbType.Integer);
            TypeDict.Add(typeof(double), NpgsqlTypes.NpgsqlDbType.Double);
            TypeDict.Add(typeof(decimal), NpgsqlTypes.NpgsqlDbType.Numeric);
            TypeDict.Add(typeof(string), NpgsqlTypes.NpgsqlDbType.Varchar);
            TypeDict.Add(typeof(DateTime), NpgsqlTypes.NpgsqlDbType.Timestamp);
            TypeDict.Add(typeof(char[]), NpgsqlTypes.NpgsqlDbType.Varchar);
            TypeDict.Add(typeof(Guid), NpgsqlTypes.NpgsqlDbType.Uuid);


            string sql = &amp;quot;COPY &amp;quot; + TableName + &amp;quot; ( &amp;quot;;
            foreach (System.Data.DataColumn col in dt.Columns)
            {
                sql += (col.ColumnName.ToLower() + &amp;quot;,&amp;quot;);
            }
            sql = sql.TrimEnd(',') + &amp;quot;) FROM STDIN (FORMAT BINARY)&amp;quot;;
            int nRows = dt.Rows.Count;
            using (var BulkWrite = ((Npgsql.NpgsqlConnection)Con).BeginBinaryImport(sql))
            {
                for (int idRow = 0; idRow &amp;lt; nRows; idRow++)
                {
                    BulkWrite.StartRow();
                    foreach (System.Data.DataColumn col in dt.Columns)
                    {
                        if (dt.Rows[idRow].IsNull(col))
                        {
                            BulkWrite.WriteNull();
                        }
                        else
                        {
                            if (col.DataType == typeof(string) &amp;amp;&amp;amp; string.IsNullOrEmpty(dt.Rows[idRow].Field&amp;lt;string&amp;gt;(col)))
                            {
                                BulkWrite.WriteNull();
                            }
                            else
                            {
                                BulkWrite.Write(dt.Rows[idRow][col.Ordinal], TypeDict[col.DataType]);
                            }
                        }
                    }
                    
                }
                BulkWrite.Complete();
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="alternative-method-for-oracle-array-bind-for-vector-insertion"&gt;Alternative Method for Oracle Array Bind, for Vector Insertion&lt;/h2&gt;
&lt;p&gt;This is a better method for insertions on Oracle that does not cause issues with dataguard, using arrays of data. The single INSERT command is fed with an array of data.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;int nRowsCount = ts.Count(); 
int[] IDTIMESERIES = new int[nRowsCount];
DateTime[] TIMEPOINT = new DateTime[nRowsCount];
decimal[] VALUE1 = new decimal[nRowsCount];

// loading the arrays with data 
int i = 0;
foreach (var sp in ts.TimeSeriesData)
{
	IDTIMESERIES[i] = ts.Id; TIMEPOINT[i] = sp.t; VALUE1[i] = sp.value;
	i++;
}

if (nRowsCount &amp;gt; 0)
{
	OracleCommand cmdTimeDump = new OracleCommand(&amp;quot;Insert into DATATIMESERIES (IDTIMESERIES, TIMEPOINT, VALUE1) VALUES (:1, :2, :3)&amp;quot;, OraCon);
	cmdTimeDump.ArrayBindCount = nRowsCount;
	cmdTimeDump.Parameters.Add(new OracleParameter() { OracleDbType = OracleDbType.Int32, Value = IDTIMESERIES });
	cmdTimeDump.Parameters.Add(new OracleParameter() { OracleDbType = OracleDbType.Date, Value = TIMEPOINT });
	cmdTimeDump.Parameters.Add(new OracleParameter() { OracleDbType = OracleDbType.Decimal, Value = VALUE1 });
  
	cmdTimeDump.ExecuteNonQuery();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="links"&gt;Links&lt;/h1&gt;
&lt;p&gt;An excellent overview of connections to databases in .net core was published on the &lt;a href="https://devblogs.microsoft.com/dotnet/net-core-data-access/"&gt;Microsoft devblogs&lt;/a&gt;.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;When inserting large amounts of data into databases, you should consider using the bulk functions instead of running single row INSERT commands. Single row INSERT command will usually lead to poor performance. There exists two main techniques for mutiple row insertions in databases from code and several more if you use the loader tools that accompany the database. Here I'll detail the two main methods: BulkInserts and VectorInserts.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/webassembly-thoughts</id>
		<title>Reflections on Webassembly - May/Nov 19</title>
		<link href="http://ewinnington.github.io/posts/webassembly-thoughts" />
		<updated>2019-11-03T17:00:00Z</updated>
		<content>&lt;h1 id="initial-post"&gt;Initial post&lt;/h1&gt;
&lt;p&gt;I rewatched this talk from 2014, &lt;a href="https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript"&gt;The Birth and Death of JavaScript&lt;/a&gt;, and am still amazed at how prescient it was and still is.&lt;/p&gt;
&lt;p&gt;The blurb for this is:
“This science fiction / comedy / absurdist / completely serious talk traces the history of JavaScript, and programming in general, from 1995 until 2035.”&lt;/p&gt;
&lt;p&gt;ASM JS is still there, but what Gary Bernhardt calls Metal in the talk is WebAssembly. And WebAssembly (Wasm) is coming, and not just for the web.&lt;/p&gt;
&lt;p&gt;In the .Net world, we see the first glimpses of the power of Wasm with the arrival of &lt;a href="https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor"&gt;Blazor&lt;/a&gt;, which allows the execution of code running on the .net framework (using the mono runtime) inside a browser.&lt;/p&gt;
&lt;p&gt;Wasm is not stopping there. With the &lt;a href="https://hacks.mozilla.org/2019/03/standardizing-wasi-a-webassembly-system-interface/"&gt;standardising of WASI&lt;/a&gt;, a system interface to run Wasm outside the web, we are truly moving towards architecture independence.&lt;/p&gt;
&lt;p&gt;It might take until 2035, like in the video, for Wasm to take over the world, but I have the feeling we will see its impact in the near future. Looking at the progress on Wasm in the two last years, I would recommend any programmer to read up on it and understanding its implications on the way they work.&lt;/p&gt;
&lt;p&gt;For further reading on Wasm, I would recommend the mozilla &lt;a href="https://hacks.mozilla.org/category/webassembly/"&gt;WebAssembly Archives&lt;/a&gt; and in particular, the &lt;a href="https://hacks.mozilla.org/2018/10/webassemblys-post-mvp-future/"&gt;WebAssembly post mvp future by Lin Clark&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="update-in-november-2019"&gt;Update in november 2019&lt;/h1&gt;
&lt;p&gt;Over the last few months, I have seen Wasm cropping up in more and more places, for example as a way to deploy code to running inside databases, such as the case of &lt;a href="https://medium.com/wasmer/announcing-the-first-postgres-extension-to-run-webassembly-561af2cfcb1"&gt;Wasm for Postgres&lt;/a&gt; which allows stored procedures to run webassembly code.&lt;/p&gt;
&lt;p&gt;Another case of that is the reflection on using &lt;a href="https://youtu.be/3yVc5t-g-VU"&gt;WebAssembly as a glue between programming languages&lt;/a&gt; by allowing type information and guarantees to flow between programming languages. This would allow future systems to take the best of breed choice of programming language for each component of the system while still allowing compile time reasoning on type safety by using a type preserving compiler.&lt;/p&gt;
&lt;?# YouTube 3yVc5t-g-VU /?&gt;
&lt;p&gt;As I noted on twitter, as I read, watch and learn about webassembly, I'm getting the feeling this is going to be a titanic shift in the way we reason about programs, languages, frameworks and software design in general.&lt;/p&gt;
&lt;p&gt;&amp;quot;The avalanche has already started, it is too late for the pebbles to vote&amp;quot; - Ambassador Kosh, Babylon 5.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;I rewatched this talk from 2014, &lt;a href="https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript"&gt;The Birth and Death of JavaScript&lt;/a&gt;, and am still amazed at how prescient it was and still is.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/wyam-github-actions</id>
		<title>Using Github actions to build Wyam and publish to github pages</title>
		<link href="http://ewinnington.github.io/posts/wyam-github-actions" />
		<updated>2019-11-03T00:00:00Z</updated>
		<content>&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Not that I have Wyam as a static site generator, I want to use &lt;a href="https://github.com/features/actions"&gt;Github Actions&lt;/a&gt; to automatically deploy it on push. This requires a quite few steps to setup, but I did it, now so can you!&lt;/p&gt;
&lt;p&gt;Github actions is still in beta, so you'll have to enroll to use the functionality:
&lt;img src="/posts/images/github-actions-wyam/EnrollActions.png" class="img-fluid" alt="EnrollActions" /&gt;&lt;/p&gt;
&lt;h1 id="setup-procedure"&gt;Setup procedure&lt;/h1&gt;
&lt;p&gt;This setup assumes you have a local Wyam that is working on your local machine. You can easily set one up by &lt;a href="http://ewinnington.github.io/posts/Switching-to-wyam"&gt;following these steps&lt;/a&gt;. You can always have a look at my &lt;a href="https://github.com/ewinnington/ewinnington.github.io"&gt;https://github.com/ewinnington/ewinnington.github.io&lt;/a&gt; repository to see what I have configured in my config.wyam.&lt;/p&gt;
&lt;h2 id="personal-page"&gt;Personal page&lt;/h2&gt;
&lt;p&gt;First you must have a &lt;a href="https://pages.github.com/"&gt;Personal Page&lt;/a&gt; setup in github. This is done by creating a public repository &lt;em&gt;username&lt;/em&gt;.github.io.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/CreateRepo.png" class="img-fluid" alt="RepoCreation" /&gt;&lt;/p&gt;
&lt;h3 id="create-the-correct-branches"&gt;Create the correct branches&lt;/h3&gt;
&lt;p&gt;Inside that repository, you will want to create a second branch next to the master: source. This can be done by typing a new branch name in the Switch branches/tags text box.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SourceBranch.png" class="img-fluid" alt="SourceBranch" /&gt;&lt;/p&gt;
&lt;p&gt;Next step is to make this branch the default when we push commits to the repository. This is because the &lt;em&gt;master&lt;/em&gt; branch of the username.gitub.io is what is hosted on github's personal pages. Therefore the source of the wyam site has to be stored on another branch. To set the branch as default, Go to &lt;em&gt;Settings&lt;/em&gt;, then &lt;em&gt;Branches&lt;/em&gt; and select &lt;strong&gt;source&lt;/strong&gt; in the dropdown box. Confirm with update.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SettingsBranches.png" class="img-fluid" alt="SettingsBranches" /&gt;&lt;/p&gt;
&lt;h3 id="prepare-keys-and-install-them"&gt;Prepare keys and install them&lt;/h3&gt;
&lt;p&gt;We will be doing automated pushes from the &lt;strong&gt;source&lt;/strong&gt; branch to the &lt;strong&gt;master&lt;/strong&gt; branch, this means that we need to setup deploy keys and the associated secrets so that github allows us to update in an automated manner.&lt;/p&gt;
&lt;p&gt;First, you need to generate your keys locally on your own machine with &lt;code&gt;ssh-keygen -t rsa -b 4096 -C &amp;quot;Github-user-email&amp;#64;example.com&amp;quot; -f gh-pages -N &amp;quot;&amp;quot;&lt;/code&gt;. You will need to replace &lt;em&gt;Github-user-email&amp;#64;example.com&lt;/em&gt; with your own, of course.&lt;/p&gt;
&lt;p&gt;This will generate two files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gh-pages : the private key file, this will go into the secrets tab on github. I named the key &lt;strong&gt;ACTIONS_DEPLOY_KEY&lt;/strong&gt;, this is important because we need to access it as an environment variable later in the action workflow script.&lt;/li&gt;
&lt;li&gt;gh-pages.pub : the public key file, this will go to the deploy tab on github. I named my deploy key &lt;em&gt;public ACTIONS_DEPLOY_KEY&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once installed, they should be like this in the github user interface of the repository:&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SecretsKey.png" class="img-fluid" alt="Secrets" /&gt;
&lt;img src="/posts/images/github-actions-wyam/DeployKey.png" class="img-fluid" alt="Deploy" /&gt;&lt;/p&gt;
&lt;h2 id="clone-the-repository-or-import-an-existing-git-repo"&gt;Clone the repository (or import an existing git repo)&lt;/h2&gt;
&lt;p&gt;If you have nothing yet in the repository, I suppose you can now directly clone it from github using &lt;code&gt;git clone https://github.com/username/username.github.io&lt;/code&gt; and it should come out all pre-prepared for you. Check something in and push.&lt;/p&gt;
&lt;h3 id="existing-repository"&gt;Existing repository&lt;/h3&gt;
&lt;p&gt;I had an existing repository, so I had a few things to do with it before it was ready to be uploaded. I had already a master branch named &lt;strong&gt;master&lt;/strong&gt;, so to make it conform with github, I renamed my local master branch with &lt;code&gt;git branch -m source &lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I then removed the previous origin before that was in use and I had to add the correct origin that I wanted to push to. Because I had previously had contents on the repository, I had to use the -f command on the push.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;git remote remove origin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git remote add origin https://github.com/username/username.github.io&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git push -u -f origin source&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now that I had pushed the Wyam blog, I was ready to setup the actions.&lt;/p&gt;
&lt;h4 id="side-note-good-wyam.gitignore-file"&gt;Side note - good wyam .gitignore file&lt;/h4&gt;
&lt;p&gt;To avoid checking in the output files of the wyam build, I have the following .gitignore file in the repository:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;config.wyam.dll
config.wyam.hash
config.wyam.packages.xml
wwwroot
output
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="setting-up-the-github-actions"&gt;Setting up the github actions&lt;/h2&gt;
&lt;p&gt;First you will want to check that you are allowing external workflow scripts to be launched on your repository, since I will be relying on a few steps from pre-existing scripts.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SetupActions.png" class="img-fluid" alt="SetupActions.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here the first mistake I made while configuring actions was not going through the Github user interface and instead creating the folders manually in my github repository. I created &lt;em&gt;.github/workflow&lt;/em&gt; instead of &lt;strong&gt;.github/workflows&lt;/strong&gt; which meant that my actions were never kicking off. So don't make my mistake, use the github UI to set up the action and they will create the correct folder structure in your project.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/SetUpActionsWorkflow.png" class="img-fluid" alt="Actions workflow" /&gt;&lt;/p&gt;
&lt;p&gt;I setup a yaml file name &lt;a href="https://github.com/ewinnington/ewinnington.github.io/blob/source/.github/workflows/wyam.yml"&gt;wyam.yml&lt;/a&gt;. You can see what it looks like here below (I have included the code below on the page for you to copy and paste if you want. Let's go through this line by line.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/wyam-yaml.png" class="img-fluid" alt="Wyam Yaml" /&gt;&lt;/p&gt;
&lt;p&gt;Line 1: Name of the action that will appear in the action tab&lt;/p&gt;
&lt;p&gt;Line 3-6: Triggers of the action. Here we trigger the action &lt;strong&gt;on push&lt;/strong&gt; of &lt;strong&gt;branch source&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Line 8: List of jobs to run.
Line 9: First job is my build and deploy, I just called it build.&lt;/p&gt;
&lt;p&gt;Line 11: The choice of the image to run on, like in docker. I chose ubuntu-latest.&lt;/p&gt;
&lt;p&gt;Line 13: Each line prexifed with a - is a seperate action.&lt;/p&gt;
&lt;p&gt;Line 14: Checkout the repository with the branch that has just been pushed. This is a standard github action, you can find &lt;a href="https://github.com/actions/checkout"&gt;explanations here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Line 15: Installing .net core for Wyam.&lt;/p&gt;
&lt;p&gt;Line 19-20: Installing Wyam. Here I install Wyam as a local tool by giving the &lt;code&gt;--tool-path .&lt;/code&gt;, since if you install it as a global tool with &lt;em&gt;-g&lt;/em&gt;, the build system won't find it due to .net core's requirement &lt;a href="https://github.com/dotnet/cli/issues/8368"&gt;to restart the shell after being installed for the paths to be valid&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Line 21-22: Running Wyam to render the blog to a set of static pages. Here is where you can change the template (Phantom) to something else if you want.&lt;/p&gt;
&lt;p&gt;Line 23-28: We take the output of Wyam, which lives in the ./output folder and we use &lt;a href="https://github.com/peaceiris/actions-gh-pages"&gt;peaceiris's github action for Github Pages&lt;/a&gt; to publish our results to the correct branch &lt;em&gt;master&lt;/em&gt; of our repository for deployment. We pass the &lt;em&gt;secrets.ACTIONS_DEPLOY_KEY&lt;/em&gt; we defined earlier to allow the script to publish to the master branch.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: Wyam

on:
  push:
    branches:
    - source  # default branch

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout&amp;#64;v1
    - name: Setup .NET Core
      uses: actions/setup-dotnet&amp;#64;v1
      with:
        dotnet-version: 2.1.802
    - name: Install Wyam
      run: dotnet tool install --tool-path . wyam.tool
    - name: Publish blog
      run: ./wyam -r blog -t Phantom
    - name: Deploy
      uses: peaceiris/actions-gh-pages&amp;#64;v2.5.0
      env:
        ACTIONS_DEPLOY_KEY: ${{ secrets.ACTIONS_DEPLOY_KEY }}
        PUBLISH_BRANCH: master  # deploying branch
        PUBLISH_DIR: ./output

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="running-the-workflow"&gt;Running the workflow&lt;/h2&gt;
&lt;p&gt;Once you have setup this file, you can commit it and it should start off the build action. You can follow the progress of the action workflow on the github action page.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/ActionOverview.png" class="img-fluid" alt="Action Overview" /&gt;&lt;/p&gt;
&lt;p&gt;You can drill down into the details of the actions in case you had any failures. This is where I had the most trouble, but with these instructions, you should be fine.&lt;/p&gt;
&lt;p&gt;&lt;img src="/posts/images/github-actions-wyam/ActionDetail.png" class="img-fluid" alt="Action Detail" /&gt;&lt;/p&gt;
&lt;h1 id="closing"&gt;Closing&lt;/h1&gt;
&lt;p&gt;If all went well, you should now have your personal wyam generated site up and running at &lt;a href="http://username.github.io"&gt;http://username.github.io&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;Please feel free to look around both branches &lt;em&gt;source&lt;/em&gt; and &lt;em&gt;master&lt;/em&gt; on &lt;a href="https://github.com/ewinnington/ewinnington.github.io"&gt;my github repo&lt;/a&gt; to understand how my blog is setup.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Not that I have Wyam as a static site generator, I want to use &lt;a href="https://github.com/features/actions"&gt;Github Actions&lt;/a&gt; to automatically deploy it on push. This requires a quite few steps to setup, but I did it, now so can you!&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/R-Redis-Json</id>
		<title>R - Reading JSON from redis</title>
		<link href="http://ewinnington.github.io/posts/R-Redis-Json" />
		<updated>2019-11-03T00:00:00Z</updated>
		<content>&lt;p&gt;I needed to access Redis from R. Here's the code I used to connect, set a value, then deserialize a key that was in json format and publish a message. &lt;a href="https://cran.r-project.org/web/packages/rredis/vignettes/rredis.pdf"&gt;Rredis documentation located here&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(&amp;quot;rredis&amp;quot;)
library(&amp;quot;jsonlite&amp;quot;, lib.loc=&amp;quot;~/R/win-library/3.2&amp;quot;)

redisConnect()
redisSet(&amp;quot;x&amp;quot;,rnorm(5))
redisGet(&amp;quot;x&amp;quot;)

x = fromJSON(redisGet(&amp;quot;ts_1&amp;quot;))
x$t &amp;lt;-  strptime(x$t, &amp;quot;%Y-%m-%dT%H:%M:%S&amp;quot;)

//https://cran.r-project.org/web/packages/rredis/vignettes/rredis.pdf
redisPublish(&amp;quot;General:Active&amp;quot;, charToRaw('Message'))

redisClose()
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;I needed to access Redis from R. Here's the code I used to connect, set a value, then deserialize a key that was in json format and publish a message. &lt;a href="https://cran.r-project.org/web/packages/rredis/vignettes/rredis.pdf"&gt;Rredis documentation located here&lt;/a&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/R-read-binary-file</id>
		<title>R - Reading binary files</title>
		<link href="http://ewinnington.github.io/posts/R-read-binary-file" />
		<updated>2019-11-03T00:00:00Z</updated>
		<content>&lt;p&gt;I had to get some data out of files written by Fortran. The format was a large array of doubles.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;numeric() for doubles&lt;/li&gt;
&lt;li&gt;integer() for integers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;readBin takes the input file and reads the binary data. If you want to read to the end of the file, don't give a dimension as 3rd parameter.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-R"&gt;#### Reading value field from file
z &amp;lt;- file(&amp;quot;/BoundValueRemain.bin&amp;quot;, &amp;quot;rb&amp;quot;)
y &amp;lt;- readBin (z, numeric(), 51*50*50*15*13)
close(z)
dim(y) &amp;lt;- c(51, 50, 50, 15, 13)
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;I had to get some data out of files written by Fortran. The format was a large array of doubles.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/Switching-to-wyam</id>
		<title>Switching to Wyam</title>
		<link href="http://ewinnington.github.io/posts/Switching-to-wyam" />
		<updated>2019-10-23T00:00:00Z</updated>
		<content>&lt;p&gt;After many years with a half abandoned Wordpress blog, I'm switching to &lt;a href="https://wyam.io/"&gt;Wyam&lt;/a&gt; for a static site generator.&lt;/p&gt;
&lt;p&gt;This blog was generated as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dotnet tool install -g wyam.tool
wyam new -r blog
wyam -r blog -t Phantom -p -w
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last command makes wyam host the blog using the recipe blog, the theme Phantom (-t), in preview mode (-p) so that you can access it locally and in Watch mode (-w), so that you can see changes without having to re-run the build line.&lt;/p&gt;
&lt;p&gt;I also exported the previous posts from Wordpress and will be adding those that are not too outdated back here.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;After many years with a half abandoned Wordpress blog, I'm switching to &lt;a href="https://wyam.io/"&gt;Wyam&lt;/a&gt; for a static site generator.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/append-files-together-using-windows-command-line</id>
		<title>Append files together using windows command line</title>
		<link href="http://ewinnington.github.io/posts/append-files-together-using-windows-command-line" />
		<updated>2015-06-26T00:00:00Z</updated>
		<content>&lt;p&gt;In the command prompt, an easy way to append files together is to use the &amp;quot;type&amp;quot; command and pipe it to an output file.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;type Results\_\* &amp;gt; Results\_combined.txt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To call this from a piece of C# code, I have been using the command line with the /c parameter, which makes it execute the attached command.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cmd /c type Results\_\* &amp;gt; Results\_combined.txt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;C# Example usage:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-CSharp"&gt;using (Process RunProc = new Process()) {
    string s = &amp;quot;cmd.exe&amp;quot;;  
    string p = &amp;quot;/c type Results\_\* &amp;gt; Results\_combined.txt&amp;quot;;
    RunProc.StartInfo = new ProcessStartInfo(s, p);
    RunProc.Start();    
    RunProc.WaitForExit();
}
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;In the command prompt, an easy way to append files together is to use the "type" command and pipe it to an output file.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/tail-command-with-powershell</id>
		<title>Tail command with powershell</title>
		<link href="http://ewinnington.github.io/posts/tail-command-with-powershell" />
		<updated>2015-02-19T00:00:00Z</updated>
		<content>&lt;p&gt;Powershell has now got a command to see the last lines of a file. The syntax is for the last 10 lines:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;Get-Content _filename _\-Tail 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It also has a -wait command that blocks and shows new entries as they arrive.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Powershell has now got a command to see the last lines of a file. The syntax is for the last 10 lines:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/oracle-getting-a-list-of-all-columns-data-types-lengths-of-column-for-every-table-in-your-schema</id>
		<title>Oracle Getting a list of all columns, data types, lengths of column for every table in your schema</title>
		<link href="http://ewinnington.github.io/posts/oracle-getting-a-list-of-all-columns-data-types-lengths-of-column-for-every-table-in-your-schema" />
		<updated>2014-09-16T00:00:00Z</updated>
		<content>&lt;p&gt;To get all the columns in the schema of an oracle DB, with the appropriate datatype and column length you can use:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;select column_name, data_type, data_length, table_name 
from all_tab_columns where table_name in 
(select TABLE_NAME from user_tables);
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;To get all the columns in the schema of an oracle DB, with the appropriate datatype and column length you can use:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/getting-autoincremented-version-numbers-in-visual-studio</id>
		<title>Getting autoincremented version numbers in Visual Studio</title>
		<link href="http://ewinnington.github.io/posts/getting-autoincremented-version-numbers-in-visual-studio" />
		<updated>2014-08-25T00:00:00Z</updated>
		<content>&lt;p&gt;On C# projects, in the &amp;quot;AssemblyInfo.cs&amp;quot; file, you can set the Assembly Version to contain *, which sets the version automatically to the build date and time.&lt;/p&gt;
&lt;p&gt;If you comment out the AssemblyFileVersion, then you can see it in the Windows explorer. If you don't then Windows Explorer will always report the AssemblyFileVersion which does not support the * notation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\[assembly: AssemblyVersion(&amp;quot;1.0.\*&amp;quot;)\]
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;On C# projects, in the "AssemblyInfo.cs" file, you can set the Assembly Version to contain *, which sets the version automatically to the build date and time.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/using-svg-images-on-azure-websites</id>
		<title>Using SVG images on Azure Websites</title>
		<link href="http://ewinnington.github.io/posts/using-svg-images-on-azure-websites" />
		<updated>2014-08-23T00:00:00Z</updated>
		<content>&lt;p&gt;I've been using &lt;a href="https://useiconic.com/"&gt;Iconic's icon set&lt;/a&gt; for the development of a dashboard for one of my projects. While publishing it to &lt;a href="http://azure.microsoft.com/en-us/"&gt;Azure&lt;/a&gt; to test it out, none of the SVGs images or icons were being served.&lt;/p&gt;
&lt;p&gt;It required a little bit of configuration to get it all running:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Make sure the svg files are included in the visual studio project and are set to &amp;quot;Copy Always&amp;quot; or &amp;quot;Copy If Newer&amp;quot;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Configure the web.config of your project to contain the following code to make azure serve the SVGs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt; &amp;lt;system.webServer&amp;gt;
   &amp;lt;staticContent&amp;gt;
     &amp;lt;remove fileExtension=&amp;quot;.svg&amp;quot;/&amp;gt;
     &amp;lt;mimeMap fileExtension=&amp;quot;.svg&amp;quot; mimeType=&amp;quot;image/svg+xml&amp;quot; /&amp;gt;
   &amp;lt;/staticContent&amp;gt;
 &amp;lt;/system.webServer&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This give the correct mimeType to Azure. For some strange reason, it doesn't have it by default in its configuration, and you'll get errors when trying to serve the content (404). With these steps done, Azure should be able to serve you static SVG images when you use the correct path (I use /img/ ).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&amp;quot;~/img/database.svg&amp;quot; alt=&amp;quot;database&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should get you a black and white database icon.&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;p&gt; To use Iconic's features like CSS styling of the icons, you need to include in your script bundle the iconic.js (or iconic.min.js).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the data-src attribute in the &lt;img&gt; tag to indicate the Iconic that it must inject the SVG into the document.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img data-src=&amp;quot;~/img/database.svg&amp;quot; class=&amp;quot;iconic iconic-md ok&amp;quot; alt=&amp;quot;database&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="5"&gt;
&lt;li&gt;Create custom CSS markings like the &amp;quot;ok&amp;quot; class to style the icon. I added these in a site-iconic.css file that I include in the bundles.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;.ok {
fill: green;
}
.nok {
fill: red;
}&lt;/p&gt;
&lt;p&gt;This &amp;quot;ok&amp;quot; class changes the icon fill to green, I have similarly an &amp;quot;nok&amp;quot; class changing the icon to red.&lt;/p&gt;
&lt;ol start="6"&gt;
&lt;li&gt;If you are using the Razor engine to generate your pages, you can directly assign class names based on the object's properties. Here I have an object DbServer which has a boolean property isAvailable to show its status.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;&amp;#64;{
string status = (DbServer.isAvailable ? &amp;quot;ok&amp;quot; : &amp;quot;nok&amp;quot;);
&amp;lt;img data-src=&amp;quot;~/img/database.svg&amp;quot; class=&amp;quot;iconic iconic-md &amp;#64;status&amp;quot; alt=&amp;quot;database&amp;quot;&amp;gt;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, every time the page is refreshed, the status of the DB is indicated by the colour of the Database icon.&lt;/p&gt;
&lt;p&gt;&lt;a href="old/images/Dashboard-e1408819237573.png"&gt;&lt;img src="old/images/Dashboard-e1408819237573.png" class="img-fluid" alt="Dashboard" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now you can really use Iconic's icon set potential.&lt;/p&gt;
&lt;p&gt;Of course, if you are using &lt;a href="http://signalr.net/"&gt;SignalR&lt;/a&gt;, you can also wire up the whole setup to dynamically adjust the icons with javascript, but that's for another post.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;I've been using &lt;a href="https://useiconic.com/"&gt;Iconic's icon&amp;nbsp;set&lt;/a&gt; for the development of a dashboard for one of my projects. While publishing&amp;nbsp;it to &lt;a href="http://azure.microsoft.com/en-us/"&gt;Azure&lt;/a&gt; to test it out, none of the SVGs images or icons were being served.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/diff-compare-two-files-in-visual-studio</id>
		<title>Diff / Compare two files in Visual Studio</title>
		<link href="http://ewinnington.github.io/posts/diff-compare-two-files-in-visual-studio" />
		<updated>2014-03-23T00:00:00Z</updated>
		<content>&lt;p&gt;In visual studio, you can use the integrated command line to diff two files by using the command &lt;em&gt;Tools.DiffFiles file1 file2&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Thanks to my work colleagues for that trick!&lt;/p&gt;
</content>
		<summary>&lt;p&gt;In visual studio, you can use the integrated command line to diff two files by using the command &lt;em&gt;Tools.DiffFiles file1 file2&lt;/em&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/listing-the-channels-of-the-wifi-networks-around-you-in-windows</id>
		<title>Listing the channels of the WIFI networks around you in Windows</title>
		<link href="http://ewinnington.github.io/posts/listing-the-channels-of-the-wifi-networks-around-you-in-windows" />
		<updated>2014-03-11T00:00:00Z</updated>
		<content>&lt;p&gt;To list the network channels in use by the various wi-fi networks, you can always use this command in an Administrator command prompt.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;netsh wlan show all
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;To list the network channels in use by the various wi-fi networks, you can always use this command in an Administrator command prompt.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/oracle-reclaiming-lob-space-after-deletion-clob-blob</id>
		<title>Oracle - Reclaiming LOB space after deletion (CLOB, BLOB)</title>
		<link href="http://ewinnington.github.io/posts/oracle-reclaiming-lob-space-after-deletion-clob-blob" />
		<updated>2014-02-03T00:00:00Z</updated>
		<content>&lt;p&gt;To reclaim space after a deleting LOBs, use the following commands. XXXXX is my tablename, data is my column name for the lob, in pink the size of the table.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Check size of the table XXXXX&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;SELECT table_name, column_name, segment_name, a.bytes
FROM dba_segments a JOIN dba_lobs b
USING (owner, segment_name)
WHERE b.table_name = 'XXXXX';
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; XXXXX DATA SYS_LOB0000025315C00007$$ 1073741824
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Delete, in my case, I just clean up all files in my table.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;DELETE FROM XXXXX;
COMMIT;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; 183 rows deleted.
&amp;gt;&amp;gt; committed.
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Ask Oracle to shrink the tablespace used by the LOB column ‘data’. Have a coffee break.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;ALTER TABLE XXXXX MODIFY LOB (data) (SHRINK SPACE);
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; table XXXXX altered.
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="4"&gt;
&lt;li&gt;Check size again:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;SELECT table_name, column_name, segment_name, a.bytes
FROM dba_segments a JOIN dba_lobs b
USING (owner, segment_name)
WHERE b.table_name = 'XXXXX';
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; XXXXX DATA SYS\_LOB0000025315C00007$$ 65536
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;To reclaim space after a deleting LOBs, use the following commands. XXXXX is my tablename, data is my column name for the lob, in pink the size of the table.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/oracle-sql-developer-set-nls-to-give-you-full-date-and-time</id>
		<title>Oracle SQL Developer - Set NLS to give you full date and time</title>
		<link href="http://ewinnington.github.io/posts/oracle-sql-developer-set-nls-to-give-you-full-date-and-time" />
		<updated>2014-01-31T00:00:00Z</updated>
		<content>&lt;p&gt;In the SQL sheet for the database, use the following SQL:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;alter session set NLS_DATE_FORMAT = &amp;quot;dd.mm.yyyy hh24:mi:ss&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;In the SQL sheet for the database, use the following SQL:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/sqlfiddle-a-way-to-share-sql-snippets-so-that-they-can-be-tested-in-the-browser</id>
		<title>SqlFiddle - A way to share SQL snippets so that they can be tested in the browser</title>
		<link href="http://ewinnington.github.io/posts/sqlfiddle-a-way-to-share-sql-snippets-so-that-they-can-be-tested-in-the-browser" />
		<updated>2013-11-05T00:00:00Z</updated>
		<content>&lt;p&gt;A couple of days ago, I stumbled upon &lt;a href="http://www.sqlfiddle.com/"&gt;SQLFiddle&lt;/a&gt;, a little magical website that allows you to upload a DBSchema and run queries on it, live in the browser. It also allows to share them with other users.&lt;/p&gt;
&lt;p&gt;In the course of my work, I've often come across a table that has an identifier, a timestamp and a value, and these rows must be mapped to one new row containing multiple identifiers. Two typical examples of that are two identifiers defining a minimum and a maximum value timeseries that must be put into a single row entry and an entry that is built from three identified timeseries representing value, volatility and mean reversion parameters of a stochastic process.&lt;/p&gt;
&lt;p&gt;In my earlier blog post, &lt;a href="Oracle10g-Pivoting-data.html"&gt;Oracle 10g - Pivoting data&lt;/a&gt;, I provided two different sql scripts to solve the first case min/max time series. You can find the SQLFiddles here:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.sqlfiddle.com/#!4/dce2d/1"&gt;Decode with subquery and max &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.sqlfiddle.com/#!4/dce2d/2"&gt;Decode in one query and max &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can even view your query's execution plan, which is a really nice touch. I'll take the time to share some more oracle sql statements next time in an SQLFiddle.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;A couple of days ago, I stumbled upon &lt;a href="http://www.sqlfiddle.com/"&gt;SQLFiddle&lt;/a&gt;, a little magical website that allows you to upload a DBSchema and run queries on it, live in the browser. It also allows to share them with other users.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/raspberry-pi-update-arkos</id>
		<title>Raspberry Pi update Arkos</title>
		<link href="http://ewinnington.github.io/posts/raspberry-pi-update-arkos" />
		<updated>2013-10-31T00:00:00Z</updated>
		<content>&lt;p&gt;Since I haven't talked much about what I've been doing with my Pi, here's the latest:&lt;/p&gt;
&lt;p&gt;I've installed a distribution called &lt;a href="https://arkos.io/"&gt;ArkOS&lt;/a&gt;, which exposes a web interface allowing the easy configuration of many network accessible services, including a blog and an &lt;a href="http://owncloud.org/"&gt;owncloud&lt;/a&gt; instance.&lt;/p&gt;
&lt;p&gt;I use owncloud as my private, unlimited, Dropbox. The first time I set it up, on a nginx server, it took a lot of configuration to get just right. ArkOS does it all out of the box.&lt;/p&gt;
&lt;p&gt;For dynamic DNS, instead of my previous self-hosted &amp;quot;poor man's&amp;quot; link, I am now using &lt;a href="http://duckdns.org/"&gt;DuckDNS&lt;/a&gt; which promises free dynamic DNS and is really easy to use.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Since I haven't talked much about what I've been doing with my Pi, here's the latest:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://ewinnington.github.io/posts/debugging-tips</id>
		<title>Debugging tips</title>
		<link href="http://ewinnington.github.io/posts/debugging-tips" />
		<updated>2013-10-31T00:00:00Z</updated>
		<content>&lt;p&gt;If you get a bug in a loop, remember that the bug could be caused by the previous execution of the loop and thus be below the code point that fails.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;If you get a bug in a loop, remember that the bug could be caused by the previous execution of the loop and thus be below the code point that fails.&lt;/p&gt;</summary>
	</entry>
</feed>